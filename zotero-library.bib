
@inproceedings{hensmanGaussian2013,
	title = {Gaussian {Processes} for {Big} {Data}},
	volume = {29},
	abstract = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be variationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our approach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
	language = {en},
	booktitle = {Proceedings of the 29th {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	author = {Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
	year = {2013},
	keywords = {gaussian-processes, sparse-gaussian-processes, variational-inference},
	pages = {282--290},
	file = {Hensman et al. - Gaussian Processes for Big Data.pdf:/Users/aidanscannell/Zotero/storage/KLY9PMZH/Hensman et al. - Gaussian Processes for Big Data.pdf:application/pdf},
}

@inproceedings{haubergGeometric2012,
	title = {A {Geometric} take on {Metric} {Learning}},
	abstract = {Multi-metric learning techniques learn local metric tensors in different parts of a feature space. With such an approach, even simple classiﬁers can be competitive with the state-of-the-art because the distance measure locally adapts to the structure of the data. The learned distance measure is, however, non-metric, which has prevented multi-metric learning from generalizing to tasks such as dimensionality reduction and regression in a principled way. We prove that, with appropriate changes, multi-metric learning corresponds to learning the structure of a Riemannian manifold. We then show that this structure gives us a principled way to perform dimensionality reduction and regression according to the learned metrics. Algorithmically, we provide the ﬁrst practical algorithm for computing geodesics according to the learned metrics, as well as algorithms for computing exponential and logarithmic maps on the Riemannian manifold. Together, these tools let many Euclidean algorithms take advantage of multi-metric learning. We illustrate the approach on regression and dimensionality reduction tasks that involve predicting measurements of the human body from shape data.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hauberg, Søren and Freifeld, Oren and Black, Michael J},
	year = {2012},
	keywords = {geometric-learning, geodesics, riemannian},
	pages = {9},
	file = {Hauberg et al. - A Geometric take on Metric Learning.pdf:/Users/aidanscannell/Zotero/storage/JSWHM5S9/Hauberg et al. - A Geometric take on Metric Learning.pdf:application/pdf},
}

@inproceedings{tosiMetrics2014,
	title = {Metrics for {Probabilistic} {Geometries}},
	abstract = {We investigate the geometrical structure of probabilistic generative dimensionality reduction models using the tools of Riemannian geometry. We explicitly deﬁne a distribution over the natural metric given by the models. We provide the necessary algorithms to compute expected metric tensors where the distribution over mappings is given by a Gaussian process. We treat the corresponding latent variable model as a Riemannian manifold and we use the expectation of the metric under the Gaussian process prior to deﬁne interpolating paths and measure distance between latent points. We show how distances that respect the expected metric lead to more appropriate generation of new data.},
	language = {en},
	booktitle = {Proceedings of the 30th {Conference}},
	author = {Tosi, Alessandra and Hauberg, Søren and Vellido, Alfredo and Lawrence, Neil D},
	year = {2014},
	keywords = {geometric-learning, gaussian-processes, gplvm},
	pages = {800--808},
	file = {Tosi et al. - Metrics for Probabilistic Geometries.pdf:/Users/aidanscannell/Zotero/storage/U65536P3/Tosi et al. - Metrics for Probabilistic Geometries.pdf:application/pdf},
}

@inproceedings{berkenkampSafe2017,
	title = {Safe {Model}-based {Reinforcement} {Learning} with {Stability} {Guarantees}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/766ebcd59621e305170616ba3d3dac32-Abstract.html},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
	year = {2017},
	keywords = {reinforcement-learning, safe-exploration},
	pages = {908--918},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/AQTLYZZW/Berkenkamp et al. - 2017 - Safe Model-based Reinforcement Learning with Stabi.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/UXGE9IY2/766ebcd59621e305170616ba3d3dac32-Abstract.html:text/html},
}

@inproceedings{kollerLearningBased2018,
	title = {Learning-{Based} {Model} {Predictive} {Control} for {Safe} {Exploration}},
	doi = {10.1109/CDC.2018.8619572},
	abstract = {Learning-based methods have been successful in solving complex control tasks without significant prior knowledge about the system. However, these methods typically do not provide any safety guarantees, which prevents their use in safety-critical, real-world applications. In this paper, we present a learning-based model predictive control scheme that can provide provable high-probability safety guarantees. To this end, we exploit regularity assumptions on the dynamics in terms of a Gaussian process prior to construct provably accurate confidence intervals on predicted trajectories. Unlike previous approaches, we do not assume that model uncertainties are independent. Based on these predictions, we guarantee that trajectories satisfy safety constraints. Moreover, we use a terminal set constraint to recursively guarantee the existence of safe control actions at every iteration. In our experiments, we show that the resulting algorithm can be used to safely and efficiently explore and learn about dynamic systems.},
	booktitle = {2018 {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Koller, T. and Berkenkamp, F. and Turchetta, M. and Krause, A.},
	month = dec,
	year = {2018},
	note = {ISSN: 2576-2370},
	keywords = {complex control tasks, Data models, dynamic systems, Ellipsoids, Gaussian process, Gaussian processes, high-probability safety guarantees, Kernel, learning (artificial intelligence), learning-based model predictive control scheme, model uncertainties, predicted trajectories, predictive control, Predictive models, probability, provably accurate confidence intervals, Safety, safety constraints, safety-critical, Trajectory, Uncertainty, mpc, safe-exploration},
	pages = {6059--6066},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/9DEXJKB7/8619572.html:text/html;Submitted Version:/Users/aidanscannell/Zotero/storage/XQVMNHZC/Koller et al. - 2018 - Learning-Based Model Predictive Control for Safe E.pdf:application/pdf},
}

@phdthesis{berkenkampSafe2019,
	type = {Doctoral {Thesis}},
	title = {Safe {Exploration} in {Reinforcement} {Learning}: {Theory} and {Applications} in {Robotics}},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
	shorttitle = {Safe {Exploration} in {Reinforcement} {Learning}},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/370833},
	language = {en},
	urldate = {2020-11-26},
	school = {ETH Zurich},
	author = {Berkenkamp, Felix},
	year = {2019},
	doi = {10.3929/ethz-b-000370833},
	note = {Accepted: 2019-10-16T10:53:26Z},
	keywords = {reinforcement-learning, safe-exploration, quadcopter, robotics},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/WYNQYBJ3/Berkenkamp - 2019 - Safe Exploration in Reinforcement Learning Theory.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/J9XZZSNF/370833.html:text/html;Snapshot:/Users/aidanscannell/Zotero/storage/7XZQV7AR/370833.html:text/html},
}

@inproceedings{curiStructured2020,
	title = {Structured {Variational} {Inference} in {Partially} {Observable} {Unstable} {Gaussian} {Process} {State} {Space} {Models}},
	url = {http://proceedings.mlr.press/v120/curi20a.html},
	abstract = {We propose a new variational inference algorithm for learning in Gaussian Process State-Space Models (GPSSMs). Our algorithm enables learning of unstable and partially observable systems, where pre...},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Learning for {Dynamics} and {Control}},
	publisher = {PMLR},
	author = {Curi, Sebastian and Melchior, Silvan and Berkenkamp, Felix and Krause, Andreas},
	month = jul,
	year = {2020},
	note = {ISSN: 2640-3498},
	keywords = {variational-inference, gaussian-process, state-space-model},
	pages = {147--157},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/DAEIJZM2/Curi et al. - 2020 - Structured Variational Inference in Partially Obse.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/9W4SGF7V/curi20a.html:text/html},
}

@inproceedings{berkenkampSafe2016,
	title = {Safe controller optimization for quadrotors with {Gaussian} processes},
	doi = {10.1109/ICRA.2016.7487170},
	abstract = {One of the most fundamental problems when designing controllers for dynamic systems is the tuning of the controller parameters. Typically, a model of the system is used to obtain an initial controller, but ultimately the controller parameters must be tuned manually on the real system to achieve the best performance. To avoid this manual tuning step, methods from machine learning, such as Bayesian optimization, have been used. However, as these methods evaluate different controller parameters on the real system, safety-critical system failures may happen. In this paper, we overcome this problem by applying, for the first time, a recently developed safe optimization algorithm, SafeOpt, to the problem of automatic controller parameter tuning. Given an initial, low-performance controller, SafeOpt automatically optimizes the parameters of a control law while guaranteeing safety. It models the underlying performance measure as a Gaussian process and only explores new controller parameters whose performance lies above a safe performance threshold with high probability. Experimental results on a quadrotor vehicle indicate that the proposed method enables fast, automatic, and safe optimization of controller parameters without human intervention.},
	booktitle = {International {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Berkenkamp, F. and Schoellig, A. P. and Krause, A.},
	month = may,
	year = {2016},
	keywords = {dynamic systems, Gaussian process, Gaussian processes, probability, Safety, safe-exploration, quadcopter, aircraft control, automatic controller parameter tuning, Bayes methods, Bayesian optimization, Computational modeling, control system synthesis, controller design, helicopters, learning systems, low-performance controller, machine learning, Noise measurement, optimisation, Optimization, parameter estimation, performance threshold, quadrotor vehicle, safe controller optimization, safe optimization algorithm, SafeOpt, safety-critical system failure, Tuning, Vehicle dynamics},
	pages = {491--496},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/P55WHW8T/7487170.html:text/html;Submitted Version:/Users/aidanscannell/Zotero/storage/ZNFMVIUZ/Berkenkamp et al. - 2016 - Safe controller optimization for quadrotors with G.pdf:application/pdf},
}

@inproceedings{curiEfficient2020,
	title = {Efficient {Model}-{Based} {Reinforcement} {Learning} through {Optimistic} {Policy} {Search} and {Planning}},
	url = {https://papers.nips.cc/paper/2020/file/a36b598abb934e4528412e5a2127b931-Paper.pdf},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Curi, Sebastian and Berkenkamp, Felix and Krause, Andreas},
	year = {2020},
	keywords = {model-based-reinforcement-learning, policy-search, planning},
	file = {NIPS Full Text PDF:/Users/aidanscannell/Zotero/storage/ID2FAF6Y/Mukherjee and Fine - 1995 - Asymptotics of Gradient-based Neural Network Train.pdf:application/pdf;NIPS Snapshot:/Users/aidanscannell/Zotero/storage/3WGIBLZ7/a36b598abb934e4528412e5a2127b931-Paper.html:text/html},
}

@inproceedings{trespMixtures2000a,
	title = {Mixtures of {Gaussian} {Processes}},
	volume = {13},
	url = {https://proceedings.neurips.cc/paper/2000/hash/9fdb62f932adf55af2c0e09e55861964-Abstract.html},
	abstract = {We introduce the mixture of Gaussian processes (MGP) model which is useful for applications in which the optimal bandwidth of a map is input dependent. The MGP is derived from the mixture of experts model and can also be used for modeling general conditional probability densities. We discuss how Gaussian processes - in particular in form of Gaussian process classification, the support vector machine and the MGP model--can be used for quantifying the dependencies in graphical models.},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tresp, Volker},
	year = {2000},
	pages = {654--660},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/VD6CC6WK/Tresp - 2000 - Mixtures of Gaussian Processes.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/4XNN58JI/9fdb62f932adf55af2c0e09e55861964-Abstract.html:text/html},
}

@inproceedings{rasmussenInfinite2001,
	title = {Infinite {Mixtures} of {Gaussian} {Process} {Experts}},
	volume = {14},
	url = {https://papers.nips.cc/paper/2001/hash/9afefc52942cb83c7c1f14b2139b09ba-Abstract.html},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rasmussen, Carl and Ghahramani, Zoubin},
	year = {2001},
	pages = {881--888},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/K55Z2K8S/Rasmussen and Ghahramani - 2001 - Infinite Mixtures of Gaussian Process Experts.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/X9FGAZH2/9afefc52942cb83c7c1f14b2139b09ba-Abstract.html:text/html},
}

@article{deisenrothGaussian2015,
	title = {Gaussian {Processes} for {Data}-{Efficient} {Learning} in {Robotics} and {Control}},
	volume = {37},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2013.218},
	abstract = {Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this paper, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Deisenroth, M. P. and Fox, D. and Rasmussen, C. E.},
	month = feb,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data models, Gaussian processes, Predictive models, Uncertainty, robotics, Computational modeling, Approximation methods, Bayesian inference, control, Policy search, Probabilistic logic, reinforcement learning, Robots},
	pages = {408--423},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/ETJFH6IF/6654139.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/EKCHX8MG/Deisenroth et al. - 2015 - Gaussian Processes for Data-Efficient Learning in .pdf:application/pdf},
}

@inproceedings{salimbeniDoubly2017,
	title = {Doubly {Stochastic} {Variational} {Inference} for {Deep} {Gaussian} {Processes}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/8208974663db80265e9bfe7b222dcb18-Abstract.html},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Salimbeni, Hugh and Deisenroth, Marc},
	year = {2017},
	keywords = {gaussian-processes, variational-inference, deep-gaussian-processes},
	pages = {4588--4599},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/6IZTGNS9/Salimbeni and Deisenroth - 2017 - Doubly Stochastic Variational Inference for Deep G.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/QV5N9ZPA/8208974663db80265e9bfe7b222dcb18-Abstract.html:text/html},
}

@phdthesis{deisenrothEfficient2010a,
	title = {Efficient {Reinforcement} {Learning} using {Gaussian} {Processes}},
	language = {en},
	author = {Deisenroth, Marc Peter},
	year = {2010},
	keywords = {gaussian-processes, model-based-rl},
	file = {Deisenroth - Efficient Reinforcement Learning using Gaussian Pr.pdf:/Users/aidanscannell/Zotero/storage/8XMSD6YK/Deisenroth - Efficient Reinforcement Learning using Gaussian Pr.pdf:application/pdf},
}

@inproceedings{kamtheDataEfficient2018,
	title = {Data-{Efficient} {Reinforcement} {Learning} with {Probabilistic} {Model} {Predictive} {Control}},
	url = {http://proceedings.mlr.press/v84/kamthe18a.html},
	abstract = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms...},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Kamthe, Sanket and Deisenroth, Marc},
	month = mar,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {mpc, model-based-rl},
	pages = {1701--1710},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/E96H6LF8/Kamthe and Deisenroth - 2018 - Data-Efficient Reinforcement Learning with Probabi.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/UGM5DYC9/kamthe18a.html:text/html},
}

@inproceedings{eleftheriadisIdentification2017,
	title = {Identification of {Gaussian} {Process} {State} {Space} {Models}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Eleftheriadis, Stefanos and Nicholson, Tom and Deisenroth, Marc and Hensman, James},
	year = {2017},
	pages = {5309--5319},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/5YAC3Z5R/Eleftheriadis et al. - 2017 - Identification of Gaussian Process State Space Mod.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/Y3DYE9YC/1006ff12c465532f8c574aeaa4461b16-Abstract.html:text/html;Snapshot:/Users/aidanscannell/Zotero/storage/EKVSHK87/1006ff12c465532f8c574aeaa4461b16-Abstract.html:text/html},
}

@inproceedings{doerrProbabilistic2018,
	title = {Probabilistic {Recurrent} {State}-{Space} {Models}},
	abstract = {State-space models (SSMs) are a highly expressive model class for learning patterns in time series data and for system identification. Deterministic versions of SSMs (e.g. LSTMs) proved extremely successful in modeling complex time series data. Fully probabilistic SSMs, however, are often found hard to train, even for smaller problems. To overcome this limitation, we propose a novel model formulation and a scalable training algorithm based on doubly stochastic variational inference and Gaussian processes. In contrast to existing work, the proposed variational approximation allows one to fully capture the latent state temporal correlations. These correlations are the key to robust training. The effectiveness of the proposed PR-SSM is evaluated on a set of real-world benchmark datasets in comparison to state-of-the-art probabilistic model learning methods. Scalability and robustness are demonstrated on a high dimensional problem.},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Doerr, A. and Daniel, C. and Schiegg, Martin and Nguyen-Tuong, D. and Schaal, S. and Toussaint, Marie-Eve and Trimpe, Sebastian},
	year = {2018},
	keywords = {gaussian-processes, variational-inference, state-space-model},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/JZL52M9S/Doerr et al. - 2018 - Probabilistic Recurrent State-Space Models.pdf:application/pdf},
}

@inproceedings{wilsonEfficiently2020,
	title = {Efficiently {Sampling} {Functions} from {Gaussian} {Process} {Posteriors}},
	volume = {37},
	url = {http://arxiv.org/abs/2002.09309},
	abstract = {Gaussian processes are the gold standard for many real-world modeling problems, especially in cases where a model's success hinges upon its ability to faithfully represent predictive uncertainty. These problems typically exist as parts of larger frameworks, wherein quantities of interest are ultimately defined by integrating over posterior distributions. These quantities are frequently intractable, motivating the use of Monte Carlo methods. Despite substantial progress in scaling up Gaussian processes to large training sets, methods for accurately generating draws from their posterior distributions still scale cubically in the number of test locations. We identify a decomposition of Gaussian processes that naturally lends itself to scalable sampling by separating out the prior from the data. Building off of this factorization, we propose an easy-to-use and general-purpose approach for fast posterior sampling, which seamlessly pairs with sparse approximations to afford scalability both during training and at test time. In a series of experiments designed to test competing sampling schemes' statistical properties and practical ramifications, we demonstrate how decoupled sample paths accurately represent Gaussian process posteriors at a fraction of the usual cost.},
	urldate = {2020-11-26},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wilson, James T. and Borovitskiy, Viacheslav and Terenin, Alexander and Mostowsky, Peter and Deisenroth, Marc Peter},
	year = {2020},
	note = {arXiv: 2002.09309},
	keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/LDX7GNL2/Wilson et al. - 2020 - Efficiently Sampling Functions from Gaussian Proce.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/WCQHCJV4/2002.html:text/html},
}

@inproceedings{ustyuzhaninovCompositional2020,
	title = {Compositional uncertainty in deep {Gaussian} processes},
	url = {http://arxiv.org/abs/1909.07698},
	abstract = {Gaussian processes (GPs) are nonparametric priors over functions. Fitting a GP implies computing a posterior distribution of functions consistent with the observed data. Similarly, deep Gaussian processes (DGPs) should allow us to compute a posterior distribution of compositions of multiple functions giving rise to the observations. However, exact Bayesian inference is intractable for DGPs, motivating the use of various approximations. We show that the application of simplifying mean-field assumptions across the hierarchy leads to the layers of a DGP collapsing to near-deterministic transformations. We argue that such an inference scheme is suboptimal, not taking advantage of the potential of the model to discover the compositional structure in the data. To address this issue, we examine alternative variational inference schemes allowing for dependencies across different layers and discuss their advantages and limitations.},
	urldate = {2020-12-01},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Ustyuzhaninov, Ivan and Kazlauskaite, Ieva and Kaiser, Markus and Bodin, Erik and Campbell, Neill D. F. and Ek, Carl Henrik},
	year = {2020},
	note = {arXiv: 1909.07698},
	keywords = {variational-inference, gaussian-process, deep-gaussian-processes, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 17 pages},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/6RMC67MW/Ustyuzhaninov et al. - 2020 - Compositional uncertainty in deep Gaussian process.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/XHN32FUW/1909.html:text/html},
}

@inproceedings{ustyuzhaninovMonotonic2020,
	title = {Monotonic {Gaussian} {Process} {Flow}},
	volume = {23},
	url = {http://arxiv.org/abs/1905.12930},
	abstract = {We propose a new framework for imposing monotonicity constraints in a Bayesian nonparametric setting based on numerical solutions of stochastic differential equations. We derive a nonparametric model of monotonic functions that allows for interpretable priors and principled quantification of hierarchical uncertainty. We demonstrate the efficacy of the proposed model by providing competitive results to other probabilistic monotonic models on a number of benchmark functions. In addition, we consider the utility of a monotonic random process as a part of a hierarchical probabilistic model; we examine the task of temporal alignment of time-series data where it is beneficial to use a monotonic random process in order to preserve the uncertainty in the temporal warpings.},
	urldate = {2020-12-01},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Ustyuzhaninov, Ivan and Kazlauskaite, Ieva and Ek, Carl Henrik and Campbell, Neill D. F.},
	year = {2020},
	note = {arXiv: 1905.12930},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Proceedings of the 23nd International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 (14 pages)},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/YF8MS6ER/Ustyuzhaninov et al. - 2020 - Monotonic Gaussian Process Flow.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/ZSC3RQJ7/1905.html:text/html},
}

@article{kaiserBayesian2020,
	title = {Bayesian decomposition of multi-modal dynamical systems for reinforcement learning},
	volume = {416},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231220305026},
	doi = {10.1016/j.neucom.2019.12.132},
	abstract = {In this paper, we present a model-based reinforcement learning system where the transition model is treated in a Bayesian manner. The approach naturally lends itself to exploit expert knowledge by introducing priors to impose structure on the underlying learning task. The additional information introduced to the system means that we can learn from small amounts of data, recover an interpretable model and, importantly, provide predictions with an associated uncertainty. To show the benefits of the approach, we use a challenging data set where the dynamics of the underlying system exhibit both operational phase shifts and heteroscedastic noise. Comparing our model to NFQ and BNN+LV, we show how our approach yields human-interpretable insight about the underlying dynamics while also increasing data-efficiency.},
	language = {en},
	urldate = {2020-12-01},
	journal = {Neurocomputing},
	author = {Kaiser, Markus and Otte, Clemens and Runkler, Thomas A. and Ek, Carl Henrik},
	month = nov,
	year = {2020},
	keywords = {Gaussian processes, Bayesian machine learning, Data-efficiency, Hierarchical gaussian processes, Model-based reinforcement learning, Reinforcement learning, Stochastic policy search},
	pages = {352--359},
	file = {ScienceDirect Full Text PDF:/Users/aidanscannell/Zotero/storage/HR34GBG6/Kaiser et al. - 2020 - Bayesian decomposition of multi-modal dynamical sy.pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/EJE7Q7YF/S0925231220305026.html:text/html},
}

@inproceedings{kaiserData2019,
	title = {Data {Association} with {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1810.07158},
	abstract = {The data association problem is concerned with separating data coming from different generating processes, for example when data come from different data sources, contain significant noise, or exhibit multimodality. We present a fully Bayesian approach to this problem. Our model is capable of simultaneously solving the data association problem and the induced supervised learning problems. Underpinning our approach is the use of Gaussian process priors to encode the structure of both the data and the data associations. We present an efficient learning scheme based on doubly stochastic variational inference and discuss how it can be applied to deep Gaussian process priors.},
	urldate = {2020-12-01},
	booktitle = {Joint {European} {Conference} on {Machine} {Learning} and {Knowledge} {Discovery} in {Databases}},
	author = {Kaiser, Markus and Otte, Clemens and Runkler, Thomas and Ek, Carl Henrik},
	year = {2019},
	note = {arXiv: 1810.07158},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/2QN8CB7D/Kaiser et al. - 2019 - Data Association with Gaussian Processes.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/PPAGW99R/1810.html:text/html},
}

@inproceedings{kaiserBayesian2018,
	title = {Bayesian {Alignments} of {Warped} {Multi}-{Output} {Gaussian} {Processes}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/2974788b53f73e7950e8aa49f3a306db-Abstract.html},
	language = {en},
	urldate = {2020-12-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kaiser, Markus and Otte, Clemens and Runkler, Thomas and Ek, Carl Henrik},
	year = {2018},
	pages = {6995--7004},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/JMCYFREV/Kaiser et al. - 2018 - Bayesian Alignments of Warped Multi-Output Gaussia.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/RM276IC3/2974788b53f73e7950e8aa49f3a306db-Abstract.html:text/html},
}

@inproceedings{belznerBayesian2017b,
	address = {Buenos Aires, Argentina},
	series = {{SEsCPS} '17},
	title = {Bayesian verification under model uncertainty},
	isbn = {978-1-5386-4043-2},
	abstract = {Machine learning enables systems to build and update domain models based on runtime observations. In this paper, we study statistical model checking and runtime verification for systems with this ability. Two challenges arise: (1) Models built from limited runtime data yield uncertainty to be dealt with. (2) There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose such a definition of subjective satisfaction based on recently introduced satisfaction functions. We also propose the BV algorithm as a Bayesian solution to runtime verification of subjective satisfaction under model uncertainty. BV provides user-definable stochastic bounds for type I and II errors. We discuss empirical results of a toy experiment.},
	urldate = {2020-12-13},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Software} {Engineering} for {Smart} {Cyber}-{Physical} {Systems}},
	publisher = {IEEE Press},
	author = {Belzner, Lenz and Gabor, Thomas},
	month = may,
	year = {2017},
	pages = {10--13},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/32XVLZ4U/Belzner and Gabor - 2017 - Bayesian Verification under Model Uncertainty.pdf:application/pdf},
}

@inproceedings{haesaerts.Datadriven2015,
	title = {Data-driven and model-based verification: a {Bayesian} identification approach},
	shorttitle = {Data-driven and model-based verification},
	url = {https://research.tue.nl/nl/publications/datadriven-and-modelbased-verification-a-bayesian-identification-approach(3a2adf32-32d2-4fe8-9f69-e2fc8142ccce).html},
	doi = {10.1109/cdc.2015.7403295},
	abstract = {This work develops a measurement-driven and model-based formal verification approach, applicable to systems with partly unknown dynamics. We provide a principled method, grounded on reachability analysis and on Bayesian inference, to compute the confidence that a physical system driven by external inputs and accessed under noisy measurements, verifies a temporal logic property. A case study is discussed, where we investigate the bounded- and unbounded-time safety of a partly unknown linear time invariant system.},
	language = {en},
	urldate = {2020-12-13},
	booktitle = {Proceedings of the {Conference} on {Decision} and {Control}, 15-18 {December} 2015, {Osaka}, {Japan}},
	publisher = {Institute of Electrical and Electronics Engineers},
	author = {{Haesaert, S.} and {van den Hof, P.M.J.} and {Abate, A.} and {Control Systems} and {Dynamic Networks: Data-Driven Modeling and Control} and {Formal methods for control of cyber-physical systems}},
	month = sep,
	year = {2015},
	pages = {6830--6835},
	file = {Submitted Version:/Users/aidanscannell/Zotero/storage/DML32MZN/Haesaert, S. et al. - 2015 - Data-driven and model-based verification a Bayesi.pdf:application/pdf},
}

@article{bellemareAutonomous2020,
	title = {Autonomous navigation of stratospheric balloons using reinforcement learning},
	volume = {588},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2939-8},
	doi = {10.1038/s41586-020-2939-8},
	abstract = {Efficiently navigating a superpressure balloon in the stratosphere1 requires the integration of a multitude of cues, such as wind speed and solar elevation, and the process is complicated by forecast errors and sparse wind measurements. Coupled with the need to make decisions in real time, these factors rule out the use of conventional control techniques2,3. Here we describe the use of reinforcement learning4,5 to create a high-performing flight controller. Our algorithm uses data augmentation6,7 and a self-correcting design to overcome the key technical challenge of reinforcement learning from imperfect data, which has proved to be a major obstacle to its application to physical systems8. We deployed our controller to station Loon superpressure balloons at multiple locations across the globe, including a 39-day controlled experiment over the Pacific Ocean. Analyses show that the controller outperforms Loon’s previous algorithm and is robust to the natural diversity in stratospheric winds. These results demonstrate that reinforcement learning is an effective solution to real-world autonomous control problems in which neither conventional methods nor human intervention suffice, offering clues about what may be needed to create artificially intelligent agents that continuously interact with real, dynamic environments.},
	language = {en},
	number = {7836},
	urldate = {2020-12-15},
	journal = {Nature},
	author = {Bellemare, Marc G. and Candido, Salvatore and Castro, Pablo Samuel and Gong, Jun and Machado, Marlos C. and Moitra, Subhodeep and Ponda, Sameera S. and Wang, Ziyu},
	month = dec,
	year = {2020},
	note = {Number: 7836
Publisher: Nature Publishing Group},
	pages = {77--82},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/698C2AZ7/Bellemare et al. - 2020 - Autonomous navigation of stratospheric balloons us.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/5CXZNZ75/s41586-020-2939-8.html:text/html},
}

@inproceedings{gonzalezGLASSES2015,
	title = {{GLASSES}: {Relieving} {The} {Myopia} {Of} {Bayesian} {Optimisation}},
	shorttitle = {{GLASSES}},
	url = {http://arxiv.org/abs/1510.06299},
	abstract = {We present GLASSES: Global optimisation with Look-Ahead through Stochastic Simulation and Expected-loss Search. The majority of global optimisation approaches in use are myopic, in only considering the impact of the next function value; the non-myopic approaches that do exist are able to consider only a handful of future evaluations. Our novel algorithm, GLASSES, permits the consideration of dozens of evaluations into the future. This is done by approximating the ideal look-ahead loss function, which is expensive to evaluate, by a cheaper alternative in which the future steps of the algorithm are simulated beforehand. An Expectation Propagation algorithm is used to compute the expected value of the loss.We show that the far-horizon planning thus enabled leads to substantive performance gains in empirical tests.},
	urldate = {2021-01-21},
	booktitle = {Proceedings of the {Nineteenth} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}},
	author = {González, Javier and Osborne, Michael and Lawrence, Neil D.},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.06299
version: 1},
	keywords = {Statistics - Machine Learning},
	annote = {Comment: 12 pages, 9 figures},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/QFYN2BAH/González et al. - 2015 - GLASSES Relieving The Myopia Of Bayesian Optimisa.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/LVQ7D5AY/1510.html:text/html},
}

@inproceedings{hafnerLearning2019,
	title = {Learning {Latent} {Dynamics} for {Planning} from {Pixels}},
	url = {http://proceedings.mlr.press/v97/hafner19a.html},
	abstract = {Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the w...},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {2555--2565},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/36E8ER7E/Hafner et al. - 2019 - Learning Latent Dynamics for Planning from Pixels.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/HB9RTJLG/hafner19a.html:text/html},
}

@inproceedings{parmasPIPPS2018,
	title = {{PIPPS}: {Flexible} {Model}-{Based} {Policy} {Search} {Robust} to the {Curse} of {Chaos}},
	shorttitle = {{PIPPS}},
	url = {http://proceedings.mlr.press/v80/parmas18a.html},
	abstract = {Previously, the exploding gradient problem has been explained to be central in deep learning and model-based reinforcement learning, because it causes numerical issues and instability in optimizati...},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {4065--4074},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/XGUGY4P8/Parmas et al. - 2018 - PIPPS Flexible Model-Based Policy Search Robust t.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/QXP623BU/parmas18a.html:text/html},
}

@article{houthooftVIME2017,
	title = {{VIME}: {Variational} {Information} {Maximizing} {Exploration}},
	shorttitle = {{VIME}},
	url = {http://arxiv.org/abs/1605.09674},
	abstract = {Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.},
	urldate = {2021-02-02},
	journal = {arXiv:1605.09674 [cs, stat]},
	author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	month = jan,
	year = {2017},
	note = {arXiv: 1605.09674},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: Published in Advances in Neural Information Processing Systems 29 (NIPS), pages 1109-1117},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/JLYSSI3G/Houthooft et al. - 2017 - VIME Variational Information Maximizing Explorati.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/PTVKGQUZ/1605.html:text/html},
}

@inproceedings{hensmanScalable2015,
	title = {Scalable {Variational} {Gaussian} {Process} {Classification}},
	url = {http://proceedings.mlr.press/v38/hensman15.html},
	abstract = {Gaussian process classification is a popular method with a number of appealing properties. We show how to scale the model within a variational inducing point framework, out-performing the state of ...},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {Artificial {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Hensman, James and Matthews, Alexander and Ghahramani, Zoubin},
	month = feb,
	year = {2015},
	note = {ISSN: 1938-7228},
	pages = {351--360},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/9HDJVCTJ/Hensman et al. - 2015 - Scalable Variational Gaussian Process Classificati.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/FD6TZPEI/hensman15.html:text/html},
}

@article{quinonero-candelaUnifying2005,
	title = {A {Unifying} {View} of {Sparse} {Approximate} {Gaussian} {Process} {Regression}},
	volume = {6},
	url = {http://jmlr.org/papers/v6/quinonero-candela05a.html},
	abstract = {We provide a new unifying view, including all existing proper probabilistic
  sparse approximations for Gaussian process regression. Our approach relies on
  expressing the effective prior which the methods are using. This
  allows new insights to be gained, and highlights the relationship between
  existing methods. It also allows for a clear theoretically justified ranking
  of the closeness of the known approximations to the corresponding full GPs.
  Finally we point directly to designs of new better sparse approximations,
  combining the best of the existing strategies, within attractive
  computational constraints.},
	number = {65},
	urldate = {2021-02-02},
	journal = {Journal of Machine Learning Research},
	author = {Quiñonero-Candela, Joaquin and Rasmussen, Carl Edward},
	year = {2005},
	pages = {1939--1959},
	file = {Fulltext PDF:/Users/aidanscannell/Zotero/storage/H6HSMVQS/Quiñonero-Candela and Rasmussen - 2005 - A Unifying View of Sparse Approximate Gaussian Pro.pdf:application/pdf},
}

@book{rasmussenGaussian2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	language = {en},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Gaussian processes, Data processing, Machine learning, Mathematical models},
	file = {Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:/Users/aidanscannell/Zotero/storage/9KYKSDXH/Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:application/pdf},
}

@inproceedings{titsiasVariational2009,
	title = {Variational {Learning} of {Inducing} {Variables} in {Sparse} {Gaussian} {Processes}},
	url = {http://proceedings.mlr.press/v5/titsias09a.html},
	abstract = {Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximat...},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {Artificial {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Titsias, Michalis},
	month = apr,
	year = {2009},
	note = {ISSN: 1938-7228},
	pages = {567--574},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/DLNKJ5XI/Titsias - 2009 - Variational Learning of Inducing Variables in Spar.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/LBI9US9A/titsias09a.html:text/html},
}

@inproceedings{bauerUnderstanding2016,
	title = {Understanding {Probabilistic} {Sparse} {Gaussian} {Process} {Approximations}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/7250eb93b3c18cc9daa29cf58af7a004-Abstract.html},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bauer, Matthias and van der Wilk, Mark and Rasmussen, Carl Edward},
	year = {2016},
	pages = {1533--1541},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/PQCYYMZR/Bauer et al. - 2016 - Understanding Probabilistic Sparse Gaussian Proces.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/FWFIKGWQ/7250eb93b3c18cc9daa29cf58af7a004-Abstract.html:text/html},
}

@inproceedings{snelsonSparse2005a,
	title = {Sparse {Gaussian} {Processes} using {Pseudo}-inputs},
	abstract = {We present a new Gaussian process (GP) regression model whose co-variance is parameterized by the the locations of M pseudo-input points, which we learn by a gradient based optimization. We take M ≪ N, where N is the number of real data points, and hence obtain a sparse regression method which has O(M2N) training cost and O(M2) prediction cost per test case. We also find hyperparameters of the covariance function in the same joint optimization. The method can be viewed as a Bayesian regression model with particular input dependent noise. The method turns out to be closely related to several other sparse GP approaches, and we discuss the relation in detail. We finally demonstrate its performance on some large data sets, and make a direct comparison to other sparse GP methods. We show that our method can match full GP performance with small M, i.e. very sparse solutions, and it significantly outperforms other approaches in this regime.},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Snelson, Edward and Ghahramani, Zoubin},
	year = {2005},
	file = {Snelson and Ghahramani - Sparse Gaussian Processes using Pseudo-inputs.pdf:/Users/aidanscannell/Zotero/storage/J54QN2B7/Snelson and Ghahramani - Sparse Gaussian Processes using Pseudo-inputs.pdf:application/pdf},
}

@article{bettsSurvey1998,
	title = {Survey of {Numerical} {Methods} for {Trajectory} {Optimization}},
	volume = {21},
	url = {https://arc.aiaa.org/doi/10.2514/2.4231},
	doi = {10.2514/2.4231},
	number = {2},
	urldate = {2021-02-08},
	journal = {Journal of Guidance, Control, and Dynamics},
	author = {Betts, John T.},
	month = mar,
	year = {1998},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	pages = {193--207},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/UX6QF98W/2.html:text/html;Submitted Version:/Users/aidanscannell/Zotero/storage/AVKV9FTT/Betts - 1998 - Survey of Numerical Methods for Trajectory Optimiz.pdf:application/pdf},
}

@inproceedings{seegerFast2003,
	title = {Fast forward selection to speed up sparse gaussian process regression},
	abstract = {We present a method for the sparse greedy approximation of Bayesian Gaussian process regression, featuring a novel heuristic for very fast forward selection. Our method is essentially as fast as an equivalent one which selects the “support” patterns at random, yet it can outperform random selection on hard curve fitting tasks. More importantly, it leads to a sufficiently stable approximation of the log marginal likelihood of the training data, which can be optimised to adjust a large number of hyperparameters automatically. We demonstrate the model selection capabilities of the algorithm in a range of experiments. In line with the development of our method, we present a simple view on sparse approximations for GP models and their underlying assumptions and show relations to other methods.},
	booktitle = {Proceedings of the {Ninth} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}},
	author = {Seeger, Matthias and Williams, Christopher K. I. and Lawrence, Neil D.},
	year = {2003},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/HUFUTERH/Seeger et al. - 2003 - Fast forward selection to speed up sparse gaussian.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/F3LX47VP/summary.html:text/html},
}

@article{leibfriedTutorial2021,
	title = {A {Tutorial} on {Sparse} {Gaussian} {Processes} and {Variational} {Inference}},
	url = {http://arxiv.org/abs/2012.13962},
	abstract = {Gaussian processes (GPs) provide a framework for Bayesian inference that can offer principled uncertainty estimates for a large range of problems. For example, if we consider regression problems with Gaussian likelihoods, a GP model enjoys a posterior in closed form. However, identifying the posterior GP scales cubically with the number of training examples and requires to store all examples in memory. In order to overcome these obstacles, sparse GPs have been proposed that approximate the true posterior GP with pseudo-training examples. Importantly, the number of pseudo-training examples is user-defined and enables control over computational and memory complexity. In the general case, sparse GPs do not enjoy closed-form solutions and one has to resort to approximate inference. In this context, a convenient choice for approximate inference is variational inference (VI), where the problem of Bayesian inference is cast as an optimization problem -- namely, to maximize a lower bound of the log marginal likelihood. This paves the way for a powerful and versatile framework, where pseudo-training examples are treated as optimization arguments of the approximate posterior that are jointly identified together with hyperparameters of the generative model (i.e. prior and likelihood). The framework can naturally handle a wide scope of supervised learning problems, ranging from regression with heteroscedastic and non-Gaussian likelihoods to classification problems with discrete labels, but also multilabel problems. The purpose of this tutorial is to provide access to the basic matter for readers without prior knowledge in both GPs and VI. A proper exposition to the subject enables also access to more recent advances (like importance-weighted VI as well as inderdomain, multioutput and deep GPs) that can serve as an inspiration for new research ideas.},
	journal = {arXiv:2012.13962 [cs, stat]},
	author = {Leibfried, Felix and Dutordoir, Vincent and John, S. T. and Durrande, Nicolas},
	month = feb,
	year = {2021},
	note = {arXiv: 2012.13962},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/P96DJSJL/Leibfried et al. - 2021 - A Tutorial on Sparse Gaussian Processes and Variat.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/Z55ZREHB/2012.html:text/html},
}

@article{nguyenStochastic2018,
	title = {Stochastic variational hierarchical mixture of sparse {Gaussian} processes for regression},
	volume = {107},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-018-5721-5},
	doi = {10.1007/s10994-018-5721-5},
	abstract = {In this article, we propose a scalable Gaussian process (GP) regression method that combines the advantages of both global and local GP approximations through a two-layer hierarchical model using a variational inference framework. The upper layer consists of a global sparse GP to coarsely model the entire data set, whereas the lower layer comprises a mixture of sparse GP experts which exploit local information to learn a fine-grained model. A two-step variational inference algorithm is developed to learn the global GP, the GP experts and the gating network simultaneously. Stochastic optimization can be employed to allow the application of the model to large-scale problems. Experiments on a wide range of benchmark data sets demonstrate the flexibility, scalability and predictive power of the proposed method.},
	language = {en},
	number = {12},
	urldate = {2021-02-18},
	journal = {Machine Learning},
	author = {Nguyen, Thi Nhat Anh and Bouzerdoum, Abdesselam and Phung, Son Lam},
	month = dec,
	year = {2018},
	pages = {1947--1986},
	file = {Springer Full Text PDF:/Users/aidanscannell/Zotero/storage/LA4BFTY4/Nguyen et al. - 2018 - Stochastic variational hierarchical mixture of spa.pdf:application/pdf},
}

@book{carmoRiemannian1992,
	series = {Mathematics: {Theory} \& {Applications}},
	title = {Riemannian {Geometry}},
	isbn = {978-0-8176-3490-2},
	url = {https://www.springer.com/gp/book/9780817634902},
	abstract = {Riemannian Geometry is an expanded edition of a highly acclaimed and successful textbook (originally published in Portuguese) for first-year graduate students in mathematics and physics. The author's treatment goes very directly to the basic language of Riemannian geometry and immediately presents some of its most fundamental theorems. It is elementary, assuming only a modest background from readers, making it suitable for a wide variety of students and course structures. Its selection of topics has been deemed "superb" by teachers who have used the text. A significant feature of the book is its powerful and revealing structure, beginning simply with the definition of a differentiable manifold and ending with one of the most important results in Riemannian geometry, a proof of the Sphere Theorem. The text abounds with basic definitions and theorems, examples, applications, and numerous exercises to test the student's understanding and extend knowledge and insight into the subject. Instructors and students alike will find the work to be a significant contribution to this highly applicable and stimulating subject.},
	language = {en},
	urldate = {2021-02-18},
	publisher = {Birkhäuser Basel},
	author = {Carmo, Manfredo do},
	year = {1992},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/VAALLD2J/9780817634902.html:text/html},
}

@article{rossPseudospectral2004,
	title = {Pseudospectral methods for optimal motion planning of differentially flat systems},
	volume = {49},
	issn = {1558-2523},
	doi = {10.1109/TAC.2004.832972},
	abstract = {The article presents some preliminary results on combining two new ideas from nonlinear control theory and dynamic optimization. We show that the computational framework facilitated by pseudospectral methods applies quite naturally and easily to Fliess' implicit state variable representation of dynamical systems. The optimal motion planning problem for differentially flat systems is equivalent to a classic Bolza problem of the calculus of variations. We exploit the notion that derivatives of flat outputs given in terms of Lagrange polynomials at Legendre-Gauss-Lobatto points can be quickly computed using pseudospectral differentiation matrices. Additionally, the Legendre pseudospectral method approximates integrals by Gauss-type quadrature rules. The application of this method to the two-dimensional crane model reveals how differential flatness may be readily exploited.},
	number = {8},
	journal = {IEEE Transactions on Automatic Control},
	author = {Ross, I. M. and Fahroo, F.},
	month = aug,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {optimisation, Asymptotic stability, Automatic control, Bolza problem, Control systems, Control theory, differentially flat systems, differentiation, dynamic optimization, dynamical systems, Fliess implicit state variable representation, Gauss-type quadrature rules, integration, Lagrange polynomials, Lagrange pseudospectral methods, Legendre-Gauss-Lobatto points, Lyapunov method, matrix algebra, nonlinear control systems, nonlinear control theory, Nonlinear systems, optimal control, optimal motion planning, Optimization methods, path planning, polynomials, pseudospectral differentiation matrices, Rivers, Time varying systems, time-varying systems, two-dimensional crane model, variational calculus, variational techniques},
	pages = {1410--1413},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/BN6XJXPM/1323189.html:text/html;Submitted Version:/Users/aidanscannell/Zotero/storage/TY8D8LGT/Ross and Fahroo - 2004 - Pseudospectral methods for optimal motion planning.pdf:application/pdf},
}

@inproceedings{milamNew2000,
	title = {A new computational approach to real-time trajectory generation for constrained mechanical systems},
	volume = {1},
	doi = {10.1109/CDC.2000.912875},
	abstract = {Preliminary results of a new computational approach to generate aggressive trajectories in real-time for constrained mechanical systems are presented. The algorithm is based on a combination of the nonlinear control theory, spline theory, and sequential quadratic programming. It is demonstrated that real-time trajectory generation for constrained mechanical systems is possible by mapping the problem to one of finding trajectory curves in a lower dimensional space. Performance of the algorithm is compared with existing optimal trajectory generation techniques. Numerical results are reported using the nonlinear trajectory generation software package.},
	booktitle = {Proceedings of the 39th {IEEE} {Conference} on {Decision} and {Control}},
	publisher = {IEEE},
	author = {Milam, M. B. and Mushambi, K. and Murray, R. M.},
	month = dec,
	year = {2000},
	note = {ISSN: 0191-2216},
	keywords = {Trajectory, optimisation, Control systems, nonlinear control systems, optimal control, Adaptive control, constrained mechanical systems, control system analysis computing, Databases, Mechanical systems, nonlinear control, Nonlinear control systems, Optimal control, quadratic programming, Real time systems, real-time systems, sequential quadratic programming, spline, splines (mathematics), Stability, Target tracking, tracking, trajectory generation},
	pages = {845--851},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/C2U83PCJ/912875.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/NUTQUYQH/Milam et al. - 2000 - A new computational approach to real-time trajecto.pdf:application/pdf},
}

@article{kellyIntroduction2017,
	title = {An {Introduction} to {Trajectory} {Optimization}: {How} to {Do} {Your} {Own} {Direct} {Collocation}},
	volume = {59},
	issn = {0036-1445, 1095-7200},
	shorttitle = {An {Introduction} to {Trajectory} {Optimization}},
	url = {https://epubs.siam.org/doi/10.1137/16M1062569},
	doi = {10.1137/16M1062569},
	abstract = {This paper is an introductory tutorial for numerical trajectory optimization with a focus on direct collocation methods. These methods are relatively simple to understand and eﬀectively solve a wide variety of trajectory optimization problems. Throughout the paper we illustrate each new set of concepts by working through a sequence of four example problems. We start by using trapezoidal collocation to solve a simple one-dimensional toy problem and work up to using Hermite–Simpson collocation to compute the optimal gait for a bipedal walking robot. Along the way, we cover basic debugging strategies and guidelines for posing well-behaved optimization problems. The paper concludes with a short overview of other methods for trajectory optimization. We also provide an electronic supplement that contains well-documented MATLAB code for all examples and methods presented. Our primary goal is to provide the reader with the resources necessary to understand and successfully implement their own direct collocation methods.},
	language = {en},
	number = {4},
	urldate = {2021-02-19},
	journal = {SIAM Review},
	author = {Kelly, Matthew},
	month = jan,
	year = {2017},
	pages = {849--904},
	file = {Kelly - 2017 - An Introduction to Trajectory Optimization How to.pdf:/Users/aidanscannell/Zotero/storage/ERJYVAY8/Kelly - 2017 - An Introduction to Trajectory Optimization How to.pdf:application/pdf},
}

@inproceedings{fahrooDirect2000,
	title = {Direct trajectory optimization by a {Chebyshev} pseudospectral method},
	volume = {6},
	doi = {10.1109/ACC.2000.876945},
	abstract = {A Chebyshev pseudospectral method is presented in this paper for directly solving a generic optimal control problem with state and control constraints. This method employs Nth degree Lagrange polynomial approximations for the state and control variables with the values of these variables at the Chebyshev-Gauss-Lobatto (CGL) points as the expansion coefficients. This process yields a nonlinear programming problem (NLP) with the state and control values at the CGL points as unknown NLP parameters. Numerical examples demonstrate this method yields more accurate results than those obtained from the traditional collocation methods.},
	booktitle = {Proceedings of the 2000 {American} {Control} {Conference}},
	author = {Fahroo, F. and Ross, I. M.},
	month = jun,
	year = {2000},
	note = {ISSN: 0743-1619},
	keywords = {Gaussian processes, optimal control, Optimization methods, path planning, Optimal control, CGL points, Chebyshev approximation, Chebyshev pseudospectral method, Chebyshev-Gauss-Lobatto points, control constraints, Cost function, Differential equations, direct trajectory optimization, high-degree Lagrange polynomial approximations, Lagrangian functions, Mathematics, Nonlinear equations, nonlinear programming, nonlinear programming problem, optimal control problem, Polynomials, spectral analysis, state constraints, unknown NLP parameters},
	pages = {3860--3864},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/CQN2YN69/876945.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/9RXR2VPM/Fahroo and Ross - 2000 - Direct trajectory optimization by a Chebyshev pseu.pdf:application/pdf},
}

@article{andersonNonCentral1946,
	title = {The {Non}-{Central} {Wishart} {Distribution} and {Certain} {Problems} of {Multivariate} {Statistics}},
	volume = {17},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2236082},
	abstract = {The non-central Wishart distribution is the joint distribution of the sums of squares and cross-products of the deviations from the sample means when the observations arise from a set of normal multivariate populations with constant covariance matrix but expected values that vary from observation to observation. The characteristic function for this distribution is obtained from the distribution of the observations (Theorem 1). By using the characteristic functions it is shown that the convolution of several non-central Wishart distributions is another non-central Wishart distribution (Theorem 2). A simple integral representation of the distribution in the general case is given (Theorem 3). The integrand is a function of the roots of a determinantal equation involving the matrix of sums of squares and cross-products of deviations of observations and the matrix of sums of squares and cross-products of deviations of corresponding expected values. The knowledge of the non-central Wishart distribution is applied to two general problems of multivariate normal statistics. The moments of the generalized variance, which is the determinant of sums of squares and cross-products multiplied by a constant, are given for the cases of the expected values of the variates lying on a line (Theorem 4) and lying on a plane (Theorem 5). The likelihood ratio criterion for testing linear hypotheses can be expressed as the ratio of two determinants or as a symmetric function of the roots of a determinantal equation. In either case there is involved a matrix having a Wishart distribution and another matrix independently distributed such that the sum of these two matrices has a non-central Wishart distribution. When the null hypothesis is not true the moments of this criterion are given in the non-central planar case (Theorem 6).},
	number = {4},
	urldate = {2021-02-23},
	journal = {The Annals of Mathematical Statistics},
	author = {Anderson, T. W.},
	year = {1946},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {409--431},
	file = {Anderson - 1946 - The Non-Central Wishart Distribution and Certain P.pdf:/Users/aidanscannell/Zotero/storage/Y35MHNGC/Anderson - 1946 - The Non-Central Wishart Distribution and Certain P.pdf:application/pdf},
}

@article{hoffmanStochastic2013,
	title = {Stochastic {Variational} {Inference}},
	volume = {14},
	url = {http://jmlr.org/papers/v14/hoffman13a.html},
	abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
	number = {4},
	urldate = {2021-03-02},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D. and Blei, David M. and Wang, Chong and Paisley, John},
	year = {2013},
	pages = {1303--1347},
	file = {Fulltext PDF:/Users/aidanscannell/Zotero/storage/9MQ4G5JD/Hoffman et al. - 2013 - Stochastic Variational Inference.pdf:application/pdf},
}

@book{stengelStochastic1986,
	title = {Stochastic optimal control: theory and application},
	isbn = {978-0-471-86462-2},
	shorttitle = {Stochastic optimal control},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Stengel, Robert F.},
	year = {1986},
}

@article{gargUnified2010,
	title = {A unified framework for the numerical solution of optimal control problems using pseudospectral methods},
	volume = {46},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/S0005109810002980},
	doi = {10.1016/j.automatica.2010.06.048},
	abstract = {A unified framework is presented for the numerical solution of optimal control problems using collocation at Legendre–Gauss (LG), Legendre–Gauss–Radau (LGR), and Legendre–Gauss–Lobatto (LGL) points. It is shown that the LG and LGR differentiation matrices are rectangular and full rank whereas the LGL differentiation matrix is square and singular. Consequently, the LG and LGR schemes can be expressed equivalently in either differential or integral form, while the LGL differential and integral forms are not equivalent. Transformations are developed that relate the Lagrange multipliers of the discrete nonlinear programming problem to the costates of the continuous optimal control problem. The LG and LGR discrete costate systems are full rank while the LGL discrete costate system is rank-deficient. The LGL costate approximation is found to have an error that oscillates about the true solution and this error is shown by example to be due to the null space in the LGL discrete costate system. An example is considered to assess the accuracy and features of each collocation scheme.},
	language = {en},
	number = {11},
	urldate = {2021-03-02},
	journal = {Automatica},
	author = {Garg, Divya and Patterson, Michael and Hager, William W. and Rao, Anil V. and Benson, David A. and Huntington, Geoffrey T.},
	month = nov,
	year = {2010},
	keywords = {Optimal control, Nonlinear programming, Pseudospectral methods},
	pages = {1843--1851},
	file = {ScienceDirect Full Text PDF:/Users/aidanscannell/Zotero/storage/T9YSQEZM/Garg et al. - 2010 - A unified framework for the numerical solution of .pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/NSLYL44L/S0005109810002980.html:text/html},
}

@article{vonstrykDirect1992,
	title = {Direct and {Indirect} {Methods} for {Trajectory} {Optimization}},
	volume = {37},
	doi = {10.1007/BF02071065},
	abstract = {This paper gives a brief list of commonly used direct and indirect efficient methods for the numerical solution of optimal control problems. To improve the low accuracy of the direct methods and to increase the convergence areas of the indirect methods we suggest a hybrid approach. For this a special direct collocation method is presented. In a hybrid approach this direct method can be used in combination with multiple shooting. Numerical examples illustrate the direct method and the hybrid approach.},
	journal = {Annals of Operations Research},
	author = {Von Stryk, Oskar and Bulirsch, Roland},
	month = dec,
	year = {1992},
	pages = {357--373},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/D99SU5KA/Von Stryk and Bulirsch - 1992 - Direct and Indirect Methods for Trajectory Optimiz.pdf:application/pdf},
}

@book{freemanRobust1996,
	series = {Modern {Birkhäuser} {Classics}},
	title = {Robust {Nonlinear} {Control} {Design}: {State}-{Space} and {Lyapunov} {Techniques}},
	isbn = {978-0-8176-4758-2},
	shorttitle = {Robust {Nonlinear} {Control} {Design}},
	url = {https://www.springer.com/gp/book/9780817647582},
	abstract = {This book presents advances in the theory and design of robust nonlinear control systems. In the first part of the book, the authors provide a unified framework for state-space and Lyapunov techniques by combining concepts from set-valued analysis, Lyapunov stability theory, and game theory. Within this unified framework, the authors then develop a variety of control design methods suitable for systems described by low-order nonlinear ordinary differential equations. Emphasis is placed on global controller designs, that is, designs for the entire region of model validity. Because linear theory deals well with local system behavior (except for critical cases in which Jacobian linearization fails), the authors focus on achieving robustness and performance for large deviations from a given operation condition. The purpose of the book is to summarize Lyapunov design techniques for nonlinear systems and to raise important issues concerning large-signal robustness and performance. The authors have been the first to address some of these issues, and they report their findings in this text. For example, they identify two potential sources of excessive control effort in Lyapunov design techniques and show how such effort can be greatly reduced. The researcher who wishes to enter the field of robust nonlinear control could use this book as a source of new research topics. For those already active in the field, the book may serve as a reference to a recent body of significant work. Finally, the design engineer faced with a nonlinear control problem will benefit from the techniques presented here. "The text is practically self-contained. The authors offer all necessary definitions and give a comprehensive introduction. Only the most basic knowledge of nonlinear analysis and design tools is required, including Lyapunov stability theory and optimal control. The authors also provide a review of set-valued maps for those readers who are not familiar with set-valued analysis. The book is intended for graduate students and researchers in control theory, serving as both a summary of recent results and a source of new research problems. In the opinion of this reviewer the authors do succeed in attaining these objectives." — Mathematical Reviews},
	language = {en},
	urldate = {2021-03-02},
	publisher = {Birkhäuser Basel},
	author = {Freeman, Randy and Kokotovic, Petar V.},
	year = {1996},
	doi = {10.1007/978-0-8176-4759-9},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/GXRPXABP/9780817647582.html:text/html},
}

@book{freemanRobust2009,
	title = {Robust {Nonlinear} {Control} {Design}: {State}-{Space} and {Lyapunov} {Techniques}},
	isbn = {978-0-8176-4759-9},
	shorttitle = {Robust {Nonlinear} {Control} {Design}},
	abstract = {This book presents advances in the theory and design of robust nonlinear control systems. In the first part of the book, the authors provide a unified framework for state-space and Lyapunov techniques by combining concepts from set-valued analysis, Lyapunov stability theory, and game theory. Within this unified framework, the authors then develop a variety of control design methods suitable for systems described by low-order nonlinear ordinary differential equations. Emphasis is placed on global controller designs, that is, designs for the entire region of model validity. Because linear theory deals well with local system behavior (except for critical cases in which Jacobian linearization fails), the authors focus on achieving robustness and performance for large deviations from a given operation condition. The purpose of the book is to summarize Lyapunov design techniques for nonlinear systems and to raise important issues concerning large-signal robustness and performance. The authors have been the first to address some of these issues, and they report their findings in this text. For example, they identify two potential sources of excessive control effort in Lyapunov design techniques and show how such effort can be greatly reduced. The researcher who wishes to enter the field of robust nonlinear control could use this book as a source of new research topics. For those already active in the field, the book may serve as a reference to a recent body of significant work. Finally, the design engineer faced with a nonlinear control problem will benefit from the techniques presented here. "The text is practically self-contained. The authors offer all necessary definitions and give a comprehensive introduction. Only the most basic knowledge of nonlinear analysis and design tools is required, including Lyapunov stability theory and optimal control. The authors also provide a review of set-valued maps for those readers who are not familiar with set-valued analysis. The book is intended for graduate students and researchers in control theory, serving as both a summary of recent results and a source of new research problems. In the opinion of this reviewer the authors do succeed in attaining these objectives." — Mathematical Reviews},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Freeman, Randy A. and Kokotovic, Petar V.},
	month = may,
	year = {2009},
	note = {Google-Books-ID: vb\_cBwAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / General, Mathematics / Differential Equations / General, Mathematics / General, Mathematics / Linear \& Nonlinear Programming, Mathematics / Mathematical Analysis, Science / System Theory},
}

@book{ljungSystem1999,
	edition = {2nd},
	series = {Prentice {Hall} {Information} and {System} {Sciences} {Series}},
	title = {System {Identification}: {Theory} for the {User}},
	publisher = {Pearson},
	author = {Ljung, Lennart},
	year = {1999},
}

@inproceedings{schneiderExploiting1996,
	title = {Exploiting {Model} {Uncertainty} {Estimates} for {Safe} {Dynamic} {Control} {Learning}},
	volume = {9},
	abstract = {Model learning combined with dynamic programming has been shown to be effective for learning control of continuous state dynamic systems. The simplest method assumes the learned model is correct and applies dynamic programming to it, but many approximators provide uncertainty estimates on the fit. How can they be exploited? This paper addresses the case where the system must be prevented from having catastrophic failures during learning. We propose a new algorithm adapted from the dual control literature and use Bayesian locally weighted regression models with dynamic programming. A common reinforcement learning assumption is that aggressive exploration should be encouraged. This paper addresses the converse case in which the system has to reign in exploration. The algorithm is illustrated on a 4 dimensional simulated control problem.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Schneider, J.},
	year = {1996},
	pages = {1047--1053},
}

@inproceedings{cutlerEfficient2015,
	title = {Efficient reinforcement learning for robots using informative simulated priors},
	doi = {10.1109/ICRA.2015.7139550},
	abstract = {Autonomous learning through interaction with the physical world is a promising approach to designing controllers and decision-making policies for robots. Unfortunately, learning on robots is often difficult due to the large number of samples needed for many learning algorithms. Simulators are one way to decrease the samples needed from the robot by incorporating prior knowledge of the dynamics into the learning algorithm. In this paper we present a novel method for transferring data from a simulator to a robot, using simulated data as a prior for real-world learning. A Bayesian nonparametric prior is learned from a potentially black-box simulator. The mean of this function is used as a prior for the Probabilistic Inference for Learning Control (PILCO) algorithm. The simulated prior improves the convergence rate and performance of PILCO by directing the policy search in areas of the state-space that have not yet been observed by the robot. Simulated and hardware results show the benefits of using the prior knowledge in the learning framework.},
	publisher = {IEEE},
	author = {Cutler, M. and How, J. P.},
	month = may,
	year = {2015},
	note = {ISSN: 1050-4729},
	keywords = {Data models, Gaussian processes, learning (artificial intelligence), Bayes methods, controller design, learning systems, Robots, autonomous learning, Bayesian nonparametric prior, black-box simulator, convergence rate, decision-making policy, Hardware, Heuristic algorithms, informative simulated priors, Mathematical model, nonparametric statistics, PILCO algorithm, Prediction algorithms, probabilistic inference for learning control algorithm, reinforcement learning algorithm, robots},
	pages = {2605--2612},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/8868YSWR/7139550.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/8TMVDYFN/Cutler and How - 2015 - Efficient reinforcement learning for robots using .pdf:application/pdf},
}

@inproceedings{panProbabilistic2014,
	title = {Probabilistic {Differential} {Dynamic} {Programming}},
	volume = {27},
	abstract = {We present a data-driven, probabilistic trajectory optimization framework for systems with unknown dynamics, called Probabilistic Differential Dynamic Programming (PDDP). PDDP takes into account uncertainty explicitly for dynamics models using Gaussian processes (GPs). Based on the second-order local approximation of the value function, PDDP performs Dynamic Programming around a nominal trajectory in Gaussian belief spaces. Different from typical gradientbased policy search methods, PDDP does not require a policy parameterization and learns a locally optimal, time-varying control policy. We demonstrate the effectiveness and efﬁciency of the proposed algorithm using two nontrivial tasks. Compared with the classical DDP and a state-of-the-art GP-based policy search method, PDDP offers a superior combination of data-efﬁciency, learning speed, and applicability.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pan, Yunpeng and Theodorou, Evangelos},
	year = {2014},
	pages = {1907--1915},
	file = {Pan and Theodorou - Probabilistic Differential Dynamic Programming.pdf:/Users/aidanscannell/Zotero/storage/D4XA2UIZ/Pan and Theodorou - Probabilistic Differential Dynamic Programming.pdf:application/pdf},
}

@inproceedings{deisenrothPILCO2011,
	title = {{PILCO}: {A} {Model}-{Based} and {Data}-{Efficient} {Approach} to {Policy} {Search}.},
	volume = {28},
	shorttitle = {{PILCO}},
	abstract = {In this paper, we introduce PILCO, a practical, data-efficient model-based policy search method. PILCO reduces model bias, one of the key problems of model-based reinforcement learning, in a principled way. By learning a probabilistic dynamics model and explicitly incorporating model uncertainty into long-term planning, PILCO can cope with very little data and facilitates learning from scratch in only a few trials. Policy evaluation is performed in closed form using state-of-the-art approximate inference. Furthermore, policy gradients are computed analytically for policy improvement. We report unprecedented learning efficiency on challenging and high-dimensional control tasks.},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Deisenroth, Marc and Rasmussen, Carl},
	month = jan,
	year = {2011},
	pages = {465--472},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/9Y6HDXE3/Deisenroth and Rasmussen - 2011 - PILCO A Model-Based and Data-Efficient Approach t.pdf:application/pdf},
}

@inproceedings{mckinnonLearning2017,
	title = {Learning multimodal models for robot dynamics online with a mixture of {Gaussian} process experts},
	doi = {10.1109/ICRA.2017.7989041},
	abstract = {For decades, robots have been essential allies alongside humans in controlled industrial environments like heavy manufacturing facilities. However, without the guidance of a trusted human operator to shepherd a robot safely through a wide range of conditions, they have been barred from the complex, ever changing environments that we live in from day to day. Safe learning control has emerged as a promising way to start bridging algorithms based on first principles to complex real-world scenarios by using data to adapt, and improve performance over time. Safe learning methods rely on a good estimate of the robot dynamics and of the bounds on modelling error in order to be effective. Current methods focus on either a single adaptive model, or a fixed, known set of models for the robot dynamics. This limits them to static or slowly changing environments. This paper presents a method using Gaussian Processes in a Dirichlet Process mixture model to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experience from an arbitrary number of previously visited operating conditions, and to automatically learn a new model when a new and distinct operating condition is encountered. This approach improves the robustness of existing Gaussian Process-based models to large changes in dynamics that do not have to be specified ahead of time.},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {McKinnon, C. D. and Schoellig, A. P.},
	month = may,
	year = {2017},
	note = {tex.ids= mckinnonLearning2017b},
	keywords = {Data models, Gaussian processes, learning (artificial intelligence), Safety, Robots, Heuristic algorithms, Aerodynamics, controlled industrial environment, Dirichlet process mixture model, human operator, mixture models, mixture of Gaussian process experts, multimodal model learning, robot dynamics, System dynamics},
	pages = {322--328},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/9JHYDX6T/7989041.html:text/html;IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/Y27Y938R/7989041.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/6XLZFBSE/McKinnon and Schoellig - 2017 - Learning multimodal models for robot dynamics onli.pdf:application/pdf},
}

@article{moerlandLearning2017,
	title = {Learning {Multimodal} {Transition} {Dynamics} for {Model}-{Based} {Reinforcement} {Learning}},
	abstract = {In this paper we study how to learn stochastic, multimodal transition dynamics in reinforcement learning (RL) tasks. We focus on evaluating transition function estimation, while we defer planning over this model to future work. Stochasticity is a fundamental property of many task environments. However, discriminative function approximators have difficulty estimating multimodal stochasticity. In contrast, deep generative models do capture complex high-dimensional outcome distributions. First we discuss why, amongst such models, conditional variational inference (VI) is theoretically most appealing for model-based RL. Subsequently, we compare different VI models on their ability to learn complex stochasticity on simulated functions, as well as on a typical RL gridworld with multimodal dynamics. Results show VI successfully predicts multimodal outcomes, but also robustly ignores these for deterministic parts of the transition dynamics. In summary, we show a robust method to learn multimodal transitions using function approximation, which is a key preliminary for model-based RL in stochastic domains.},
	journal = {arXiv:1705.00470},
	author = {Moerland, Thomas M. and Broekens, Joost and Jonker, Catholijn M.},
	month = aug,
	year = {2017},
	note = {arXiv: 1705.00470},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Scaling Up Reinforcement Learning (SURL) Workshop @ European Machine Learning Conference (ECML)},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/8BGSA3IV/Moerland et al. - 2017 - Learning Multimodal Transition Dynamics for Model-.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/6PAULW4H/1705.html:text/html},
}

@article{herzallahPMAC2020,
	title = {{PMAC}: probabilistic multimodality adaptive control},
	volume = {93},
	issn = {0020-7179},
	shorttitle = {{PMAC}},
	url = {https://doi.org/10.1080/00207179.2018.1523567},
	doi = {10.1080/00207179.2018.1523567},
	abstract = {This paper develops a probabilistic multimodal adaptive control approach for systems that are characterised by temporal multimodality where the system dynamics are subject to abrupt mode switching at arbitrary times. In this framework, the control objective is redefined such that it utilises the complete probability distribution of the system dynamics. The derived probabilistic control law is thus of a dual type that incorporates the functional uncertainty of the controlled system. A multi-modal density model with prediction error-dependent mixing coefficients is introduced to effect the mode switching. This approach can deal with arbitrary noise distributions, nonlinear plant dynamics and arbitrary mode switching. For the affine systems focussed upon for illustration in this paper the approach has global stability. The theoretical architecture constructs are verified by validation on a simulation example.},
	number = {7},
	urldate = {2021-03-02},
	journal = {International Journal of Control},
	author = {Herzallah, Randa and Lowe, David},
	month = jul,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207179.2018.1523567},
	keywords = {Multi-modal density model, multiobjective probabilistic control, operator Riccati equation, probabilistic multimodal adaptive control, switching control, temporal multimodality},
	pages = {1637--1650},
	file = {Accepted Version:/Users/aidanscannell/Zotero/storage/SKYIVLD6/Herzallah and Lowe - 2020 - PMAC probabilistic multimodality adaptive control.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/4Z7VFDS9/00207179.2018.html:text/html},
}

@inproceedings{arvanitidisLatent2018a,
	title = {Latent {Space} {Oddity}: on the {Curvature} of {Deep} {Generative} {Models}},
	shorttitle = {Latent {Space} {Oddity}},
	url = {https://openreview.net/forum?id=SJzRZ-WCZ},
	abstract = {Deep generative models provide a systematic way to learn nonlinear data distributions through a set of latent variables and a nonlinear "generator" function that maps latent points into the input...},
	language = {en},
	urldate = {2021-03-08},
	author = {Arvanitidis, Georgios and Hansen, Lars Kai and Hauberg, Søren},
	month = feb,
	year = {2018},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/8Z7PQAKV/Arvanitidis et al. - 2018 - Latent Space Oddity on the Curvature of Deep Gene.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/UJFPWJWH/forum.html:text/html},
}

@article{nguyenModel2020,
	title = {Model {Predictive} {Control} for {Micro} {Aerial} {Vehicles}: {A} {Survey}},
	shorttitle = {Model {Predictive} {Control} for {Micro} {Aerial} {Vehicles}},
	url = {http://arxiv.org/abs/2011.11104},
	abstract = {This paper presents a review of the design and application of model predictive control strategies for Micro Aerial Vehicles and specifically multirotor configurations such as quadrotors. The diverse set of works in the domain is organized based on the control law being optimized over linear or nonlinear dynamics, the integration of state and input constraints, possible fault-tolerant design, if reinforcement learning methods have been utilized and if the controller refers to free-flight or other tasks such as physical interaction or load transportation. A selected set of comparison results are also presented and serve to provide insight for the selection between linear and nonlinear schemes, the tuning of the prediction horizon, the importance of disturbance observer-based offset-free tracking and the intrinsic robustness of such methods to parameter uncertainty. Furthermore, an overview of recent research trends on the combined application of modern deep reinforcement learning techniques and model predictive control for multirotor vehicles is presented. Finally, this review concludes with explicit discussion regarding selected open-source software packages that deliver off-the-shelf model predictive control functionality applicable to a wide variety of Micro Aerial Vehicle configurations.},
	urldate = {2021-03-23},
	journal = {arXiv:2011.11104 [cs]},
	author = {Nguyen, Huan and Kamel, Mina and Alexis, Kostas and Siegwart, Roland},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.11104},
	keywords = {Computer Science - Robotics},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/SASSEGG9/Nguyen et al. - 2020 - Model Predictive Control for Micro Aerial Vehicles.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/P8F5EY7X/2011.html:text/html},
}

@inproceedings{wilkinsonSparse2021,
	title = {Sparse {Algorithms} for {Markovian} {Gaussian} {Processes}},
	abstract = {Approximate Bayesian inference methods that scale to very large datasets are crucial in leveraging probabilistic models for real-world time series. Sparse Markovian Gaussian processes combine the use of inducing variables with efficient Kalman filter-like recursions, resulting in algorithms whose computational and memory requirements scale linearly in the number of inducing points, whilst also enabling parallel parameter updates and stochastic optimisation. Under this paradigm, we derive a general site-based approach to approximate inference, whereby we approximate the non-Gaussian likelihood with local Gaussian terms, called sites. Our approach results in a suite of novel sparse extensions to algorithms from both the machine learning and signal processing literature, including variational inference, expectation propagation, and the classical nonlinear Kalman smoothers. The derived methods are suited to large time series, and we also demonstrate their applicability to spatio-temporal data, where the model has separate inducing points in both time and space.},
	booktitle = {{AISTATS}},
	author = {Wilkinson, William J. and Solin, A. and Adam, Vincent},
	year = {2021},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/VJTCCV38/Wilkinson et al. - 2021 - Sparse Algorithms for Markovian Gaussian Processes.pdf:application/pdf},
}

@article{jacobsAdaptive1991,
	title = {Adaptive {Mixtures} of {Local} {Experts}},
	volume = {3},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1991.3.1.79},
	doi = {10.1162/neco.1991.3.1.79},
	abstract = {We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.},
	number = {1},
	urldate = {2021-04-27},
	journal = {Neural Computation},
	author = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
	month = mar,
	year = {1991},
	pages = {79--87},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/85CFX29F/Jacobs et al. - 1991 - Adaptive Mixtures of Local Experts.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/EYULD8LB/Adaptive-Mixtures-of-Local-Experts.html:text/html},
}

@article{yukselTwenty2012,
	title = {Twenty {Years} of {Mixture} of {Experts}},
	volume = {23},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2012.2200299},
	abstract = {In this paper, we provide a comprehensive survey of the mixture of experts (ME). We discuss the fundamental models for regression and classification and also their training with the expectation-maximization algorithm. We follow the discussion with improvements to the ME model and focus particularly on the mixtures of Gaussian process experts. We provide a review of the literature for other training methods, such as the alternative localized ME training, and cover the variational learning of ME in detail. In addition, we describe the model selection literature which encompasses finding the optimum number of experts, as well as the depth of the tree. We present the advances in ME in the classification area and present some issues concerning the classification model. We list the statistical properties of ME, discuss how the model has been modified over the years, compare ME to some popular algorithms, and list several applications. We conclude our survey with future directions and provide a list of publicly available datasets and a list of publicly available software that implement ME. Finally, we provide examples for regression and classification. We believe that the study described in this paper will provide quick access to the relevant literature for researchers and practitioners who would like to improve or use ME, and that it will stimulate further studies in ME.},
	number = {8},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Yuksel, Seniha Esen and Wilson, Joseph N. and Gader, Paul D.},
	month = aug,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Data models, Gaussian processes, mixture of Gaussian process experts, Applications, Bayesian, Bayesian methods, classification, comparison, Decision trees, Hidden Markov models, hierarchical mixture of experts (HME), regression, Regression analysis, statistical properties, Support vector machines, survey, variational},
	pages = {1177--1193},
	file = {IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/DBIQM3DW/Yuksel et al. - 2012 - Twenty Years of Mixture of Experts.pdf:application/pdf},
}

@inproceedings{scannellTrajectory2021,
	title = {Trajectory {Optimisation} in {Learned} {Multimodal} {Dynamical} {Systems} {Via} {Latent}-{ODE} {Collocation}},
	abstract = {This paper presents a two-stage method to perform trajectory optimisation in multimodal dynamical systems with unknown nonlinear stochastic transition dynamics. The method finds trajectories that remain in a preferred dynamics mode where possible and in regions of the transition dynamics model that have been observed and can be predicted confidently. The first stage leverages a Mixture of Gaussian Process Experts method to learn a predictive dynamics model from historical data. Importantly, this model learns a gating function that indicates the probability of being in a particular dynamics mode at a given state location. This gating function acts as a coordinate map for a latent Riemannian manifold on which shortest trajectories are solutions to our trajectory optimisation problem. Based on this intuition, the second stage formulates a geometric cost function, which it then implicitly minimises by projecting the trajectory optimisation onto the second-order geodesic ODE; a classic result of Riemannian geometry. A set of collocation constraints are derived that ensure trajectories are solutions to this ODE, implicitly solving the trajectory optimisation problem.},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Scannell, Aidan and Ek, Carl Henrik and Richards, Arthur},
	year = {2021},
	file = {Scannell et al. - 2021 - Trajectory Optimisation in Learned Multimodal Dyna.pdf:/Users/aidanscannell/Zotero/storage/JLG5TV8J/Scannell et al. - 2021 - Trajectory Optimisation in Learned Multimodal Dyna.pdf:application/pdf},
}

@inproceedings{salimbeniDeep2019,
	title = {Deep {Gaussian} {Processes} with {Importance}-{Weighted} {Variational} {Inference}},
	url = {http://proceedings.mlr.press/v97/salimbeni19a.html},
	abstract = {Deep Gaussian processes (DGPs) can model complex marginal densities as well as complex mappings. Non-Gaussian marginals are essential for modelling real-world data, and can be generated from the DG...},
	language = {en},
	urldate = {2021-05-12},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Salimbeni, Hugh and Dutordoir, Vincent and Hensman, James and Deisenroth, Marc},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {5589--5598},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/M3UC5GE3/Salimbeni et al. - 2019 - Deep Gaussian Processes with Importance-Weighted V.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/SN6XD5GN/salimbeni19a.html:text/html},
}

@inproceedings{eeckmanSigmoid1988,
	title = {The {Sigmoid} {Nonlinearity} in {Prepyriform} {Cortex}},
	url = {https://proceedings.neurips.cc/paper/1987/file/c9f0f895fb98ab9159f51fd0297e236d-Paper.pdf},
	urldate = {2021-05-12},
	booktitle = {Neural {Information} {Processing} {Systems}},
	publisher = {American Institute of Physics},
	author = {Eeckman, Frank},
	editor = {Anderson, D.},
	year = {1988},
	file = {NIPS Snapshot:/Users/aidanscannell/Zotero/storage/HXJWREHX/60a70bb05b08d6cd95deb3bdb750dce8-Abstract.html:text/html},
}

@inproceedings{lindingerMeanField2020,
	title = {Beyond the {Mean}-{Field}: {Structured} {Deep} {Gaussian} {Processes} {Improve} the {Predictive} {Uncertainties}},
	volume = {34},
	shorttitle = {Beyond the {Mean}-{Field}},
	abstract = {Deep Gaussian Processes learn probabilistic data representations for supervised learning by cascading multiple Gaussian Processes. While this model family promises flexible predictive distributions, exact inference is not tractable. Approximate inference techniques trade off the ability to closely resemble the posterior distribution against speed of convergence and computational efficiency. We propose a novel Gaussian variational family that allows for retaining covariances between latent processes while achieving fast convergence by marginalising out all global latent variables. After providing a proof of how this marginalisation can be done for general covariances, we restrict them to the ones we empirically found to be most important in order to also achieve computational efficiency. We provide an efficient implementation of our new approach and apply it to several regression benchmark datasets. We find that it yields more accurate predictive distributions, in particular for test data points that are distant from the training set.},
	booktitle = {Neural {Information} {Processing} {Systems}},
	author = {Lindinger, J. and Reeb, D. and Lippert, C. and Rakitsch, Barbara},
	year = {2020},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/5FZWEGC3/Lindinger et al. - 2020 - Beyond the Mean-Field Structured Deep Gaussian Pr.pdf:application/pdf},
}

@article{hennigEntropy2012,
	title = {Entropy {Search} for {Information}-{Efficient} {Global} {Optimization}},
	volume = {13},
	url = {http://jmlr.org/papers/v13/hennig12a.html},
	abstract = {Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation.},
	urldate = {2021-05-12},
	journal = {Journal of Machine Learning Research},
	author = {Hennig, Philipp and Schuler, Christian J.},
	year = {2012},
	pages = {1809--1837},
	file = {Fulltext PDF:/Users/aidanscannell/Zotero/storage/9HLX5WWP/Hennig and Schuler - 2012 - Entropy Search for Information-Efficient Global Op.pdf:application/pdf},
}

@article{shahriariTaking2016,
	title = {Taking the {Human} {Out} of the {Loop}: {A} {Review} of {Bayesian} {Optimization}},
	volume = {104},
	issn = {1558-2256},
	shorttitle = {Taking the {Human} {Out} of the {Loop}},
	abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and de Freitas, Nando},
	month = jan,
	year = {2016},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Bayes methods, Optimization, Big data, decision making, Decision making, design of experiments, Design of experiments, Genomes, genomic medicine, Linear programming, optimization, response surface methodology, Statistical analysis, statistical learning},
	pages = {148--175},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/XLYEGD6W/7352306.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/PX9FTIL2/Shahriari et al. - 2016 - Taking the Human Out of the Loop A Review of Baye.pdf:application/pdf},
}

@article{frohlichCautious2020,
	title = {Cautious {Bayesian} {Optimization} for {Efficient} and {Scalable} {Policy} {Search}},
	url = {/paper/Cautious-Bayesian-Optimization-for-Efficient-and-Fr%C3%B6hlich-Zeilinger/a6b6de5bcb1f609aed6d78d735622ab196455700},
	abstract = {Sample efficiency is one of the key factors when applying policy search to real-world problems. In recent years, Bayesian Optimization (BO) has become prominent in the field of robotics due to its sample efficiency and little prior knowledge needed. However, one drawback of BO is its poor performance on high-dimensional search spaces as it focuses on global search. In the policy search setting, local optimization is typically sufficient as initial policies are often available, e.g., via meta-learning, kinesthetic demonstrations or sim-to-real approaches. In this paper, we propose to constrain the policy search space to a sublevel-set of the Bayesian surrogate model\&\#39;s predictive uncertainty. This simple yet effective way of constraining the policy update enables BO to scale to high-dimensional spaces (\&gt;100) as well as reduces the risk of damaging the system. We demonstrate the effectiveness of our approach on a wide range of problems, including a motor skills task, adapting deep RL agents to new reward signals and a sim-to-real task for an inverted pendulum system.},
	language = {en},
	urldate = {2021-06-01},
	journal = {undefined},
	author = {Fröhlich, Lukas P. and Zeilinger, M. and Klenske, Edgar D.},
	year = {2020},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/A3PDNMG4/Fröhlich et al. - 2020 - Cautious Bayesian Optimization for Efficient and S.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/XRS7FCMY/a6b6de5bcb1f609aed6d78d735622ab196455700.html:text/html},
}

@inproceedings{jannerWhen2019,
	title = {When to {Trust} {Your} {Model}: {Model}-{Based} {Policy} {Optimization}},
	volume = {32},
	shorttitle = {When to {Trust} {Your} {Model}},
	url = {https://papers.nips.cc/paper/2019/hash/5faf461eff3099671ad63c6f3f094f7f-Abstract.html},
	language = {en},
	urldate = {2021-06-08},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
	year = {2019},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/CIG5RUDI/Janner et al. - 2019 - When to Trust Your Model Model-Based Policy Optim.pdf:application/pdf;mbpo_2019_supp.pdf:/Users/aidanscannell/Zotero/storage/Q5UZUMN8/mbpo_2019_supp.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/RUBIH4IV/5faf461eff3099671ad63c6f3f094f7f-Abstract.html:text/html},
}

@inproceedings{haarnojaSoft2018,
	title = {Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep} {Reinforcement} {Learning} with a {Stochastic} {Actor}},
	shorttitle = {Soft {Actor}-{Critic}},
	url = {http://proceedings.mlr.press/v80/haarnoja18b.html},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major cha...},
	language = {en},
	urldate = {2021-06-08},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {1861--1870},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/8HLAHQGR/Haarnoja et al. - 2018 - Soft Actor-Critic Off-Policy Maximum Entropy Deep.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/SVVM4X8W/haarnoja18b.html:text/html},
}

@article{matthewsGPflow2017,
	title = {\{{GP}\}flow: {A} \{{G}\}aussian process library using \{{T}\}ensor\{{F}\vphantom{\{}\}low\}},
	volume = {18},
	url = {http://jmlr.org/papers/v18/16-537.html},
	journal = {Journal of Machine Learning Research},
	author = {Matthews, Alexander G de G. and van der Wilk, Mark and Nickson, Tom and Fujii, Keisuke and Boukouvalas, Alexis and \{Le\{{\textbackslash}'o\}n-Villagr\{{\textbackslash}'a\}\}, Pablo and Ghahramani, Zoubin},
	month = apr,
	year = {2017},
	pages = {1--6},
}

@article{vanderwilkFramework2020,
	title = {A {Framework} for {Interdomain} and {Multioutput} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/2003.01115},
	abstract = {One obstacle to the use of Gaussian processes (GPs) in large-scale problems, and as a component in deep learning system, is the need for bespoke derivations and implementations for small variations in the model or inference. In order to improve the utility of GPs we need a modular system that allows rapid implementation and testing, as seen in the neural network community. We present a mathematical and software framework for scalable approximate inference in GPs, which combines interdomain approximations and multiple outputs. Our framework, implemented in GPflow, provides a unified interface for many existing multioutput models, as well as more recent convolutional structures. This simplifies the creation of deep models with GPs, and we hope that this work will encourage more interest in this approach.},
	urldate = {2021-06-15},
	journal = {arXiv:2003.01115 [cs, stat]},
	author = {van der Wilk, Mark and Dutordoir, Vincent and John, S. T. and Artemev, Artem and Adam, Vincent and Hensman, James},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.01115},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/C89VTA94/van der Wilk et al. - 2020 - A Framework for Interdomain and Multioutput Gaussi.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/EMGDFEFE/2003.html:text/html},
}

@misc{tensorflow2015-whitepaper,
	title = {{TensorFlow}: {Large}-scale machine learning on heterogeneous systems},
	url = {https://www.tensorflow.org/},
	author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dandelion and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year = {2015},
	annote = {Software available from tensorflow.org},
}

@article{GPflow2017,
	title = {{GPflow}: {A} {Gaussian} process library using {TensorFlow}},
	volume = {18},
	url = {http://jmlr.org/papers/v18/16-537.html},
	number = {40},
	journal = {Journal of Machine Learning Research},
	author = {Matthews, Alexander G. de G. and van der Wilk, Mark and Nickson, Tom and Fujii, Keisuke. and Boukouvalas, Alexis and León-Villagrá, Pablo and Ghahramani, Zoubin and Hensman, James},
	month = apr,
	year = {2017},
	pages = {1--6},
}

@inproceedings{levineGuided2013,
	title = {Guided {Policy} {Search}},
	url = {http://proceedings.mlr.press/v28/levine13.html},
	abstract = {Direct policy search can effectively scale to high-dimensional systems, but complex policies with hundreds of parameters often present a challenge for such methods, requiring numerous samples and o...},
	language = {en},
	urldate = {2021-06-17},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Levine, Sergey and Koltun, Vladlen},
	month = may,
	year = {2013},
	note = {ISSN: 1938-7228},
	pages = {1--9},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/3256U5QT/Levine and Koltun - 2013 - Guided Policy Search.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/VKD6XSNY/levine13.html:text/html},
}

@inproceedings{levineLearning2014,
	title = {Learning {Neural} {Network} {Policies} with {Guided} {Policy} {Search} under {Unknown} {Dynamics}},
	volume = {27},
	url = {https://papers.nips.cc/paper/2014/hash/6766aa2750c19aad2fa1b32f36ed4aee-Abstract.html},
	language = {en},
	urldate = {2021-06-17},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Levine, Sergey and Abbeel, Pieter},
	year = {2014},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/M7QQLZRR/Levine and Abbeel - 2014 - Learning Neural Network Policies with Guided Polic.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/RUZWAZFU/6766aa2750c19aad2fa1b32f36ed4aee-Abstract.html:text/html},
}

@inproceedings{berkenkampSafe2015,
	title = {Safe and robust learning control with {Gaussian} processes},
	doi = {10.1109/ECC.2015.7330913},
	abstract = {This paper introduces a learning-based robust control algorithm that provides robust stability and performance guarantees during learning. The approach uses Gaussian process (GP) regression based on data gathered during operation to update an initial model of the system and to gradually decrease the uncertainty related to this model. Embedding this data-based update scheme in a robust control framework guarantees stability during the learning process. Traditional robust control approaches have not considered online adaptation of the model and its uncertainty before. As a result, their controllers do not improve performance during operation. Typical machine learning algorithms that have achieved similar high-performance behavior by adapting the model and controller online do not provide the guarantees presented in this paper. In particular, this paper considers a stabilization task, linearizes the nonlinear, GP-based model around a desired operating point, and solves a convex optimization problem to obtain a linear robust controller. The resulting performance improvements due to the learning-based controller are demonstrated in experiments on a quadrotor vehicle.},
	booktitle = {2015 {European} {Control} {Conference} ({ECC})},
	author = {Berkenkamp, Felix and Schoellig, Angela P.},
	month = jul,
	year = {2015},
	keywords = {Data models, Uncertainty, Vehicle dynamics, Adaptation models, Robust control, Robustness, Stability analysis},
	pages = {2496--2501},
	file = {IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/BBDEMG6I/Berkenkamp and Schoellig - 2015 - Safe and robust learning control with Gaussian pro.pdf:application/pdf},
}

@inproceedings{wangSafe2018,
	title = {Safe {Learning} of {Quadrotor} {Dynamics} {Using} {Barrier} {Certificates}},
	doi = {10.1109/ICRA.2018.8460471},
	abstract = {To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. Simulation results are provided to demonstrate the effectiveness of the proposed approach.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Wang, Li and Theodorou, Evangelos A. and Egerstedt, Magnus},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Gaussian processes, Safety, Computational modeling, Control systems, System dynamics, Adaptation models, Lyapunov methods},
	pages = {2460--2465},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/UC3UH27R/8460471.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/SA29II8X/Wang et al. - 2018 - Safe Learning of Quadrotor Dynamics Using Barrier .pdf:application/pdf},
}

@inproceedings{jagtapControl2020,
	title = {Control {Barrier} {Functions} for {Unknown} {Nonlinear} {Systems} using {Gaussian} {Processes}*},
	volume = {59},
	doi = {10.1109/CDC42340.2020.9303847},
	abstract = {This paper focuses on the controller synthesis for unknown, nonlinear systems while ensuring safety constraints. Our approach consists of two steps, a learning step that uses Gaussian processes and a controller synthesis step that is based on control barrier functions. In the learning step, we use a data-driven approach utilizing Gaussian processes to learn the unknown control affine nonlinear dynamics together with a statistical bound on the accuracy of the learned model. In the second controller synthesis steps, we develop a systematic approach to compute control barrier functions that explicitly take into consideration the uncertainty of the learned model. The control barrier function not only results in a safe controller by construction but also provides a rigorous lower bound on the probability of satisfaction of the safety specification. Finally, we illustrate the effectiveness of the proposed results by synthesizing a safety controller for a jet engine example.},
	booktitle = {{IEEE} {Conference} on {Decision} and {Control}},
	publisher = {IEEE},
	author = {Jagtap, Pushpak and Pappas, George J. and Zamani, M.},
	year = {2020},
	file = {Submitted Version:/Users/aidanscannell/Zotero/storage/URCCH3KQ/Jagtap et al. - 2020 - Control Barrier Functions for Unknown Nonlinear Sy.pdf:application/pdf},
}

@inproceedings{deisenrothApproximate2008,
	title = {Approximate dynamic programming with {Gaussian} processes},
	doi = {10.1109/ACC.2008.4587201},
	abstract = {In general, it is difficult to determine an optimal closed-loop policy in nonlinear control problems with continuous-valued state and control domains. Hence, approximations are often inevitable. The standard method of discretizing states and controls suffers from the curse of dimensionality and strongly depends on the chosen temporal sampling rate. In this paper, we introduce Gaussian process dynamic programming (GPDP) and determine an approximate globally optimal closed-loop policy. In GPDP, value functions in the Bellman recursion of the dynamic programming algorithm are modeled using Gaussian processes. GPDP returns an optimal state- feedback for a finite set of states. Based on these outcomes, we learn a possibly discontinuous closed-loop policy on the entire state space by switching between two independently trained Gaussian processes. A binary classifier selects one Gaussian process to predict the optimal control signal. We show that GPDP is able to yield an almost optimal solution to an LQ problem using few sample points. Moreover, we successfully apply GPDP to the underpowered pendulum swing up, a complex nonlinear control problem.},
	booktitle = {American {Control} {Conference}},
	publisher = {IEEE},
	author = {Deisenroth, Marc P. and Peters, Jan and Rasmussen, Carl E.},
	month = jun,
	year = {2008},
	note = {ISSN: 2378-5861},
	keywords = {Gaussian processes, Machine learning, Control systems, Optimal control, Bayesian methods, Dynamic programming, Function approximation, Nonlinear dynamical systems, Sampling methods, State-space methods},
	pages = {4480--4485},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/EM9NQUE4/4587201.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/YT5V4IBN/Deisenroth et al. - 2008 - Approximate dynamic programming with Gaussian proc.pdf:application/pdf},
}

@article{deisenrothGaussian2009,
	series = {Advances in {Machine} {Learning} and {Computational} {Intelligence}},
	title = {Gaussian process dynamic programming},
	volume = {72},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231209000162},
	doi = {10.1016/j.neucom.2008.12.019},
	abstract = {Reinforcement learning (RL) and optimal control of systems with continuous states and actions require approximation techniques in most interesting cases. In this article, we introduce Gaussian process dynamic programming (GPDP), an approximate value function-based RL algorithm. We consider both a classic optimal control problem, where problem-specific prior knowledge is available, and a classic RL problem, where only very general priors can be used. For the classic optimal control problem, GPDP models the unknown value functions with Gaussian processes and generalizes dynamic programming to continuous-valued states and actions. For the RL problem, GPDP starts from a given initial state and explores the state space using Bayesian active learning. To design a fast learner, available data have to be used efficiently. Hence, we propose to learn probabilistic models of the a priori unknown transition dynamics and the value functions on the fly. In both cases, we successfully apply the resulting continuous-valued controllers to the under-actuated pendulum swing up and analyze the performances of the suggested algorithms. It turns out that GPDP uses data very efficiently and can be applied to problems, where classic dynamic programming would be cumbersome.},
	language = {en},
	number = {7},
	urldate = {2021-06-18},
	journal = {Neurocomputing},
	author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Peters, Jan},
	month = mar,
	year = {2009},
	keywords = {Gaussian processes, Reinforcement learning, Optimal control, Dynamic programming, Bayesian active learning, Policy learning},
	pages = {1508--1524},
	file = {ScienceDirect Full Text PDF:/Users/aidanscannell/Zotero/storage/WSCK8AP2/Deisenroth et al. - 2009 - Gaussian process dynamic programming.pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/LC9VDCYH/S0925231209000162.html:text/html},
}

@inproceedings{vinogradskaStability2016,
	title = {Stability of {Controllers} for {Gaussian} {Process} {Forward} {Models}},
	url = {http://proceedings.mlr.press/v48/vinogradska16.html},
	abstract = {Learning control has become an appealing alternative to the derivation of control laws based on classic control theory. However, a major shortcoming of learning control is the lack of performance g...},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Vinogradska, Julia and Bischoff, Bastian and Nguyen-Tuong, Duy and Romer, Anne and Schmidt, Henner and Peters, Jan},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	pages = {545--554},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/ZXXMUJ9K/Vinogradska et al. - 2016 - Stability of Controllers for Gaussian Process Forw.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/685IQFF8/vinogradska16.html:text/html},
}

@inproceedings{doerrOptimizing2017,
	title = {Optimizing {Long}-term {Predictions} for {Model}-based {Policy} {Search}},
	url = {http://proceedings.mlr.press/v78/doerr17a.html},
	abstract = {We propose a novel long-term optimization criterion to improve the robustness of model-based reinforcement learning in real-world scenarios. Learning a dynamics model to derive a solution promises...},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {Conference on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Doerr, Andreas and Daniel, CHristian and Nguyen-Tuong, Duy and Marco, Alonso and Schaal, Stefan and Marc, Toussaint and Trimpe, Sebastian},
	month = oct,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {227--238},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/T23MBV4T/Doerr et al. - 2017 - Optimizing Long-term Predictions for Model-based P.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/TUM2S5EH/doerr17a.html:text/html},
}

@article{hewingCautious2020,
	title = {Cautious {Model} {Predictive} {Control} {Using} {Gaussian} {Process} {Regression}},
	volume = {28},
	issn = {1558-0865},
	doi = {10.1109/TCST.2019.2949757},
	abstract = {Gaussian process (GP) regression has been widely used in supervised machine learning due to its flexibility and inherent ability to describe uncertainty in function estimation. In the context of control, it is seeing increasing use for modeling of nonlinear dynamical systems from data, as it allows the direct assessment of residual model uncertainty. We present a model predictive control (MPC) approach that integrates a nominal system with an additive nonlinear part of the dynamics modeled as a GP. We describe a principled way of formulating the chance-constrained MPC problem, which takes into account residual uncertainties provided by the GP model to enable cautious control. Using additional approximations for efficient computation, we finally demonstrate the approach in a simulation example, as well as in a hardware implementation for autonomous racing of remote-controlled race cars with fast sampling times of 20 ms, highlighting improvements with regard to both performance and safety over a nominal controller.},
	number = {6},
	journal = {IEEE Transactions on Control Systems Technology},
	author = {Hewing, Lukas and Kabzan, Juraj and Zeilinger, Melanie N.},
	month = nov,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Control Systems Technology},
	keywords = {Data models, Gaussian processes, Kernel, Predictive models, Uncertainty, Computational modeling, Autonomous racing, Gaussian processes (GPs), learning-based control, model learning, model predictive control (MPC), Predictive control},
	pages = {2736--2743},
	file = {Accepted Version:/Users/aidanscannell/Zotero/storage/5NP9WH9Y/Hewing et al. - 2020 - Cautious Model Predictive Control Using Gaussian P.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/5LZ4583Z/8909368.html:text/html},
}

@inproceedings{polymenakosSafe2019,
	address = {Richland, SC},
	series = {{AAMAS} '19},
	title = {Safe {Policy} {Search} {Using} {Gaussian} {Process} {Models}},
	isbn = {978-1-4503-6309-9},
	abstract = {We propose a method to optimise the parameters of a policy which will be used to safely perform a given task in a data-efficient manner. We train a Gaussian process model to capture the system dynamics, based on the PILCO framework. The model has useful analytic properties, which allow closed form computation of error gradients and the probability of violating given state space constraints. Even during training, only policies that are deemed safe are implemented on the real system, minimising the risk of catastrophic failure.},
	urldate = {2021-06-18},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Autonomous} {Agents} and {MultiAgent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Polymenakos, Kyriakos and Abate, Alessandro and Roberts, Stephen},
	month = may,
	year = {2019},
	note = {tex.ids= polymenakosSafe2019a},
	keywords = {gaussian processes, model-based reinforcement learning, safety critical systems},
	pages = {1565--1573},
	file = {Polymenakos et al. - 2019 - Safe Policy Search Using Gaussian Process Models.pdf:/Users/aidanscannell/Zotero/storage/LEEH5ULN/Polymenakos et al. - 2019 - Safe Policy Search Using Gaussian Process Models.pdf:application/pdf},
}

@article{sasakiVariational2021,
	title = {Variational policy search using sparse {Gaussian} process priors for learning multimodal optimal actions},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608021002422},
	doi = {10.1016/j.neunet.2021.06.010},
	abstract = {Policy search reinforcement learning has been drawing much attention as a method of learning a robot control policy. In particular, policy search using such non-parametric policies as Gaussian process regression can learn optimal actions with high-dimensional and redundant sensors as input. However, previous methods implicitly assume that the optimal action becomes unique for each state. This assumption can severely limit such practical applications as robot manipulations since designing a reward function that appears in only one optimal action for complex tasks is difficult. The previous methods might have caused critical performance deterioration because the typical non-parametric policies cannot capture the optimal actions due to their unimodality. We propose novel approaches in non-parametric policy searches with multiple optimal actions and offer two different algorithms commonly based on a sparse Gaussian process prior and variational Bayesian inference. The following are the key ideas: (1) multimodality for capturing multiple optimal actions and (2) mode-seeking for capturing one optimal action by ignoring the others. First, we propose a multimodal sparse Gaussian process policy search that uses multiple overlapped GPs as a prior. Second, we propose a mode-seeking sparse Gaussian process policy search that uses the student-t distribution for a likelihood function. The effectiveness of those algorithms is demonstrated through applications to object manipulation tasks with multiple optimal actions in simulations.},
	language = {en},
	urldate = {2021-06-18},
	journal = {Neural Networks},
	author = {Sasaki, Hikaru and Matsubara, Takamitsu},
	month = jun,
	year = {2021},
	keywords = {Gaussian processes, Policy search, Reinforcement learning, Mode-seeking, Multimodality},
	file = {ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/JK92RTY5/S0893608021002422.html:text/html},
}

@inproceedings{marcoAutomatic2016,
	title = {Automatic {LQR} tuning based on {Gaussian} process global optimization},
	doi = {10.1109/ICRA.2016.7487144},
	abstract = {This paper proposes an automatic controller tuning framework based on linear optimal control combined with Bayesian optimization. With this framework, an initial set of controller gains is automatically improved according to a pre-defined performance objective evaluated from experimental data. The underlying Bayesian optimization algorithm is Entropy Search, which represents the latent objective as a Gaussian process and constructs an explicit belief over the location of the objective minimum. This is used to maximize the information gain from each experimental evaluation. Thus, this framework shall yield improved controllers with fewer evaluations compared to alternative approaches. A seven-degree-of-freedom robot arm balancing an inverted pole is used as the experimental demonstrator. Results of two- and four-dimensional tuning problems highlight the method's potential for automatic controller tuning on robotic platforms.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Marco, Alonso and Hennig, Philipp and Bohg, Jeannette and Schaal, Stefan and Trimpe, Sebastian},
	month = may,
	year = {2016},
	note = {tex.ids= marcoAutomatic2016a},
	keywords = {Gaussian processes, Bayes methods, Computational modeling, Tuning, Robots, Cost function},
	pages = {270--277},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/GLH4RV2S/7487144.html:text/html;IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/2MZEI9XT/7487144.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/IS625MU9/Marco et al. - 2016 - Automatic LQR tuning based on Gaussian process glo.pdf:application/pdf;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/7H6NWTCX/Marco et al. - 2016 - Automatic LQR tuning based on Gaussian process glo.pdf:application/pdf},
}

@inproceedings{rohrProbabilistic2021,
	title = {Probabilistic robust linear quadratic regulators with {Gaussian} processes},
	url = {http://proceedings.mlr.press/v144/rohr21a.html},
	abstract = {Probabilistic models such as Gaussian processes (GPs) are powerful tools to learn unknown dynamical systems from data for subsequent use in control design. While learning-based control has the pote...},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {Learning for {Dynamics} and {Control}},
	publisher = {PMLR},
	author = {Rohr, Alexander von and Neumann-Brosig, Matthias and Trimpe, Sebastian},
	month = may,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {324--335},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/49R9IA7G/Rohr et al. - 2021 - Probabilistic robust linear quadratic regulators w.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/BX9VVXBP/rohr21a.html:text/html},
}

@inproceedings{boedeckerApproximate2014,
	title = {Approximate real-time optimal control based on sparse {Gaussian} process models},
	doi = {10.1109/ADPRL.2014.7010608},
	abstract = {In this paper we present a fully automated approach to (approximate) optimal control of non-linear systems. Our algorithm jointly learns a non-parametric model of the system dynamics - based on Gaussian Process Regression (GPR) - and performs receding horizon control using an adapted iterative LQR formulation. This results in an extremely data-efficient learning algorithm that can operate under real-time constraints. When combined with an exploration strategy based on GPR variance, our algorithm successfully learns to control two benchmark problems in simulation (two-link manipulator, cart-pole) as well as to swing-up and balance a real cart-pole system. For all considered problems learning from scratch, that is without prior knowledge provided by an expert, succeeds in less than 10 episodes of interaction with the system.},
	booktitle = {2014 {IEEE} {Symposium} on {Adaptive} {Dynamic} {Programming} and {Reinforcement} {Learning} ({ADPRL})},
	author = {Boedecker, Joschka and Springenberg, Jost Tobias and Wülfing, Jan and Riedmiller, Martin},
	month = dec,
	year = {2014},
	note = {ISSN: 2325-1867},
	keywords = {Predictive models, Trajectory, Computational modeling, Optimization, Approximation methods, Optimal control, Approximation algorithms},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/VCPKHUJ7/7010608.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/DYM9RM8Y/Boedecker et al. - 2014 - Approximate real-time optimal control based on spa.pdf:application/pdf},
}

@inproceedings{zhouVector2014,
	title = {Vector field following for quadrotors using differential flatness},
	doi = {10.1109/ICRA.2014.6907828},
	abstract = {This paper proposes a differential flatness-based method for maneuvering a quadrotor so that its position follows a specified velocity vector field. Existing planning and control algorithms often give a 2D or 3D velocity vector field to be followed by a robot. However, quadrotors have complex nonlinear dynamics that make vector field following difficult, especially in aggressive maneuvering regimes. This paper exploits the differential flatness property of a quadrotor's dynamics to control its position along a given vector field. Differential flatness allows for the analytical derivation of control inputs in order to control the 12D dynamical state of the quadrotor such that the 2D or 3D position of the quadrotor follows the flow specified by a given vector field. The method is derived mathematically, and demonstrated in numerical simulations and in experiments with a quadrotor robot for three different vector fields.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Zhou, Dingjiang and Schwager, Mac},
	month = may,
	year = {2014},
	note = {ISSN: 1050-4729},
	keywords = {Trajectory, Robots, Heuristic algorithms, Collision avoidance, Navigation, Spirals, Vectors},
	pages = {6567--6572},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/YPFEFDI6/6907828.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/83EI6RHU/Zhou and Schwager - 2014 - Vector field following for quadrotors using differ.pdf:application/pdf},
}

@article{rosenbrockDifferential1972,
	title = {Differential {Dynamic} {Programming}. {By} {D}.{H}. {Jacobson} and {D}. {Q}. {Mayne}. {Pp}. viii, 208. 1970. ({Elsevier}.)},
	volume = {56},
	issn = {0025-5572, 2056-6328},
	url = {https://www.cambridge.org/core/journals/mathematical-gazette/article/abs/differential-dynamic-programming-by-dh-jacobson-and-d-q-mayne-pp-viii-208-1970-elsevier/CB6EA5B3191A305CFB1D2CDF9CC5BA1D},
	doi = {10.2307/3613752},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0025557200188072/resource/name/firstPage-S0025557200188072a.jpg},
	language = {en},
	number = {395},
	urldate = {2021-06-21},
	journal = {The Mathematical Gazette},
	author = {Rosenbrock, H. H.},
	month = feb,
	year = {1972},
	note = {Publisher: Cambridge University Press},
	pages = {78--78},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/BDJAYGT9/CB6EA5B3191A305CFB1D2CDF9CC5BA1D.html:text/html},
}

@article{jacobsonDifferential1970,
	title = {Differential dynamic programming},
	author = {Jacobson, David H. and Mayne, David Q.},
	year = {1970},
	note = {Publisher: North-Holland},
}

@inproceedings{tassaSynthesis2012,
	title = {Synthesis and stabilization of complex behaviors through online trajectory optimization},
	doi = {10.1109/IROS.2012.6386025},
	abstract = {We present an online trajectory optimization method and software platform applicable to complex humanoid robots performing challenging tasks such as getting up from an arbitrary pose on the ground and recovering from large disturbances using dexterous acrobatic maneuvers. The resulting behaviors, illustrated in the attached video, are computed only 7 × slower than real time, on a standard PC. The video also shows results on the acrobot problem, planar swimming and one-legged hopping. These simpler problems can already be solved in real time, without pre-computing anything.},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
	month = oct,
	year = {2012},
	note = {ISSN: 2153-0866},
	keywords = {Trajectory, Computational modeling, Optimization, Robots, Heuristic algorithms, Mathematical model, Real-time systems},
	pages = {4906--4913},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/W7EMBPV4/6386025.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/R6QNBA2X/Tassa et al. - 2012 - Synthesis and stabilization of complex behaviors t.pdf:application/pdf},
}

@techreport{liaoAdvantages1992,
	title = {Advantages of {Differential} {Dynamic} {Programming} {Over} {Newton}''s {Method} for {Discrete}-time {Optimal} {Control} {Problems}},
	url = {https://www.semanticscholar.org/paper/Advantages-of-Differential-Dynamic-Programming-Over-Liao-Shoemaker/787b49f4ad64f175d6afa47fd16068d2281be2c5},
	abstract = {Differential Dynamic Programming (DDP) and stagewise Newton\&\#39;\&\#39;s method are both quadratically convergent algorithms for solving discrete time optimal control problems. Although these two algorithms share many theoretical similarities, they demonstrate significantly different numerical performance. In this paper, we will compare and analyze these two algorithms in detail and derive another quadratically convergent algorithm which is a combination of the DDP algorithm and Newton\&\#39;\&\#39;s method. This new second-order algorithm plays a key role in the explanation of the numerical differences between the DDP algorithm and Newton\&\#39;\&\#39;s method. The detailed algorithmic and structural differences for these three algorithms and their impact on numerical performance will be discussed and explored. Two test problems with various dimensions solved by these three algorithms will be presented. One nonlinear test problem demonstrates that the DDP algorithm can be as much as 28 times faster than the stagewise Newton\&\#39;\&\#39;s method. The numerical comparsion indicates that the DDP algorithm is numerically superior to the stagewise Newton\&\#39;\&\#39;s method.},
	language = {en},
	urldate = {2021-06-21},
	institution = {Cornell University, Ithaca, NY},
	author = {Liao, L. and Shoemaker, C.},
	year = {1992},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/9GC5A94M/787b49f4ad64f175d6afa47fd16068d2281be2c5.html:text/html},
}

@article{hehnRealTime2015,
	title = {Real-{Time} {Trajectory} {Generation} for {Quadrocopters}},
	volume = {31},
	issn = {1941-0468},
	doi = {10.1109/TRO.2015.2432611},
	abstract = {This paper presents a trajectory generation algorithm that efficiently computes high-performance flight trajectories that are capable of moving a quadrocopter from a large class of initial states to a given target point that will be reached at rest. The approach consists of planning separate trajectories in each of the three translational degrees of freedom, and ensuring feasibility by deriving decoupled constraints for each degree of freedom through approximations that preserve feasibility. The presented algorithm can compute a feasible trajectory within tens of microseconds on a laptop computer; remaining computation time can be used to iteratively improve the trajectory. By replanning the trajectory at a high rate, the trajectory generator can be used as an implicit feedback law similar to model predictive control. The solutions generated by the algorithm are analyzed by comparing them with time-optimal motions, and experimental results validate the approach.},
	number = {4},
	journal = {IEEE Transactions on Robotics},
	author = {Hehn, Markus and D’Andrea, Raffaello},
	month = aug,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {Trajectory, Vehicle dynamics, Robots, optimal control, trajectory generation, Heuristic algorithms, Real-time systems, Acceleration, Motion control, quadrocopter, unmanned aerial vehicles, Vehicles},
	pages = {877--892},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/LUYRASXX/7128399.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/XM4Y3DUK/Hehn and D’Andrea - 2015 - Real-Time Trajectory Generation for Quadrocopters.pdf:application/pdf},
}

@inproceedings{todorovGeneralized2005,
	title = {A generalized iterative {LQG} method for locally-optimal feedback control of constrained nonlinear stochastic systems},
	doi = {10.1109/ACC.2005.1469949},
	abstract = {We present an iterative linear-quadratic-Gaussian method for locally-optimal feedback control of nonlinear stochastic systems subject to control constraints. Previously, similar methods have been restricted to deterministic unconstrained problems with quadratic costs. The new method constructs an affine feedback control law, obtained by minimizing a novel quadratic approximation to the optimal cost-to-go function. Global convergence is guaranteed through a Levenberg-Marquardt method; convergence in the vicinity of a local minimum is quadratic. Performance is illustrated on a limited-torque inverted pendulum problem, as well as a complex biomechanical control problem involving a stochastic model of the human arm, with 10 state dimensions and 6 muscle actuators. A Matlab implementation of the new algorithm is availabe at www.cogsci.ucsd.edu//spl sim/todorov.},
	booktitle = {Proceedings of the 2005, {American} {Control} {Conference}, 2005.},
	author = {Todorov, E. and Li, Weiwei},
	month = jun,
	year = {2005},
	note = {ISSN: 2378-5861},
	keywords = {Control systems, Nonlinear control systems, Mathematical model, Convergence, Costs, Feedback control, Iterative methods, Linear feedback control systems, Stochastic processes, Stochastic systems},
	pages = {300--306 vol. 1},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/XVSZ5EIE/1469949.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/5YFS2PIJ/Todorov and Li - 2005 - A generalized iterative LQG method for locally-opt.pdf:application/pdf},
}

@inproceedings{tassaReceding2007,
	title = {Receding {Horizon} {Differential} {Dynamic} {Programming}},
	volume = {20},
	url = {https://proceedings.neurips.cc/paper/1987/file/6c8349cc7260ae62e3b1396831a8398f-Paper.pdf},
	urldate = {2021-06-23},
	booktitle = {Neural {Information} {Processing} {Systems}},
	author = {Tassa, Yuval and Erez, Tom and Smart, Bill},
	year = {2007},
	file = {NIPS Full Text PDF:/Users/aidanscannell/Zotero/storage/Y7BD5423/Jang et al. - 1988 - An Optimization Network for Matrix Inversion.pdf:application/pdf;NIPS Snapshot:/Users/aidanscannell/Zotero/storage/FKB3ZUD6/c6bff625bdb0393992c9d4db0c6bbe45-Paper.html:text/html},
}

@inproceedings{theodorouStochastic2010,
	title = {Stochastic {Differential} {Dynamic} {Programming}},
	doi = {10.1109/ACC.2010.5530971},
	abstract = {Although there has been a significant amount of work in the area of stochastic optimal control theory towards the development of new algorithms, the problem of how to control a stochastic nonlinear system remains an open research topic. Recent iterative linear quadratic optimal control methods iLQG handle control and state multiplicative noise while they are derived based on first order approximation of dynamics. On the other hand, methods such as Differential Dynamic Programming expand the dynamics up to the second order but so far they can handle nonlinear systems with additive noise. In this work we present a generalization of the classic Differential Dynamic Programming algorithm. We assume the existence of state and control multiplicative process noise, and proceed to derive the second-order expansion of the cost-to-go. We find the correction terms that arise from the stochastic assumption. Despite having quartic and cubic terms in the initial expression, we show that these vanish, leaving us with the same quadratic structure as standard DDP.},
	booktitle = {Proceedings of the 2010 {American} {Control} {Conference}},
	author = {Theodorou, Evangelos and Tassa, Yuval and Todorov, Emo},
	month = jun,
	year = {2010},
	note = {ISSN: 2378-5861},
	keywords = {Control systems, Nonlinear systems, Nonlinear control systems, Optimal control, Dynamic programming, Nonlinear dynamical systems, Stochastic processes, Stochastic systems, Iterative algorithms, Stochastic resonance},
	pages = {1125--1132},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/FVYIC7HX/5530971.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/V3X594IF/Theodorou et al. - 2010 - Stochastic Differential Dynamic Programming.pdf:application/pdf},
}

@inproceedings{mitrovicAdaptive2010,
	title = {Adaptive {Optimal} {Feedback} {Control} with {Learned} {Internal} {Dynamics} {Models}},
	doi = {10.1007/978-3-642-05181-4_4},
	abstract = {Optimal Feedback Control (OFC) has been proposed as an attractive movement generation strategy in goal reaching tasks for anthropomorphic manipulator systems. Recent developments, such as the Iterative Linear Quadratic Gaussian (ILQG) algorithm, have focused on the case of non-linear, but still analytically available, dynamics. For realistic control systems, however, the dynamics may often be unknown, difficult to estimate, or subject to frequent systematic changes. In this chapter, we combine the ILQG framework with learning the forward dynamics for simulated arms, which exhibit large redundancies, both, in kinematics and in the actuation. We demonstrate how our approach can compensate for complex dynamic perturbations in an online fashion. The specific adaptive framework introduced lends itself to a computationally more efficient implementation of the ILQG optimisation without sacrificing control accuracy – allowing the method to scale to large DoF systems.},
	booktitle = {From {Motor} {Learning} to {Interaction} {Learning} in {Robots}},
	author = {Mitrovic, Djordje and Klanke, Stefan and Vijayakumar, S.},
	year = {2010},
	file = {Submitted Version:/Users/aidanscannell/Zotero/storage/Q9BM2T8Y/Mitrovic et al. - 2010 - Adaptive Optimal Feedback Control with Learned Int.pdf:application/pdf},
}

@article{faesslerDifferential2018,
	title = {Differential {Flatness} of {Quadrotor} {Dynamics} {Subject} to {Rotor} {Drag} for {Accurate} {Tracking} of {High}-{Speed} {Trajectories}},
	volume = {3},
	issn = {2377-3766},
	doi = {10.1109/LRA.2017.2776353},
	abstract = {In this letter, we prove that the dynamical model of a quadrotor subject to linear rotor drag effects is differentially flat in its position and heading. We use this property to compute feedforward control terms directly from a reference trajectory to be tracked. The obtained feedforward terms are then used in a cascaded, nonlinear feedback control law that enables accurate agile flight with quadrotors. Compared to the state-of-the-art control methods, which treat the rotor drag as an unknown disturbance, our method reduces the trajectory tracking error significantly. Finally, we present a method based on a gradient-free optimization to identify the rotor drag coefficients, which are required to compute the feedforward control terms. The new theoretical results are thoroughly validated trough extensive comparative experiments.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Faessler, Matthias and Franchi, Antonio and Scaramuzza, Davide},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Trajectory, Computational modeling, Aerodynamics, Acceleration, Aerial systems, differential flatness, Drag, dynamics, mechanics and control, quadrotor control, Rotors, Trajectory tracking},
	pages = {620--626},
	file = {IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/4JIJS2IU/Faessler et al. - 2018 - Differential Flatness of Quadrotor Dynamics Subjec.pdf:application/pdf},
}

@inproceedings{hewingSimulation2020,
	title = {On {Simulation} and {Trajectory} {Prediction} with {Gaussian} {Process} {Dynamics}},
	url = {http://proceedings.mlr.press/v120/hewing20a.html},
	abstract = {Established techniques for simulation and prediction with Gaussian process (GP) dynamics implicitly make use of an independence assumption on successive function evaluations of the dynamics model. ...},
	language = {en},
	urldate = {2021-06-24},
	booktitle = {Learning for {Dynamics} and {Control}},
	publisher = {PMLR},
	author = {Hewing, Lukas and Arcari, Elena and Fröhlich, Lukas P. and Zeilinger, Melanie N.},
	month = jul,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {424--434},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/SLW3YVJJ/Hewing et al. - 2020 - On Simulation and Trajectory Prediction with Gauss.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/PM5RAFJM/hewing20a.html:text/html},
}

@article{williamsModel2017,
	title = {Model {Predictive} {Path} {Integral} {Control}: {From} {Theory} to {Parallel} {Computation}},
	volume = {40},
	shorttitle = {Model {Predictive} {Path} {Integral} {Control}},
	url = {https://doi.org/10.2514/1.G001921},
	doi = {10.2514/1.G001921},
	abstract = {In this paper, a model predictive path integral control algorithm based on a generalized importance sampling scheme is developed and parallel optimization via sampling is performed using a graphics processing unit. The proposed generalized importance sampling scheme allows for changes in the drift and diffusion terms of stochastic diffusion processes and plays a significant role in the performance of the model predictive control algorithm. The proposed algorithm is compared in simulation with a model predictive control version of differential dynamic programming on nonlinear systems. Finally, the proposed algorithm is applied on multiple vehicles for the task of navigating through a cluttered environment. The current simulations illustrate the efficiency and robustness of the proposed approach and demonstrate the advantages of computational frameworks that incorporate concepts from statistical physics, control theory, and parallelization against more traditional approaches of optimal control theory.},
	number = {2},
	urldate = {2021-06-24},
	journal = {Journal of Guidance, Control, and Dynamics},
	author = {Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos A.},
	year = {2017},
	note = {Publisher: American Institute of Aeronautics and Astronautics
\_eprint: https://doi.org/10.2514/1.G001921},
	pages = {344--357},
	file = {AIAA Full Text PDF:/Users/aidanscannell/Zotero/storage/UADARRDZ/Williams et al. - 2017 - Model Predictive Path Integral Control From Theor.pdf:application/pdf;AIAA Snapshot:/Users/aidanscannell/Zotero/storage/9C2RDKAE/1.html:text/html},
}

@inproceedings{panSample2015,
	title = {Sample {Efficient} {Path} {Integral} {Control} under {Uncertainty}},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper/1987/file/072b030ba126b2f4b2374f342be9ed44-Paper.pdf},
	urldate = {2021-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pan, Yunpeng and Theodorou, Evangelos and Kontitsis, Michail},
	year = {2015},
	file = {NIPS Full Text PDF:/Users/aidanscannell/Zotero/storage/J6YZYW7T/Fleisher - 1988 - The Hopfield Model with Multi-Level Neurons.pdf:application/pdf;NIPS Snapshot:/Users/aidanscannell/Zotero/storage/RDCXT48K/81ca0262c82e712e50c580c032d99b60-Paper.html:text/html},
}

@inproceedings{williamsInformation2017,
	title = {Information theoretic {MPC} for model-based reinforcement learning},
	doi = {10.1109/ICRA.2017.7989202},
	abstract = {We introduce an information theoretic model predictive control (MPC) algorithm capable of handling complex cost criteria and general nonlinear dynamics. The generality of the approach makes it possible to use multi-layer neural networks as dynamics models, which we incorporate into our MPC algorithm in order to solve model-based reinforcement learning tasks. We test the algorithm in simulation on a cart-pole swing up and quadrotor navigation task, as well as on actual hardware in an aggressive driving task. Empirical results demonstrate that the algorithm is capable of achieving a high level of performance and does so only utilizing data collected from the system.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M. and Boots, Byron and Theodorou, Evangelos A.},
	month = may,
	year = {2017},
	note = {tex.ids= williamsInformation2017a},
	keywords = {Trajectory, Robots, Optimal control, Cost function, Heuristic algorithms, Learning (artificial intelligence)},
	pages = {1714--1721},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/DGP8VC62/7989202.html:text/html;IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/GYW9MRB7/7989202.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/4T95X4BV/Williams et al. - 2017 - Information theoretic MPC for model-based reinforc.pdf:application/pdf;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/H3WL5XS4/Williams et al. - 2017 - Information theoretic MPC for model-based reinforc.pdf:application/pdf},
}

@article{hewingLearningBased2020,
	title = {Learning-{Based} {Model} {Predictive} {Control}: {Toward} {Safe} {Learning} in {Control}},
	volume = {3},
	shorttitle = {Learning-{Based} {Model} {Predictive} {Control}},
	url = {https://doi.org/10.1146/annurev-control-090419-075625},
	doi = {10.1146/annurev-control-090419-075625},
	abstract = {Recent successes in the field of machine learning, as well as the availability of increased sensing and computational capabilities in modern control systems, have led to a growing interest in learning and data-driven control techniques. Model predictive control (MPC), as the prime methodology for constrained control, offers a significant opportunity to exploit the abundance of data in a reliable manner, particularly while taking safety constraints into account. This review aims at summarizing and categorizing previous research on learning-based MPC, i.e., the integration or combination of MPC with learning methods, for which we consider three main categories. Most of the research addresses learning for automatic improvement of the prediction model from recorded data. There is, however, also an increasing interest in techniques to infer the parameterization of the MPC controller, i.e., the cost and constraints, that lead to the best closed-loop performance. Finally, we discuss concepts that leverage MPC to augment learning-based controllers with constraint satisfaction properties.},
	number = {1},
	urldate = {2021-06-24},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Hewing, Lukas and Wabersich, Kim P. and Menner, Marcel and Zeilinger, Melanie N.},
	year = {2020},
	note = {\_eprint: https://doi.org/10.1146/annurev-control-090419-075625
tex.ids= hewingLearningBased2020a},
	pages = {269--296},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/5M3WTY63/Hewing et al. - 2020 - Learning-Based Model Predictive Control Toward Sa.pdf:application/pdf},
}

@article{aswaniProvably2013,
	title = {Provably safe and robust learning-based model predictive control},
	volume = {49},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/S0005109813000678},
	doi = {10.1016/j.automatica.2013.02.003},
	abstract = {Controller design faces a trade-off between robustness and performance, and the reliability of linear controllers has caused many practitioners to focus on the former. However, there is renewed interest in improving system performance to deal with growing energy constraints. This paper describes a learning-based model predictive control (LBMPC) scheme that provides deterministic guarantees on robustness, while statistical identification tools are used to identify richer models of the system in order to improve performance; the benefits of this framework are that it handles state and input constraints, optimizes system performance with respect to a cost function, and can be designed to use a wide variety of parametric or nonparametric statistical tools. The main insight of LBMPC is that safety and performance can be decoupled under reasonable conditions in an optimization framework by maintaining two models of the system. The first is an approximate model with bounds on its uncertainty, and the second model is updated by statistical methods. LBMPC improves performance by choosing inputs that minimize a cost subject to the learned dynamics, and it ensures safety and robustness by checking whether these same inputs keep the approximate model stable when it is subject to uncertainty. Furthermore, we show that if the system is sufficiently excited, then the LBMPC control action probabilistically converges to that of an MPC computed using the true dynamics.},
	language = {en},
	number = {5},
	urldate = {2021-06-25},
	journal = {Automatica},
	author = {Aswani, Anil and Gonzalez, Humberto and Sastry, S. Shankar and Tomlin, Claire},
	month = may,
	year = {2013},
	keywords = {Robustness, Predictive control, Learning control, Safety analysis, Statistics},
	pages = {1216--1226},
	file = {ScienceDirect Full Text PDF:/Users/aidanscannell/Zotero/storage/NM75P263/Aswani et al. - 2013 - Provably safe and robust learning-based model pred.pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/L22HPPJE/S0005109813000678.html:text/html},
}

@article{williamsInformationTheoretic2018,
	title = {Information-{Theoretic} {Model} {Predictive} {Control}: {Theory} and {Applications} to {Autonomous} {Driving}},
	volume = {34},
	issn = {1941-0468},
	shorttitle = {Information-{Theoretic} {Model} {Predictive} {Control}},
	doi = {10.1109/TRO.2018.2865891},
	abstract = {We present an information-theoretic approach to stochastic optimal control problems that can be used to derive general sampling-based optimization schemes. This new mathematical method is used to develop a sampling-based model predictive control algorithm. We apply this information-theoretic model predictive control scheme to the task of aggressive autonomous driving around a dirt test track, and compare its performance with a model predictive control version of the cross-entropy method.},
	number = {6},
	journal = {IEEE Transactions on Robotics},
	author = {Williams, Grady and Drews, Paul and Goldfain, Brian and Rehg, James M. and Theodorou, Evangelos A.},
	month = dec,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {nonlinear control systems, optimal control, Nonlinear control systems, Optimal control, Stochastic processes, Autonomous vehicles, Monte Carlo methods, Monte-Carlo methods, parallel algorithms, Parallel processing},
	pages = {1603--1622},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/HWUPYAJG/8558663.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/CNPYIW9A/Williams et al. - 2018 - Information-Theoretic Model Predictive Control Th.pdf:application/pdf},
}

@article{aoyamaReceding2021,
	title = {Receding {Horizon} {Differential} {Dynamic} {Programming} {Under} {Parametric} {Uncertainty}},
	url = {http://arxiv.org/abs/2104.10836},
	abstract = {Generalized Polynomial Chaos (gPC) theory has been widely used for representing parametric uncertainty in a system, thanks to its ability to propagate uncertainty evolution. In an optimal control context, gPC can be combined with several optimization techniques to achieve a control policy that handles effectively this type of uncertainty. Such a suitable method is Differential Dynamic Programming (DDP), leading to an algorithm that inherits the scalability to high-dimensional systems and fast convergence nature of the latter. In this paper, we expand this combination aiming to acquire probabilistic guarantees on the satisfaction of constraints. In particular, we exploit the ability of gPC to express higher order moments of the uncertainty distribution - without any Gaussianity assumption - and we incorporate chance constraints that lead to expressions involving the state variance. Furthermore, we demonstrate that by implementing our algorithm in a receding horizon fashion, we compute control policies that effectively reduce the accumulation of uncertainty on the trajectory. The applicability of our method is verified through simulation results on a differential wheeled robot and a quadrotor that perform obstacle avoidance tasks.},
	urldate = {2021-06-25},
	journal = {arXiv:2104.10836 [math]},
	author = {Aoyama, Yuichiro and Saravanos, Augustinos D. and Theodorou, Evangelos A.},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.10836},
	keywords = {Mathematics - Optimization and Control},
	annote = {Comment: 7 pages, 3 figures, for CDC 2021},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/CXB6FM5C/Aoyama et al. - 2021 - Receding Horizon Differential Dynamic Programming .pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/5XLXZG2Z/2104.html:text/html},
}

@article{theodorouGeneralized2010,
	title = {A {Generalized} {Path} {Integral} {Control} {Approach} to {Reinforcement} {Learning}},
	volume = {11},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v11/theodorou10a.html},
	number = {104},
	urldate = {2021-06-25},
	journal = {Journal of Machine Learning Research},
	author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
	year = {2010},
	pages = {3137--3181},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/V9XNWFXI/Theodorou et al. - 2010 - A Generalized Path Integral Control Approach to Re.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/P82WK5SN/theodorou10a.html:text/html},
}

@article{wilsonPathwise2021,
	title = {Pathwise {Conditioning} of {Gaussian} {Processes}},
	volume = {22},
	url = {http://jmlr.org/papers/v22/20-1260.html},
	abstract = {As Gaussian processes are used to answer increasingly complex questions, analytic solutions become scarcer and scarcer. Monte Carlo methods act as a convenient bridge for connecting intractable mathematical expressions with actionable estimates via sampling. Conventional approaches for simulating Gaussian process posteriors view samples as draws from marginal distributions of process values at finite sets of input locations. This distribution-centric characterization leads to generative strategies that scale cubically in the size of the desired random vector. These methods are prohibitively expensive in cases where we would, ideally, like to draw high-dimensional vectors or even continuous sample paths. In this work, we investigate a different line of reasoning: rather than focusing on distributions, we articulate Gaussian conditionals at the level of random variables. We show how this pathwise interpretation of conditioning gives rise to a general family of approximations that lend themselves to efficiently sampling Gaussian process posteriors. Starting from first principles, we derive these methods and analyze the approximation errors they introduce. We, then, ground these results by exploring the practical implications of pathwise conditioning in various applied settings, such as global optimization and reinforcement learning.},
	number = {105},
	urldate = {2021-06-25},
	journal = {Journal of Machine Learning Research},
	author = {Wilson, James T. and Borovitskiy, Viacheslav and Terenin, Alexander and Mostowsky, Peter and Deisenroth, Marc Peter},
	year = {2021},
	note = {tex.ids= wilsonPathwise},
	pages = {1--47},
	file = {Fulltext PDF:/Users/aidanscannell/Zotero/storage/EQYCWMQY/Wilson et al. - 2021 - Pathwise Conditioning of Gaussian Processes.pdf:application/pdf},
}

@inproceedings{kappenIntroduction2007,
	title = {An introduction to stochastic control theory, path integrals and reinforcement learning},
	abstract = {Control theory is a mathematical description of how to act optimally to gain future rewards. In this paper I give an introduction to deterministic and stochastic control theory and I give an overview of the possible application of control theory to the modeling of animal behavior and learning. I discuss a class of non-linear stochastic control problems that can be efficiently solved using a path integral or by MC sampling. In this control formalism the central concept of cost-to-go becomes a free energy and methods and concepts from statistical physics can be readily applied.},
	language = {en},
	booktitle = {{AIP} {Conference} {Proceedings}},
	author = {Kappen, Hilbert J},
	year = {2007},
	pages = {34},
	file = {Kappen - An introduction to stochastic control theory, path.pdf:/Users/aidanscannell/Zotero/storage/T5W7HD97/Kappen - An introduction to stochastic control theory, path.pdf:application/pdf},
}

@article{kofmanProbabilistic2012,
	title = {Probabilistic set invariance and ultimate boundedness},
	volume = {48},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/S0005109812003408},
	doi = {10.1016/j.automatica.2012.06.074},
	abstract = {The notions of invariant sets and ultimate bounds are important concepts in the analysis of dynamical systems and very useful tools for the design of control systems. Several approaches have been reported for the characterisation of these sets, including constructive methods for their computation and procedures to obtain different approximations. However, there are shortcomings in those concepts, in the sense that no general probability distributions can be considered for the disturbances affecting the system (which, for example, precludes the assumption of Gaussian distributions insofar as they are not bounded). Motivated by those shortcomings, we propose in this paper the novel concepts of probabilistic ultimate bounds and probabilistic invariant sets, which extend the notions of invariant sets and ultimate bounds to consider ‘containment in probability’, and have the important feature of allowing stochastic noises with more general distributions, including the ubiquitous Gaussian distribution, to be considered. We introduce some key definitions for these sets, establish their main properties and develop methods for their computation. A numerical example illustrates the main ideas.},
	language = {en},
	number = {10},
	urldate = {2021-06-28},
	journal = {Automatica},
	author = {Kofman, Ernesto and De Doná, José A. and Seron, Maria M.},
	month = oct,
	year = {2012},
	keywords = {Invariant sets, Linear systems, Probabilistic methods, Ultimate bounds},
	pages = {2670--2676},
	file = {ScienceDirect Full Text PDF:/Users/aidanscannell/Zotero/storage/6UFJUVQ6/Kofman et al. - 2012 - Probabilistic set invariance and ultimate boundedn.pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/BYUCB2YS/S0005109812003408.html:text/html},
}

@inproceedings{hewingCorrespondence2018,
	title = {On a {Correspondence} between {Probabilistic} and {Robust} {Invariant} {Sets} for {Linear} {Systems}},
	doi = {10.23919/ECC.2018.8550160},
	abstract = {Dynamical systems with stochastic uncertainties are ubiquitous in the field of control, with linear systems under additive Gaussian disturbances a most prominent example. The concept of probabilistic invariance was introduced to extend the widely applied concept of invariance to this class of problems. Computational methods for their synthesis, however, are limited. In this paper we present a relationship between probabilistic and robust invariant sets for linear systems, which enables the use of well-studied robust design methods. Conditions are shown, under which a robust invariant set, designed with a confidence region of the disturbance, results in a probabilistic invariant set. We furthermore show that this condition holds for common box and ellipsoidal confidence regions, generalizing and improving existing results for probabilistic invariant set computation. We finally exemplify the synthesis for an ellipsoidal probabilistic invariant set. Two numerical examples demonstrate the approach and the advantages to be gained from exploiting robust computations for probabilistic invariant sets.},
	booktitle = {2018 {European} {Control} {Conference} ({ECC})},
	author = {Hewing, Lukas and Carron, Andrea and Wabersich, Kim P. and Zeilinger, Melanie N.},
	month = jun,
	year = {2018},
	keywords = {Probabilistic logic, Control systems, Stochastic processes, Linear systems, Additives, Gaussian distribution, Random variables},
	pages = {1642--1647},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/L4TEPLYJ/8550160.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/A7RQGY5L/Hewing et al. - 2018 - On a Correspondence between Probabilistic and Robu.pdf:application/pdf},
}

@inproceedings{hewingStochastic2018,
	title = {Stochastic {Model} {Predictive} {Control} for {Linear} {Systems} {Using} {Probabilistic} {Reachable} {Sets}},
	doi = {10.1109/CDC.2018.8619554},
	abstract = {In this paper, we propose a stochastic model predictive control (MPC) algorithm for linear discrete-time systems affected by possibly unbounded additive disturbances and subject to probabilistic constraints. Constraints are treated in analogy to robust MPC using a constraint tightening based on the concept of probabilistic reachable sets, which is shown to provide closed-loop fulfillment of chance constraints under a unimodality assumption on the disturbance distribution. A control scheme reverting to a backup solution from a previous time step in case of infeasibility is proposed, for which an asymptotic average performance bound is derived. Two examples illustrate the approach, highlighting closed-loop chance constraint satisfaction and the benefits of the proposed controller in the presence of unmodeled disturbances.},
	booktitle = {2018 {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Hewing, Lukas and Zeilinger, Melanie N.},
	month = dec,
	year = {2018},
	note = {ISSN: 2576-2370},
	keywords = {Probabilistic logic, Chebyshev approximation, Predictive control, Stochastic processes, Linear systems, Additives, Random variables},
	pages = {5182--5188},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/KCQRLML6/8619554.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/D74JVUVJ/Hewing and Zeilinger - 2018 - Stochastic Model Predictive Control for Linear Sys.pdf:application/pdf},
}

@inproceedings{amesControl2019,
	title = {Control {Barrier} {Functions}: {Theory} and {Applications}},
	shorttitle = {Control {Barrier} {Functions}},
	doi = {10.23919/ECC.2019.8796030},
	abstract = {This paper provides an introduction and overview of recent work on control barrier functions and their use to verify and enforce safety properties in the context of (optimization based) safety-critical controllers. We survey the main technical results and discuss applications to several domains including robotic systems.},
	booktitle = {2019 18th {European} {Control} {Conference} ({ECC})},
	author = {Ames, Aaron D. and Coogan, Samuel and Egerstedt, Magnus and Notomista, Gennaro and Sreenath, Koushil and Tabuada, Paulo},
	month = jun,
	year = {2019},
	pages = {3420--3431},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/9BY4GJA5/8796030.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/HMGX6K3G/Ames et al. - 2019 - Control Barrier Functions Theory and Applications.pdf:application/pdf},
}

@article{rybkinModelBased2021,
	title = {Model-{Based} {Reinforcement} {Learning} via {Latent}-{Space} {Collocation}},
	url = {http://arxiv.org/abs/2106.13229},
	abstract = {The ability to plan into the future while utilizing only raw high-dimensional observations, such as images, can provide autonomous agents with broad capabilities. Visual model-based reinforcement learning (RL) methods that plan future actions directly have shown impressive results on tasks that require only short-horizon reasoning, however, these methods struggle on temporally extended tasks. We argue that it is easier to solve long-horizon tasks by planning sequences of states rather than just actions, as the effects of actions greatly compound over time and are harder to optimize. To achieve this, we draw on the idea of collocation, which has shown good results on long-horizon tasks in optimal control literature, and adapt it to the image-based setting by utilizing learned latent state space models. The resulting latent collocation method (LatCo) optimizes trajectories of latent states, which improves over previously proposed shooting methods for visual model-based RL on tasks with sparse rewards and long-term goals. Videos and code at https://orybkin.github.io/latco/.},
	urldate = {2021-06-29},
	journal = {arXiv:2106.13229 [cs]},
	author = {Rybkin, Oleh and Zhu, Chuning and Nagabandi, Anusha and Daniilidis, Kostas and Mordatch, Igor and Levine, Sergey},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.13229},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: International Conference on Machine Learning (ICML), 2021. Videos and code at https://orybkin.github.io/latco/},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/MDHUIW24/Rybkin et al. - 2021 - Model-Based Reinforcement Learning via Latent-Spac.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/RARRLXIJ/2106.html:text/html},
}

@inproceedings{nagumoUber1942,
	title = {Über die {Lage} der {Integralkurven} gewöhnlicher {Differentialgleichungen}},
	volume = {24},
	doi = {10.11429/PPMSJ1919.24.0_551},
	abstract = {Semantic Scholar extracted view of "Über die Lage der Integralkurven gewöhnlicher Differentialgleichungen" by Mitio Nagumo},
	booktitle = {Proceedings of the {Physico}-{Mathematical} {Society} of {Japan}. 3rd {Series}},
	author = {Nagumo, Mitio},
	year = {1942},
	pages = {551--559},
}

@article{brezisCharacterization1970,
	title = {On a characterization of flow-invariant sets},
	volume = {23},
	issn = {00103640, 10970312},
	url = {http://doi.wiley.com/10.1002/cpa.3160230211},
	doi = {10.1002/cpa.3160230211},
	language = {en},
	number = {2},
	urldate = {2021-06-29},
	journal = {Communications on Pure and Applied Mathematics},
	author = {Brezis, Haim},
	month = mar,
	year = {1970},
	pages = {261--263},
	file = {On a characterization of flow‐invariant sets, Communications on Pure & Applied Mathematics | 10.1002/cpa.3160230211 | DeepDyve:/Users/aidanscannell/Zotero/storage/FL6V3IAF/on-a-characterization-of-flow-invariant-sets-FOPl7HAHdR.html:text/html},
}

@book{abrahamManifolds1988,
	address = {New York},
	edition = {2},
	series = {Applied {Mathematical} {Sciences}},
	title = {Manifolds, {Tensor} {Analysis}, and {Applications}},
	isbn = {978-0-387-96790-5},
	url = {https://www.springer.com/gp/book/9780387967905},
	abstract = {The purpose of this book is to provide core material in nonlinear analysis for mathematicians, physicists, engineers, and mathematical biologists. The main goal is to provide a working knowledge of manifolds, dynamical systems, tensors, and differential forms. Some applications to Hamiltonian mechanics, fluid me­ chanics, electromagnetism, plasma dynamics and control thcory arc given in Chapter 8, using both invariant and index notation. The current edition of the book does not deal with Riemannian geometry in much detail, and it does not treat Lie groups, principal bundles, or Morse theory. Some of this is planned for a subsequent edition. Meanwhile, the authors will make available to interested readers supplementary chapters on Lie Groups and Differential Topology and invite comments on the book's contents and development. Throughout the text supplementary topics are given, marked with the symbols {\textasciitilde} and \{\vphantom{\}}l:;J. This device enables the reader to skip various topics without disturbing the main flow of the text. Some of these provide additional background material intended for completeness, to minimize the necessity of consulting too many outside references. We treat finite and infinite-dimensional manifolds simultaneously. This is partly for efficiency of exposition. Without advanced applications, using manifolds of mappings, the study of infinite-dimensional manifolds can be hard to motivate.},
	language = {en},
	urldate = {2021-06-29},
	publisher = {Springer-Verlag},
	author = {Abraham, Ralph and Marsden, J. E. and Ratiu, Tudor},
	year = {1988},
	doi = {10.1007/978-1-4612-1029-0},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/PAPUN7FY/9780387967905.html:text/html},
}

@article{bonyPrincipe1969,
	title = {Principe du maximum, inégalité de {Harnack} et unicité du problème de {Cauchy} pour les opérateurs elliptiques dégénérés},
	volume = {19},
	url = {https://aif.centre-mersenne.org/item/?id=AIF_1969__19_1_277_0},
	doi = {10.5802/aif.319},
	number = {1},
	urldate = {2021-06-29},
	journal = {Annales de l'Institut Fourier},
	author = {Bony, Jean-Michel},
	year = {1969},
	pages = {277--304},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/XNR2DYNE/Bony - 1969 - Principe du maximum, inégalité de Harnack et unici.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/FLLNVGFL/item.html:text/html},
}

@article{prajnaBarrier2006,
	title = {Barrier certificates for nonlinear model validation},
	volume = {42},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/S0005109805002839},
	doi = {10.1016/j.automatica.2005.08.007},
	abstract = {Methods for model validation of continuous-time nonlinear systems with uncertain parameters are presented in this paper. The methods employ functions of state-parameter-time, termed barrier certificates, whose existence proves that a model and a feasible parameter set are inconsistent with some time-domain experimental data. A very large class of models can be treated within this framework; this includes differential-algebraic models, models with memoryless/dynamic uncertainties, and hybrid models. Construction of barrier certificates can be performed by convex optimization, utilizing recent results on the sum of squares decomposition of multivariate polynomials.},
	language = {en},
	number = {1},
	urldate = {2021-06-29},
	journal = {Automatica},
	author = {Prajna, Stephen},
	month = jan,
	year = {2006},
	keywords = {Nonlinear systems, Barrier certificates, Model validation, Semidefinite programming relaxations},
	pages = {117--126},
	file = {Prajna - 2006 - Barrier certificates for nonlinear model validatio.pdf:/Users/aidanscannell/Zotero/storage/2GNGMD4X/Prajna - 2006 - Barrier certificates for nonlinear model validatio.pdf:application/pdf;ScienceDirect Snapshot:/Users/aidanscannell/Zotero/storage/JE8FZWCV/S0005109805002839.html:text/html},
}

@inproceedings{prajnaSafety2004,
	title = {Safety {Verification} of {Hybrid} {Systems} {Using} {Barrier} {Certificates}},
	abstract = {This paper presents a novel methodology for safety verification  of hybrid systems. For proving that all trajectories of a hybrid  system do not enter an unsafe region, the proposed method uses a function  of state termed a barrier certificate. The zero level set of a barrier  certificate separates the unsafe region from all possible trajectories starting  from a given set of initial conditions, hence providing an exact proof  of system safety. No explicit computation of reachable sets is required in  the construction of barrier certificates, which makes nonlinearity, uncertainty,  and constraints can be handled directly within this framework.},
	booktitle = {In {Hybrid} {Systems}: {Computation} and {Control}},
	publisher = {Springer},
	author = {Prajna, Stephen and Jadbabaie, Ali},
	year = {2004},
	pages = {477--492},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/DQXKMT8U/Prajna and Jadbabaie - 2004 - Safety Verification of Hybrid Systems Using Barrie.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/5F4IM4ZH/summary.html:text/html},
}

@inproceedings{khojastehProbabilistic2020,
	title = {Probabilistic {Safety} {Constraints} for {Learned} {High} {Relative} {Degree} {System} {Dynamics}},
	url = {http://proceedings.mlr.press/v120/khojasteh20a.html},
	abstract = {This paper focuses on learning a model of system dynamics online while satisfying safety constraints. Our motivation is to avoid offline system identification or hand-specified dynamics models and ...},
	language = {en},
	urldate = {2021-06-30},
	booktitle = {Learning for {Dynamics} and {Control}},
	publisher = {PMLR},
	author = {Khojasteh, Mohammad Javad and Dhiman, Vikas and Franceschetti, Massimo and Atanasov, Nikolay},
	month = jul,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {781--792},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/8RWK9LT6/Khojasteh et al. - 2020 - Probabilistic Safety Constraints for Learned High .pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/YA9Z3G8C/khojasteh20a.html:text/html},
}

@article{amesControl2017,
	title = {Control {Barrier} {Function} {Based} {Quadratic} {Programs} for {Safety} {Critical} {Systems}},
	volume = {62},
	issn = {1558-2523},
	doi = {10.1109/TAC.2016.2638961},
	abstract = {Safety critical systems involve the tight coupling between potentially conflicting control objectives and safety constraints. As a means of creating a formal framework for controlling systems of this form, and with a view toward automotive applications, this paper develops a methodology that allows safety conditions-expressed as control barrier functions-to be unified with performance objectives-expressed as control Lyapunov functions-in the context of real-time optimization-based controllers. Safety conditions are specified in terms of forward invariance of a set, and are verified via two novel generalizations of barrier functions; in each case, the existence of a barrier function satisfying Lyapunov-like conditions implies forward invariance of the set, and the relationship between these two classes of barrier functions is characterized. In addition, each of these formulations yields a notion of control barrier function (CBF), providing inequality constraints in the control input that, when satisfied, again imply forward invariance of the set. Through these constructions, CBFs can naturally be unified with control Lyapunov functions (CLFs) in the context of a quadratic program (QP); this allows for the achievement of control objectives (represented by CLFs) subject to conditions on the admissible states of the system (represented by CBFs). The mediation of safety and performance through a QP is demonstrated on adaptive cruise control and lane keeping, two automotive control problems that present both safety and performance considerations coupled with actuator bounds.},
	number = {8},
	journal = {IEEE Transactions on Automatic Control},
	author = {Ames, Aaron D. and Xu, Xiangru and Grizzle, Jessy W. and Tabuada, Paulo},
	month = aug,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Safety, nonlinear control, Lyapunov methods, Automotive engineering, Barrier function, control Lyapunov function, Cruise control, Electrical engineering, Electronic mail, quadratic program, safety, set invariance},
	pages = {3861--3876},
	file = {IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/9NUGNXTJ/Ames et al. - 2017 - Control Barrier Function Based Quadratic Programs .pdf:application/pdf},
}

@article{panEfficient2018,
	title = {Efficient {Reinforcement} {Learning} via {Probabilistic} {Trajectory} {Optimization}},
	volume = {29},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2017.2764499},
	abstract = {We present a trajectory optimization approach to reinforcement learning in continuous state and action spaces, called probabilistic differential dynamic programming (PDDP). Our method represents systems dynamics using Gaussian processes (GPs), and performs local dynamic programming iteratively around a nominal trajectory in Gaussian belief spaces. Different from model-based policy search methods, PDDP does not require a policy parameterization and learns a time-varying control policy via successive forward-backward sweeps. A convergence analysis of the iterative scheme is given, showing that our algorithm converges to a stationary point globally under certain conditions. We show that prior model knowledge can be incorporated into the proposed framework to speed up learning, and a generalized optimization criterion based on the predicted cost distribution can be employed to enable risk-sensitive learning. We demonstrate the effectiveness and efficiency of the proposed algorithm using nontrivial tasks. Compared with a state-of-the-art GP-based policy search method, PDDP offers a superior combination of learning speed, data efficiency, and applicability.},
	number = {11},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Pan, Yunpeng and Boutselis, George I. and Theodorou, Evangelos A.},
	month = nov,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Data models, Predictive models, Probabilistic logic, optimal control, Optimal control, Heuristic algorithms, Dynamic programming, Gaussian processes (GPs), Aerospace electronics, reinforcement learning (RL), trajectory optimization, Trajectory optimization},
	pages = {5459--5474},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/P62DM6XT/8306829.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/UIRUIIA8/Pan et al. - 2018 - Efficient Reinforcement Learning via Probabilistic.pdf:application/pdf},
}

@article{leeGPILQG2017,
	title = {{GP}-{ILQG}: {Data}-driven {Robust} {Optimal} {Control} for {Uncertain} {Nonlinear} {Dynamical} {Systems}},
	shorttitle = {{GP}-{ILQG}},
	url = {http://arxiv.org/abs/1705.05344},
	abstract = {As we aim to control complex systems, use of a simulator in model-based reinforcement learning is becoming more common. However, it has been challenging to overcome the Reality Gap, which comes from nonlinear model bias and susceptibility to disturbance. To address these problems, we propose a novel algorithm that combines data-driven system identification approach (Gaussian Process) with a Differential-Dynamic-Programming-based robust optimal control method (Iterative Linear Quadratic Control). Our algorithm uses the simulator's model as the mean function for a Gaussian Process and learns only the difference between the simulator's prediction and actual observations, making it a natural hybrid of simulation and real-world observation. We show that our approach quickly corrects incorrect models, comes up with robust optimal controllers, and transfers its acquired model knowledge to new tasks efficiently.},
	urldate = {2021-06-30},
	journal = {arXiv:1705.05344 [cs]},
	author = {Lee, Gilwoo and Srinivasa, Siddhartha S. and Mason, Matthew T.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.05344},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/KEQGYL7T/Lee et al. - 2017 - GP-ILQG Data-driven Robust Optimal Control for Un.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/2NUXIVH4/1705.html:text/html},
}

@inproceedings{bechtleCurious2020,
	title = {Curious {iLQR}: {Resolving} {Uncertainty} in {Model}-based {RL}},
	shorttitle = {Curious {iLQR}},
	url = {http://proceedings.mlr.press/v100/bechtle20a.html},
	abstract = {Curiosity as a means to explore during reinforcement learning problems has recently become very popular. However, very little progress has been made in utilizing curiosity for learning control. In ...},
	language = {en},
	urldate = {2021-06-30},
	booktitle = {Conference on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Bechtle, Sarah and Lin, Yixin and Rai, Akshara and Righetti, Ludovic and Meier, Franziska},
	month = may,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {162--171},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/JVSF3DF5/Bechtle et al. - 2020 - Curious iLQR Resolving Uncertainty in Model-based.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/57HXZE89/bechtle20a.html:text/html},
}

@article{barcelosDual2021,
	title = {Dual {Online} {Stein} {Variational} {Inference} for {Control} and {Dynamics}},
	url = {http://arxiv.org/abs/2103.12890},
	abstract = {Model predictive control (MPC) schemes have a proven track record for delivering aggressive and robust performance in many challenging control tasks, coping with nonlinear system dynamics, constraints, and observational noise. Despite their success, these methods often rely on simple control distributions, which can limit their performance in highly uncertain and complex environments. MPC frameworks must be able to accommodate changing distributions over system parameters, based on the most recent measurements. In this paper, we devise an implicit variational inference algorithm able to estimate distributions over model parameters and control inputs on-the-fly. The method incorporates Stein Variational gradient descent to approximate the target distributions as a collection of particles, and performs updates based on a Bayesian formulation. This enables the approximation of complex multi-modal posterior distributions, typically occurring in challenging and realistic robot navigation tasks. We demonstrate our approach on both simulated and real-world experiments requiring real-time execution in the face of dynamically changing environments.},
	urldate = {2021-06-30},
	journal = {arXiv:2103.12890 [cs]},
	author = {Barcelos, Lucas and Lambert, Alexander and Oliveira, Rafael and Borges, Paulo and Boots, Byron and Ramos, Fabio},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.12890},
	keywords = {Computer Science - Robotics},
	annote = {Comment: Corresponding author: lucas.barcelos@sydney.edu.au},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/XEYAVZZ7/Barcelos et al. - 2021 - Dual Online Stein Variational Inference for Contro.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/RYZDEYSS/2103.html:text/html},
}

@inproceedings{okadaVariational2020,
	title = {Variational {Inference} {MPC} for {Bayesian} {Model}-based {Reinforcement} {Learning}},
	url = {http://proceedings.mlr.press/v100/okada20a.html},
	abstract = {In recent studies on model-based reinforcement learning (MBRL), incorporating uncertainty in forward dynamics is a state-of-the-art strategy to enhance learning performance, making MBRLs competitiv...},
	language = {en},
	urldate = {2021-06-30},
	booktitle = {Conference on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Okada, Masashi and Taniguchi, Tadahiro},
	month = may,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {258--272},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/4R3LXT8H/Okada and Taniguchi - 2020 - Variational Inference MPC for Bayesian Model-based.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/XWZNGU6G/okada20a.html:text/html},
}

@article{almubarakSafety2021,
	title = {Safety {Embedded} {Differential} {Dynamic} {Programming} using {Discrete} {Barrier} {States}},
	url = {http://arxiv.org/abs/2105.14608},
	abstract = {Certified safe control is a growing challenge in robotics, especially when performance and safety objectives are desired to be concurrently achieved. In this work, we extend the barrier state (BaS) concept, recently proposed for stabilization of continuous time systems, to enforce safety for discrete time systems by creating a discrete barrier state (DBaS). The constructed DBaS is embedded into the discrete model of the safety-critical system in order to integrate safety objectives into performance objectives. We subsequently use the proposed technique to implement a safety embedded stabilizing control for nonlinear discrete systems. Furthermore, we employ the DBaS method to develop a safety embedded differential dynamic programming (DDP) technique to plan and execute safe optimal trajectories. The proposed algorithm is leveraged on a differential wheeled robot and on a quadrotor to safely perform several tasks including reaching, tracking and safe multi-quadrotor movement. The DBaS-based DDP (DBaS-DDP) is compared to the penalty method used in constrained DDP problems where it is shown that the DBaS-DDP consistently outperforms the penalty method.},
	urldate = {2021-06-30},
	journal = {arXiv:2105.14608 [cs, eess]},
	author = {Almubarak, Hassan and Stachowicz, Kyle and Sadegh, Nader and Theodorou, Evangelos A.},
	month = may,
	year = {2021},
	note = {arXiv: 2105.14608},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/3JZHF338/Almubarak et al. - 2021 - Safety Embedded Differential Dynamic Programming u.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/QN5N9CF7/2105.html:text/html},
}

@article{almubarakSafety2021a,
	title = {Safety {Embedded} {Control} of {Nonlinear} {Systems} via {Barrier} {States}},
	url = {http://arxiv.org/abs/2102.10253},
	abstract = {In many safety critical control systems, possibly opposing safety restrictions and control performance objectives may arise. To confront such a conflict, this paper proposes a methodology that embeds safety into stability of control systems. The development enforces safety by means of barrier functions used in optimization which are used to construct {\textbackslash}textit\{barrier states\} (BaS) that are {\textbackslash}textit\{embedded\} in the control system's model. As a result, as long as the equilibrium point of interest of the closed loop system is asymptotically stable, the generated trajectories are guaranteed to be safe. Consequently, a conflict between control objectives and safety constraints is substantially avoided. To show the efficacy of the proposed technique, we employ the simple pole placement method on a linear control system to generate a safely stabilizing controller. Optimal control is subsequently employed to fulfill safety, stability and performance objectives by solving the associated Hamilton-Jacobi-Bellman (HJB) which minimizes a cost functional that can involve the barrier states. Following this further, we exploit optimal control on a second dimensional pendulum on a cart model that is desired to avoid low velocities regions where the system may exhibit some controllability loss and on two simple mobile robots that are sent to opposite targets with an obstacle on the way which may potentially result in a collision.},
	urldate = {2021-06-30},
	journal = {arXiv:2102.10253 [cs, eess]},
	author = {Almubarak, Hassan and Sadegh, Nader and Theodorou, Evangelos A.},
	month = mar,
	year = {2021},
	note = {arXiv: 2102.10253},
	keywords = {Electrical Engineering and Systems Science - Systems and Control},
	annote = {Comment: Updates: Corrected typos. Revised arguments in Section III and Section IV},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/3L49BDYL/Almubarak et al. - 2021 - Safety Embedded Control of Nonlinear Systems via B.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/NXP4GVNR/2102.html:text/html},
}

@article{levineReinforcement2018,
	title = {Reinforcement {Learning} and {Control} as {Probabilistic} {Inference}: {Tutorial} and {Review}},
	shorttitle = {Reinforcement {Learning} and {Control} as {Probabilistic} {Inference}},
	abstract = {The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.},
	journal = {ArXiv},
	author = {Levine, Sergey},
	year = {2018},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/74K38XL7/Levine - 2018 - Reinforcement Learning and Control as Probabilisti.pdf:application/pdf},
}

@inproceedings{chuaDeep2018,
	title = {Deep {Reinforcement} {Learning} in a {Handful} of {Trials} using {Probabilistic} {Dynamics} {Models}},
	volume = {31},
	url = {https://papers.nips.cc/paper/2018/hash/3de568f8597b94bda53149c7d7f5958c-Abstract.html},
	language = {en},
	urldate = {2021-07-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
	year = {2018},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/K5RIDAIK/Chua et al. - 2018 - Deep Reinforcement Learning in a Handful of Trials.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/GPK99BVP/3de568f8597b94bda53149c7d7f5958c-Abstract.html:text/html},
}

@book{sutton2018reinforcement,
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning, second edition: {An} introduction},
	isbn = {978-0-262-35270-3},
	url = {https://books.google.co.uk/books?id=uWV0DwAAQBAJ},
	publisher = {MIT Press},
	author = {Sutton, R.S. and Barto, A.G.},
	year = {2018},
}

@incollection{patilScaling2015,
	address = {Cham},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Scaling up {Gaussian} {Belief} {Space} {Planning} {Through} {Covariance}-{Free} {Trajectory} {Optimization} and {Automatic} {Differentiation}},
	isbn = {978-3-319-16595-0},
	url = {https://doi.org/10.1007/978-3-319-16595-0_30},
	abstract = {Belief space planning provides a principled framework to compute motion plans that explicitly gather information from sensing, as necessary, to reduce uncertainty about the robot and the environment. We consider the problem of planning in Gaussian belief spaces, which are parameterized in terms of mean states and covariances describing the uncertainty. In this work, we show that it is possible to compute locally optimal plans without including the covariance in direct trajectory optimization formulations of the problem. As a result, the dimensionality of the problem scales linearly in the state dimension instead of quadratically, as would be the case if we were to include the covariance in the optimization. We accomplish this by taking advantage of recent advances in numerical optimal control that include automatic differentiation and state of the art convex solvers. We show that the running time of each optimization step of the covariance-free trajectory optimization is 𝑂(𝑛3𝑇)O(n3T)O(n{\textasciicircum}3T), where 𝑛nn is the dimension of the state space and 𝑇TT is the number of time steps in the trajectory. We present experiments in simulation on a variety of planning problems under uncertainty including manipulator planning, estimating unknown model parameters for dynamical systems, and active simultaneous localization and mapping (active SLAM). Our experiments suggest that our method can solve planning problems in 100100100 dimensional state spaces and obtain computational speedups of 400×400×400{\textbackslash}times over related trajectory optimization methods .},
	language = {en},
	urldate = {2021-07-13},
	booktitle = {Algorithmic {Foundations} of {Robotics} {XI}: {Selected} {Contributions} of the {Eleventh} {International} {Workshop} on the {Algorithmic} {Foundations} of {Robotics}},
	publisher = {Springer International Publishing},
	author = {Patil, Sachin and Kahn, Gregory and Laskey, Michael and Schulman, John and Goldberg, Ken and Abbeel, Pieter},
	editor = {Akin, H. Levent and Amato, Nancy M. and Isler, Volkan and van der Stappen, A. Frank},
	year = {2015},
	doi = {10.1007/978-3-319-16595-0_30},
	keywords = {Automatic Differentiation, Model Predictive Control, Optimal Control Method, Sequential Quadratic Programming, Trajectory Optimization},
	pages = {515--533},
	file = {Submitted Version:/Users/aidanscannell/Zotero/storage/5T8GHMQX/Patil et al. - 2015 - Scaling up Gaussian Belief Space Planning Through .pdf:application/pdf},
}

@inproceedings{chengEndtoEnd2019,
	title = {End-to-{End} {Safe} {Reinforcement} {Learning} through {Barrier} {Functions} for {Safety}-{Critical} {Continuous} {Control} {Tasks}},
	doi = {10.1609/aaai.v33i01.33013387},
	abstract = {Reinforcement Learning (RL) algorithms have found limited success beyond simulated applications, and one main reason is the absence of safety guarantees during the learning process. Real world systems would realistically fail or break before an optimal controller can be learned. To address this issue, we propose a controller architecture that combines (1) a model-free RL-based controller with (2) model-based controllers utilizing control barrier functions (CBFs) and (3) on-line learning of the unknown system dynamics, in order to ensure safety during learning. Our general framework leverages the success of RL algorithms to learn high-performance controllers, while the CBF-based controllers both guarantee safety and guide the learning process by constraining the set of explorable polices. We utilize Gaussian Processes (GPs) to model the system dynamics and its uncertainties. 
Our novel controller synthesis algorithm, RL-CBF, guarantees safety with high probability during the learning process, regardless of the RL algorithm used, and demonstrates greater policy exploration efficiency. We test our algorithm on (1) control of an inverted pendulum and (2) autonomous car-following with wireless vehicle-to-vehicle communication, and show that our algorithm attains much greater sample efficiency in learning than other state-of-the-art algorithms and maintains safety during the entire learning process.},
	booktitle = {{AAAI}},
	author = {Cheng, Richard and Orosz, G. and Murray, R. and Burdick, J.},
	year = {2019},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/AAV4CC6T/Cheng et al. - 2019 - End-to-End Safe Reinforcement Learning through Bar.pdf:application/pdf},
}

@inproceedings{toussaintRobot2009,
	title = {Robot {Trajectory} {Optimization} using {Approximate} {Inference}},
	abstract = {The general stochastic optimal control (SOC) problem in robotics scenarios is often too complex to be solved exactly and in near real time. A classical approximate solution is to first compute an optimal (deterministic) trajectory and then solve a local linear-quadratic-gaussian (LQG) perturbation model to handle the system stochasticity. We present a new algorithm for this approach which improves upon previous algorithms like iLQG. We consider a probabilistic model for which the maximum likelihood (ML) trajectory coincides with the optimal trajectory and which, in the LQG case, reproduces the classical SOC solution. The algorithm then utilizes approximate inference methods (similar to expectation propagation) that efficiently generalize to non-LQG systems. We demonstrate the algorithm on a simulated 39-DoF humanoid robot. 1.},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Toussaint, Marc},
	year = {2009},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/9HG93BHX/Toussaint - Robot Trajectory Optimization using Approximate In.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/G6S25WB6/summary.html:text/html},
}

@inproceedings{rawlikStochastic2013,
	title = {On {Stochastic} {Optimal} {Control} and {Reinforcement} {Learning} by {Approximate} {Inference} ({Extended} {Abstract})},
	abstract = {We present a reformulation of the stochastic optimal control problem in terms of KL divergence minimisation, not only providing a unifying perspective of previous approaches in this area, but also demonstrating that the formalism leads to novel practical approaches to the control problem. Speciﬁcally, a natural relaxation of the dual formulation gives rise to exact iterative solutions to the ﬁnite and inﬁnite horizon stochastic optimal control problem, while direct application of Bayesian inference methods yields instances of risk sensitive control.},
	language = {en},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Artificial} {Intelligence}},
	author = {Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
	year = {2013},
	pages = {5},
	file = {Rawlik et al. - On Stochastic Optimal Control and Reinforcement Le.pdf:/Users/aidanscannell/Zotero/storage/XRQ3NLZ6/Rawlik et al. - On Stochastic Optimal Control and Reinforcement Le.pdf:application/pdf},
}

@article{mukadamContinuoustime2018,
	title = {Continuous-time {Gaussian} process motion planning via probabilistic inference},
	volume = {37},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364918790369},
	doi = {10.1177/0278364918790369},
	abstract = {We introduce a novel formulation of motion planning, for continuous-time trajectories, as probabilistic inference. We first show how smooth continuous-time trajectories can be represented by a small number of states using sparse Gaussian process (GP) models. We next develop an efficient gradient-based optimization algorithm that exploits this sparsity and GP interpolation. We call this algorithm the Gaussian Process Motion Planner (GPMP). We then detail how motion planning problems can be formulated as probabilistic inference on a factor graph. This forms the basis for GPMP2, a very efficient algorithm that combines GP representations of trajectories with fast, structure-exploiting inference via numerical optimization. Finally, we extend GPMP2 to an incremental algorithm, iGPMP2, that can efficiently replan when conditions change. We benchmark our algorithms against several sampling-based and trajectory optimization-based motion planning algorithms on planning problems in multiple environments. Our evaluation reveals that GPMP2 is several times faster than previous algorithms while retaining robustness. We also benchmark iGPMP2 on replanning problems, and show that it can find successful solutions in a fraction of the time required by GPMP2 to replan from scratch.},
	language = {en},
	number = {11},
	urldate = {2021-07-29},
	journal = {The International Journal of Robotics Research},
	author = {Mukadam, Mustafa and Dong, Jing and Yan, Xinyan and Dellaert, Frank and Boots, Byron},
	month = sep,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {Gaussian processes, trajectory optimization, factor graphs, Motion planning, probabilistic inference},
	pages = {1319--1340},
	file = {SAGE PDF Full Text:/Users/aidanscannell/Zotero/storage/GB3VYF5E/Mukadam et al. - 2018 - Continuous-time Gaussian process motion planning v.pdf:application/pdf},
}

@inproceedings{dongMotion2016,
	title = {Motion {Planning} as {Probabilistic} {Inference} using {Gaussian} {Processes} and {Factor} {Graphs}},
	doi = {10.15607/RSS.2016.XII.001},
	abstract = {With the increased use of high degree-of-freedom robots that must perform tasks in real-time, there is a need for fast algorithms for motion planning. In this work, we view motion planning from a probabilistic perspective. We consider smooth continuous-time trajectories as samples from a Gaussian process (GP) and formulate the planning problem as probabilistic inference. We use factor graphs and numerical optimization to perform inference quickly, and we show how GP interpolation can further increase the speed of the algorithm. Our framework also allows us to incrementally update the solution of the planning problem to contend with changing conditions. We benchmark our algorithm against several recent trajectory optimization algorithms on planning problems in multiple environments. Our evaluation reveals that our approach is several times faster than previous algorithms while retaining robustness. Finally, we demonstrate the incremental version of our algorithm on replanning problems, and show that it often can find successful solutions in a fraction of the time required to replan from scratch.},
	booktitle = {Robotics: {Science} and {Systems}},
	author = {Dong, Jing and Mukadam, Mustafa and Dellaert, F. and Boots, Byron},
	year = {2016},
	file = {Full Text:/Users/aidanscannell/Zotero/storage/TYZB7HUM/Dong et al. - 2016 - Motion Planning as Probabilistic Inference using G.pdf:application/pdf},
}

@inproceedings{bhardwajDifferentiable2020,
	title = {Differentiable {Gaussian} {Process} {Motion} {Planning}},
	doi = {10.1109/ICRA40945.2020.9197260},
	abstract = {Modern trajectory optimization based approaches to motion planning are fast, easy to implement, and effective on a wide range of robotics tasks. However, trajectory optimization algorithms have parameters that are typically set in advance (and rarely discussed in detail). Setting these parameters properly can have a significant impact on the practical performance of the algorithm, sometimes making the difference between finding a feasible plan or failing at the task entirely. We propose a method for leveraging past experience to learn how to automatically adapt the parameters of Gaussian Process Motion Planning (GPMP) algorithms. Specifically, we propose a differentiable extension to the GPMP2 algorithm, so that it can be trained end-to-end from data. We perform several experiments that validate our algorithm and illustrate the benefits of our proposed learning-based approach to motion planning.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bhardwaj, Mohak and Boots, Byron and Mukadam, Mustafa},
	month = may,
	year = {2020},
	note = {ISSN: 2577-087X},
	keywords = {Gaussian processes, Robots, Trajectory optimization, Artificial intelligence, Automation, Conferences, Planning},
	pages = {10598--10604},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/CB972CMQ/9197260.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/Z83QZZAC/Bhardwaj et al. - 2020 - Differentiable Gaussian Process Motion Planning.pdf:application/pdf},
}

@inproceedings{schreiterSafe2015,
	address = {Cham},
	title = {Safe {Exploration} for {Active} {Learning} with {Gaussian} {Processes}},
	isbn = {978-3-319-23461-8},
	doi = {10.1007/978-3-319-23461-8_9},
	abstract = {In this paper, the problem of safe exploration in the active learning context is considered. Safe exploration is especially important for data sampling from technical and industrial systems, e.g. combustion engines and gas turbines, where critical and unsafe measurements need to be avoided. The objective is to learn data-based regression models from such technical systems using a limited budget of measured, i.e. labelled, points while ensuring that critical regions of the considered systems are avoided during measurements. We propose an approach for learning such models and exploring new data regions based on Gaussian processes (GP’s). In particular, we employ a problem specific GP classifier to identify safe and unsafe regions, while using a differential entropy criterion for exploring relevant data regions. A theoretical analysis is shown for the proposed algorithm, where we provide an upper bound for the probability of failure. To demonstrate the efficiency and robustness of our safe exploration scheme in the active learning setting, we test the approach on a policy exploration task for the inverse pendulum hold up problem.},
	language = {en},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Schreiter, Jens and Nguyen-Tuong, Duy and Eberts, Mona and Bischoff, Bastian and Markert, Heiner and Toussaint, Marc},
	year = {2015},
	keywords = {Decision Boundary, Discriminative Function, Exploration Scheme, Gaussian Process, Input Space},
	pages = {133--149},
	file = {Springer Full Text PDF:/Users/aidanscannell/Zotero/storage/8HEA83P2/Schreiter et al. - 2015 - Safe Exploration for Active Learning with Gaussian.pdf:application/pdf},
}

@inproceedings{watsonStochastic2020,
	title = {Stochastic {Optimal} {Control} as {Approximate} {Input} {Inference}},
	url = {http://proceedings.mlr.press/v100/watson20a.html},
	language = {en},
	urldate = {2021-08-03},
	booktitle = {Conference on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Watson, Joe and Abdulsamad, Hany and Peters, Jan},
	month = may,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {697--716},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/AQK5B45X/Watson et al. - 2020 - Stochastic Optimal Control as Approximate Input In.pdf:application/pdf},
}

@article{krauseNearOptimal2008,
	title = {Near-{Optimal} {Sensor} {Placements} in {Gaussian} {Processes}: {Theory}, {Efficient} {Algorithms} and {Empirical} {Studies}},
	volume = {9},
	shorttitle = {Near-{Optimal} {Sensor} {Placements} in {Gaussian} {Processes}},
	url = {http://jmlr.org/papers/v9/krause08a.html},
	abstract = {When monitoring spatial phenomena, which can often be modeled as
Gaussian processes (GPs), choosing sensor locations is a fundamental
task. There are several common strategies to address this task, for
example, geometry or disk models, placing sensors at the points of
highest entropy (variance) in the GP model, and A-, D-, or E-optimal
design. In this paper, we tackle the combinatorial optimization
problem of maximizing the mutual information between the
chosen locations and the locations which are not selected. We prove
that the problem of finding the configuration that maximizes mutual
information is NP-complete. To address this issue, we describe a
polynomial-time approximation that is within (1-1/e) of the
optimum by exploiting the submodularity of mutual
information. We also show how submodularity can be used to obtain
online bounds, and design branch and bound search procedures. We
then extend our algorithm to exploit lazy evaluations and local
structure in the GP, yielding significant speedups. We also extend
our approach to find placements which are robust against node
failures and uncertainties in the model. These extensions are again
associated with rigorous theoretical approximation guarantees,
exploiting the submodularity of the objective function. We
demonstrate the advantages of our approach towards optimizing mutual
information in a very extensive empirical study on two real-world
data sets.},
	number = {8},
	urldate = {2021-08-04},
	journal = {Journal of Machine Learning Research},
	author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
	year = {2008},
	pages = {235--284},
	file = {Fulltext PDF:/Users/aidanscannell/Zotero/storage/LRZX27GX/Krause et al. - 2008 - Near-Optimal Sensor Placements in Gaussian Process.pdf:application/pdf},
}

@inproceedings{ertinMaximum2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Maximum {Mutual} {Information} {Principle} for {Dynamic} {Sensor} {Query} {Problems}},
	isbn = {978-3-540-36978-3},
	doi = {10.1007/3-540-36978-3_27},
	abstract = {In this paper we study a dynamic sensor selection method for Bayesian filtering problems. In particular we consider the distributed Bayesian Filtering strategy given in [1] and show that the principle of mutual information maximization follows naturally from the expected uncertainty minimization criterion in a Bayesian filtering framework. This equivalence results in a computationally feasible approach to state estimation in sensor networks. We illustrate the application of the proposed dynamic sensor selection method to both discrete and linear Gaussian models for distributed tracking as well as to stationary target localization using acoustic arrays.},
	language = {en},
	booktitle = {Information {Processing} in {Sensor} {Networks}},
	publisher = {Springer},
	author = {Ertin, Emre and Fisher, John W. and Potter, Lee C.},
	editor = {Zhao, Feng and Guibas, Leonidas},
	year = {2003},
	keywords = {Mutual Information, Sensor Measurement, Sensor Network, Sensor Node, State Space Model},
	pages = {405--416},
	file = {Springer Full Text PDF:/Users/aidanscannell/Zotero/storage/R5MFG3MW/Ertin et al. - 2003 - Maximum Mutual Information Principle for Dynamic S.pdf:application/pdf},
}

@book{coverElements2006,
	title = {Elements of information theory},
	publisher = {John Wiley \& Sons},
	author = {Cover, M., Thomas and Joy, A., Thomas},
	year = {2006},
}

@article{watsonStochastic2021,
	title = {Stochastic {Control} through {Approximate} {Bayesian} {Input} {Inference}},
	url = {http://arxiv.org/abs/2105.07693},
	abstract = {Optimal control under uncertainty is a prevailing challenge in control, due to the difficulty in producing tractable solutions for the stochastic optimization problem. By framing the control problem as one of input estimation, advanced approximate inference techniques can be used to handle the statistical approximations in a principled and practical manner. Analyzing the Gaussian setting, we present a solver capable of several stochastic control methods, and was found to be superior to popular baselines on nonlinear simulated tasks. We draw connections that relate this inference formulation to previous approaches for stochastic optimal control, and outline several advantages that this inference view brings due to its statistical nature.},
	urldate = {2021-08-04},
	journal = {arXiv:2105.07693 [cs, eess]},
	author = {Watson, Joe and Abdulsamad, Hany and Findeisen, Rolf and Peters, Jan},
	month = may,
	year = {2021},
	note = {arXiv: 2105.07693},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	annote = {Comment: Submitted to Transactions on Automatic Control Special Issue: Learning and Control. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/HSJRT7F9/Watson et al. - 2021 - Stochastic Control through Approximate Bayesian In.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/ATILHJPE/2105.html:text/html},
}

@inproceedings{levineVariational2013,
	title = {Variational {Policy} {Search} via {Trajectory} {Optimization}},
	volume = {26},
	url = {https://proceedings.neurips.cc/paper/2013/hash/38af86134b65d0f10fe33d30dd76442e-Abstract.html},
	language = {en},
	urldate = {2021-08-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Levine, Sergey and Koltun, Vladlen},
	year = {2013},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/LHGXIJIL/Levine and Koltun - 2013 - Variational Policy Search via Trajectory Optimizat.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/RSGHGXI9/38af86134b65d0f10fe33d30dd76442e-Abstract.html:text/html},
}

@misc{williamsAdvancing,
	title = {Advancing {Trajectory} {Optimization} with {Approximate} {Inference}: {Exploration}, {Covariance} {Control} and {Adaptive} {Risk}},
	shorttitle = {Advancing {Trajectory} {Optimization} with {Approximate} {Inference}},
	url = {https://is.mpg.de},
	abstract = {Our goal is to understand the principles of Perception, Action and Learning in autonomous systems that successfully interact with complex environments and to use this understanding to design future systems.},
	language = {en},
	urldate = {2021-08-04},
	journal = {Max Planck Institute for Intelligent Systems},
	author = {Williams, Jon},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/RT8WP95Y/watpet21.html:text/html},
}

@inproceedings{watsonAdvancing2021,
	title = {Advancing {Trajectory} {Optimization} with {Approximate} {Inference}: {Exploration}, {Covariance} {Control} and {Adaptive} {Risk}},
	shorttitle = {Advancing {Trajectory} {Optimization} with {Approximate} {Inference}},
	url = {http://arxiv.org/abs/2103.06319},
	abstract = {Discrete-time stochastic optimal control remains a challenging problem for general, nonlinear systems under significant uncertainty, with practical solvers typically relying on the certainty equivalence assumption, replanning and/or extensive regularization. Control as inference is an approach that frames stochastic control as an equivalent inference problem, and has demonstrated desirable qualities over existing methods, namely in exploration and regularization. We look specifically at the input inference for control (i2c) algorithm, and derive three key characteristics that enable advanced trajectory optimization: An `expert' linear Gaussian controller that combines the benefits of open-loop optima and closed-loop variance reduction when optimizing for nonlinear systems, inherent adaptive risk sensitivity from the inference formulation, and covariance control functionality with only a minor algorithmic adjustment.},
	urldate = {2021-08-04},
	booktitle = {American {Control} {Conference} ({ACC})},
	author = {Watson, Joe and Peters, Jan},
	year = {2021},
	note = {arXiv: 2103.06319
version: 1},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	annote = {Comment: American Control Conference (ACC) 2021},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/WLS2UV6J/Watson and Peters - 2021 - Advancing Trajectory Optimization with Approximate.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/HBV63NMC/2103.html:text/html},
}

@inproceedings{krauseNonmyopic2007,
	address = {New York, NY, USA},
	series = {{ICML} '07},
	title = {Nonmyopic active learning of {Gaussian} processes: an exploration-exploitation approach},
	isbn = {978-1-59593-793-3},
	shorttitle = {Nonmyopic active learning of {Gaussian} processes},
	url = {https://doi.org/10.1145/1273496.1273553},
	doi = {10.1145/1273496.1273553},
	abstract = {When monitoring spatial phenomena, such as the ecological condition of a river, deciding where to make observations is a challenging task. In these settings, a fundamental question is when an active learning, or sequential design, strategy, where locations are selected based on previous measurements, will perform significantly better than sensing at an a priori specified set of locations. For Gaussian Processes (GPs), which often accurately model spatial phenomena, we present an analysis and efficient algorithms that address this question. Central to our analysis is a theoretical bound which quantifies the performance difference between active and a priori design strategies. We consider GPs with unknown kernel parameters and present a nonmyopic approach for trading off exploration, i.e., decreasing uncertainty about the model parameters, and exploitation, i.e., near-optimally selecting observations when the parameters are (approximately) known. We discuss several exploration strategies, and present logarithmic sample complexity bounds for the exploration phase. We then extend our algorithm to handle nonstationary GPs exploiting local structure in the model. We also present extensive empirical evaluation on several real-world problems.},
	urldate = {2021-08-04},
	booktitle = {Proceedings of the 24th international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Krause, Andreas and Guestrin, Carlos},
	month = jun,
	year = {2007},
	pages = {449--456},
	file = {Submitted Version:/Users/aidanscannell/Zotero/storage/74BTCB6D/Krause and Guestrin - 2007 - Nonmyopic active learning of Gaussian processes a.pdf:application/pdf},
}

@article{klenskeDual2016,
	title = {Dual {Control} for {Approximate} {Bayesian} {Reinforcement} {Learning}},
	volume = {17},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v17/15-162.html},
	language = {en},
	number = {127},
	urldate = {2021-08-04},
	journal = {Journal of Machine Learning Research},
	author = {Klenske, Edgar D. and Hennig, Philipp},
	year = {2016},
	pages = {1--30},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/CG3X7PCY/Klenske and Hennig - 2016 - Dual Control for Approximate Bayesian Reinforcemen.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/6CPR4MF6/15-162.html:text/html},
}

@inproceedings{buisson-fenetActively2020,
	title = {Actively {Learning} {Gaussian} {Process} {Dynamics}},
	volume = {120},
	abstract = {Despite the availability of ever more data enabled through modern sensor and computer technology, it still remains an open problem to learn dynamical systems in a sample-efﬁcient way. We propose active learning strategies that leverage information-theoretical properties arising naturally during Gaussian process regression while respecting constraints on the sampling process imposed by the system dynamics. Sample points are selected in regions with high uncertainty, leading to exploratory behavior and data-efﬁcient training of the model. All results are validated in an extensive numerical benchmark.},
	language = {en},
	booktitle = {2nd {Annual} {Conference} on {Learning} for {Dynamics} and {Control}},
	publisher = {Proceedings of Machine Learning Research},
	author = {Buisson-Fenet, Mona and Solowjow, Friedrich and Trimpe, Sebastian},
	year = {2020},
	pages = {1--11},
	file = {Buisson-Fenet et al. - Actively Learning Gaussian Process Dynamics.pdf:/Users/aidanscannell/Zotero/storage/3LQUYRKQ/Buisson-Fenet et al. - Actively Learning Gaussian Process Dynamics.pdf:application/pdf},
}

@inproceedings{caponeLocalized2020,
	title = {Localized active learning of {Gaussian} process state space models},
	volume = {120:1-12},
	url = {http://arxiv.org/abs/2005.02191},
	abstract = {The performance of learning-based control techniques crucially depends on how effectively the system is explored. While most exploration techniques aim to achieve a globally accurate model, such approaches are generally unsuited for systems with unbounded state spaces. Furthermore, a globally accurate model is not required to achieve good performance in many common control applications, e.g., local stabilization tasks. In this paper, we propose an active learning strategy for Gaussian process state space models that aims to obtain an accurate model on a bounded subset of the state-action space. Our approach aims to maximize the mutual information of the exploration trajectories with respect to a discretization of the region of interest. By employing model predictive control, the proposed technique integrates information collected during exploration and adaptively improves its exploration strategy. To enable computational tractability, we decouple the choice of most informative data points from the model predictive control optimization step. This yields two optimization problems that can be solved in parallel. We apply the proposed method to explore the state space of various dynamical systems and compare our approach to a commonly used entropy-based exploration strategy. In all experiments, our method yields a better model within the region of interest than the entropy-based method.},
	urldate = {2021-08-05},
	booktitle = {2nd {Annual} {Conference} on {Learning} for {Dynamics} and {Control}},
	publisher = {Proceedings of Machine Learning Research},
	author = {Capone, Alexandre and Noske, Gerrit and Umlauft, Jonas and Beckers, Thomas and Lederer, Armin and Hirche, Sandra},
	year = {2020},
	note = {arXiv: 2005.02191},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Electrical Engineering and Systems Science - Systems and Control},
	annote = {Comment: Submitted to Learning for Dynamics and Control (L4DC)},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/HWFMG3WZ/Capone et al. - 2020 - Localized active learning of Gaussian process stat.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/J8WW4JNZ/2005.html:text/html},
}

@article{koExact1995,
	title = {An {Exact} {Algorithm} for {Maximum} {Entropy} {Sampling}},
	volume = {43},
	issn = {0030-364X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/opre.43.4.684},
	doi = {10.1287/opre.43.4.684},
	abstract = {We study the experimental design problem of selecting a most informative subset, having prespecified size, from a set of correlated random variables. The problem arises in many applied domains, such as meteorology, environmental statistics, and statistical geology. In these applications, observations can be collected at different locations, and possibly, at different times. Information is measured by “entropy.” In the Gaussian case, the problem is recast as that of maximizing the determinant of the covariance matrix of the chosen subset. We demonstrate that this problem is NP-hard. We establish an upper bound for the entropy, based on the eigenvalue interlacing property, and we incorporate this bound in a branch-and-bound algorithm for the exact solution of the problem. We present computational results for estimated covariance matrices that correspond to sets of environmental monitoring stations in the United States.},
	number = {4},
	urldate = {2021-08-06},
	journal = {Operations Research},
	author = {Ko, Chun-Wa and Lee, Jon and Queyranne, Maurice},
	month = aug,
	year = {1995},
	note = {Publisher: INFORMS},
	keywords = {facilities/equipment planning, location of environmental monitoring stations, maximum entropy sampling, nonlinear combinatorial optimization, programming, statistics},
	pages = {684--691},
}

@article{yuActive2021,
	title = {Active {Learning} in {Gaussian} {Process} {State} {Space} {Model}},
	url = {http://arxiv.org/abs/2108.00819},
	abstract = {We investigate active learning in Gaussian Process state-space models (GPSSM). Our problem is to actively steer the system through latent states by determining its inputs such that the underlying dynamics can be optimally learned by a GPSSM. In order that the most informative inputs are selected, we employ mutual information as our active learning criterion. In particular, we present two approaches for the approximation of mutual information for the GPSSM given latent states. The proposed approaches are evaluated in several physical systems where we actively learn the underlying non-linear dynamics represented by the state-space model.},
	urldate = {2021-08-06},
	journal = {arXiv:2108.00819 [cs, stat]},
	author = {Yu, Hon Sum Alec and Yao, Dingling and Zimmer, Christoph and Toussaint, Marc and Nguyen-Tuong, Duy},
	month = jul,
	year = {2021},
	note = {arXiv: 2108.00819},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2021},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/GQRXJZJA/Yu et al. - 2021 - Active Learning in Gaussian Process State Space Mo.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/XS273K4X/2108.html:text/html},
}

@article{houlsbyBayesian2011,
	title = {Bayesian {Active} {Learning} for {Classification} and {Preference} {Learning}},
	url = {http://arxiv.org/abs/1112.5745},
	abstract = {Information theoretic active learning has been widely studied for probabilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classification with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractability. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classifier (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classification problem, we extend our algorithm to Gaussian Process preference learning.},
	urldate = {2021-08-06},
	journal = {arXiv:1112.5745 [cs, stat]},
	author = {Houlsby, Neil and Huszár, Ferenc and Ghahramani, Zoubin and Lengyel, Máté},
	month = dec,
	year = {2011},
	note = {arXiv: 1112.5745
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/NWQLADHZ/Houlsby et al. - 2011 - Bayesian Active Learning for Classification and Pr.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/JGWGTBSD/1112.html:text/html},
}

@inproceedings{dasguptaAnalysis2005,
	title = {Analysis of a greedy active learning strategy},
	volume = {17},
	url = {https://proceedings.neurips.cc/paper/2004/hash/c61fbef63df5ff317aecdc3670094472-Abstract.html},
	urldate = {2021-08-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Dasgupta, Sanjoy},
	year = {2005},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/V7PKLZJS/Dasgupta - 2005 - Analysis of a greedy active learning strategy.pdf:application/pdf},
}

@article{nickischApproximations2008,
	title = {Approximations for {Binary} {Gaussian} {Process} {Classiﬁcation}},
	volume = {9},
	abstract = {We provide a comprehensive overview of many recent algorithms for approximate inference in Gaussian process models for probabilistic binary classiﬁcation. The relationships between several approaches are elucidated theoretically, and the properties of the different algorithms are corroborated by experimental results. We examine both 1) the quality of the predictive distributions and 2) the suitability of the different marginal likelihood approximations for model selection (selecting hyperparameters) and compare to a gold standard based on MCMC. Interestingly, some methods produce good predictive distributions although their marginal likelihood approximations are poor. Strong conclusions are drawn about the methods: The Expectation Propagation algorithm is almost always the method of choice unless the computational budget is very tight. We also extend existing methods in various ways, and provide unifying code implementing all approaches.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Nickisch, Hannes and Rasmussen, Carl Edward},
	year = {2008},
	pages = {2035--2078},
	file = {Nickisch and Rasmussen - Approximations for Binary Gaussian Process Classiﬁ.pdf:/Users/aidanscannell/Zotero/storage/R7ZVMTFH/Nickisch and Rasmussen - Approximations for Binary Gaussian Process Classiﬁ.pdf:application/pdf},
}

@article{Silverman1985,
	title = {Some aspects of the spline smoothing approach to non-parametric regression curve fitting},
	volume = {47},
	doi = {10.1111/j.2517-6161.1985.tb01327.x},
	abstract = {Non-parametric regression using cubic splines is an attractive, flexible and widely-applicable approach to curve estimation. Although the basic idea was formulated many years ago, the method is not as widely known or adopted as perhaps it should be. The topics and examples discussed in this paper are intended to promote the understanding and extend the practicability of the spline smoothing methodology. Particular subjects covered include the basic principles of the method; the relation with moving average and other smoothing methods; the automatic choice of the amount of smoothing; and the use of residuals for diagnostic checking and model adaptation. The question of providing inference regions for curves-and for relevant properties of curves–is approached via a finite-dimensional Bayesian formulation.},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Silverman, B W},
	year = {1985},
	note = {tex.mendeley-groups: GP/Mixture of GPs},
	keywords = {mcycle, motorcycle},
	pages = {1--21},
	file = {Silverman - 1985 - Some Aspects of the Spline Smoothing Approach to Non-Parametric Regression Curve Fitting:/Users/aidanscannell/Zotero/storage/GVBR4H9A/Silverman - 1985 - Some Aspects of the Spline Smoothing Approach to Non-Parametric Regression Curve Fitting.pdf:application/pdf},
}

@misc{jax2018github,
	title = {{JAX}: composable transformations of {Python}+{NumPy} programs},
	url = {http://github.com/google/jax},
	author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and Zhang, Qiao},
	year = {2018},
}

@inproceedings{toussaintProbabilistic2006,
	title = {Probabilistic inference for solving discrete and continuous state {Markov} {Decision} {Processes}},
	volume = {2006},
	doi = {10.1145/1143844.1143963},
	abstract = {Inference in Markov Decision Processes has recently received interest as a means to in- fer goals of an observed action, policy recog- nition, and also as a tool to compute poli- cies. A particularly interesting aspect of the approach is that any existing inference tech- nique in DBNs now becomes available for an- swering behavioral questions-including those on continuous, factorial, or hierarchical state representations. Here we present an Expecta- tion Maximization algorithm for computing optimal policies. Unlike previous approaches we can show that this actually optimizes the discounted expected future return for arbi- trary reward functions and without assuming an ad hoc finite total time. The algorithm is generic in that any inference technique can be utilized in the E-step. We demonstrate this for exact inference on a discrete maze and Gaussian belief state propagation in continu- ous stochastic optimal control problems.},
	author = {Toussaint, Marc and Storkey, Amos},
	month = jan,
	year = {2006},
	pages = {945--952},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/X266VYD8/Toussaint and Storkey - 2006 - Probabilistic inference for solving discrete and c.pdf:application/pdf},
}

@inproceedings{kappenOptimal2013,
	address = {Rome, Italy},
	series = {{ICAPS}'13},
	title = {Optimal control as a graphical model inference problem},
	abstract = {In this paper we show the identification between stochastic optimal control computation and probabilistic inference on a graphical model for certain class of control problems. We refer to these problems as Kullback-Leibler (KL) control problems. We illustrate how KL control can be used to model a multi-agent cooperative game for which optimal control can be approximated using belief propagation when exact inference is unfeasible.},
	urldate = {2021-08-31},
	booktitle = {Proceedings of the {Twenty}-{Third} {International} {Conference} on {International} {Conference} on {Automated} {Planning} and {Scheduling}},
	publisher = {AAAI Press},
	author = {Kappen, Hilbert J. and Gómez, Vicenç and Opper, Manfred},
	month = jun,
	year = {2013},
	note = {tex.ids= kappenOptimal2013a},
	pages = {472--473},
	file = {Springer Full Text PDF:/Users/aidanscannell/Zotero/storage/C4NPGFTC/Kappen et al. - 2012 - Optimal control as a graphical model inference pro.pdf:application/pdf},
}

@article{hennigProbabilistic2015,
	title = {Probabilistic numerics and uncertainty in computations},
	volume = {471},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2015.0142},
	doi = {10.1098/rspa.2015.0142},
	abstract = {We deliver a call to arms for probabilistic numerical methods: algorithms for numerical tasks, including linear algebra, integration, optimization and solving differential equations, that return uncertainties in their calculations. Such uncertainties, arising from the loss of precision induced by numerical calculation with limited time or hardware, are important for much contemporary science and industry. Within applications such as climate science and astrophysics, the need to make decisions on the basis of computations with large and complex data have led to a renewed focus on the management of numerical uncertainty. We describe how several seminal classic numerical methods can be interpreted naturally as probabilistic inference. We then show that the probabilistic view suggests new algorithms that can flexibly be adapted to suit application specifics, while delivering improved empirical performance. We provide concrete illustrations of the benefits of probabilistic numeric algorithms on real scientific problems from astrometry and astronomical imaging, while highlighting open problems with these new algorithms. Finally, we describe how probabilistic numerical methods provide a coherent framework for identifying the uncertainty in calculations performed with a combination of numerical algorithms (e.g. both numerical optimizers and differential equation solvers), potentially allowing the diagnosis (and control) of error sources in computations.},
	number = {2179},
	urldate = {2021-08-31},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Hennig, Philipp and Osborne, Michael A. and Girolami, Mark},
	month = jul,
	year = {2015},
	note = {Publisher: Royal Society},
	keywords = {probability, statistics, inference, numerical methods},
	pages = {20150142},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/3PDGNY4K/Hennig et al. - 2015 - Probabilistic numerics and uncertainty in computat.pdf:application/pdf},
}

@article{kalmanNew1960,
	title = {A {New} {Approach} to {Linear} {Filtering} and {Prediction} {Problems}},
	volume = {82},
	issn = {0021-9223},
	url = {https://doi.org/10.1115/1.3662552},
	doi = {10.1115/1.3662552},
	abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
	number = {1},
	urldate = {2021-08-31},
	journal = {Journal of Basic Engineering},
	author = {Kalman, R. E.},
	month = mar,
	year = {1960},
	pages = {35--45},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/S93L7H82/A-New-Approach-to-Linear-Filtering-and-Prediction.html:text/html},
}

@article{hoBayesian1964,
	title = {A {Bayesian} approach to problems in stochastic estimation and control},
	volume = {9},
	doi = {10.1109/JACC.1964.4168717},
	abstract = {In this paper, a general class of stochastic estimation and control problems is formulated from the Bayesian Decision-Theoretic viewpoint. A discussion as to how these problems can be solved step by step in principle and practice from this approach is presented. As a specific example, the closed form Wiener-Kalman solution for linear estimation in Gaussian noise is derived. The purpose of the paper is to show that the Bayesian approach provides; 1) a general unifying framework within which to pursue further researches in stochastic estimation and control problems, and 2) the necessary computations and difficulties that must be overcome for these problems. An example of a nonlinear, non-Gaussian estimation problem is also solved.},
	journal = {IEEE Transactions on Automatic Control},
	author = {Ho, Y. and Lee, R.},
	year = {1964},
	pages = {382--387},
}

@phdthesis{ziebartModeling2010,
	title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
	abstract = {Predicting human behavior from a small amount of training examples is a challenging machine learning problem. In this thesis, we introduce the principle of maximum causal entropy, a general technique for applying information theory to decision-theoretic, game-theoretic, and control settings where relevant information is sequentially revealed over time. This approach guarantees decision-theoretic performance by matching purposeful measures of behavior (Abbeel \& Ng, 2004), and/or enforces game-theoretic rationality constraints (Aumann, 1974), while otherwise being as uncertain as possible, which minimizes worst-case predictive log-loss (Grunwald \& Dawid, 2003). 
We derive probabilistic models for decision, control, and multi-player game settings using this approach. We then develop corresponding algorithms for efficient inference that include relaxations of the Bellman equation (Bellman, 1957), and simple learning algorithms based on convex optimization. We apply the models and algorithms to a number of behavior prediction tasks. Specifically, we present empirical evaluations of the approach in the domains of vehicle route preference modeling using over 100,000 miles of collected taxi driving data, pedestrian motion modeling from weeks of indoor movement data, and robust prediction of game play in stochastic multi-player games.},
	author = {Ziebart, Brian D.},
	year = {2010},
	file = {Ziebart - 2010 - Modeling purposeful adaptive behavior with the pri.pdf:/Users/aidanscannell/Zotero/storage/IS248UI6/Ziebart - 2010 - Modeling purposeful adaptive behavior with the pri.pdf:application/pdf},
}

@article{schonSystem2011,
	title = {System identification of nonlinear state-space models},
	volume = {47},
	issn = {00051098},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0005109810004279},
	doi = {10.1016/j.automatica.2010.10.013},
	abstract = {This paper is concerned with the parameter estimation of a general class of nonlinear dynamic systems in state-space form. More speciﬁcally, a Maximum Likelihood (ML) framework is employed and an Expectation Maximisation (EM) algorithm is derived to compute these ML estimates. The Expectation (E) step involves solving a nonlinear state estimation problem, where the smoothed estimates of the states are required. This problem lends itself perfectly to the particle smoother, which provide arbitrarily good estimates. The maximisation (M) step is solved using standard techniques from numerical optimisation theory. Simulation examples demonstrate the eﬃcacy of our proposed solution.},
	language = {en},
	number = {1},
	urldate = {2021-09-10},
	journal = {Automatica},
	author = {Schön, Thomas B. and Wills, Adrian and Ninness, Brett},
	month = jan,
	year = {2011},
	pages = {39--49},
	file = {Schön et al. - 2011 - System identification of nonlinear state-space mod.pdf:/Users/aidanscannell/Zotero/storage/GHK4KDGX/Schön et al. - 2011 - System identification of nonlinear state-space mod.pdf:application/pdf},
}

@inproceedings{ghahramaniLearning1999,
	title = {Learning {Nonlinear} {Dynamical} {Systems} using an {EM} {Algorithm}},
	abstract = {The Expectation Maximization (EM) algorithm is an iterative procedure for maximum likelihood parameter estimation from data sets with missing or hidden variables[2]. It has been applied to system identification in linear stochastic state-space models, where the state variables are hidden from the observer and both the state and the parameters of the model have to be estimated simultaneously [9]. We present a generalization of the EM algorithm for parameter estimation in nonlinear dynamical systems. The "expectation" step makes use of Extended Kalman Smoothing to estimate the state, while the "maximization" step re-estimates the parameters using these uncertain state estimates. In general, the nonlinear maximization step is difficult because it requires integrating out the uncertainty in the states. However, if Gaussian radial basis function (RBF) approximators are used to model the nonlinearities, the integrals become tractable and the maximization step can be solved via systems of linear equations.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 11},
	publisher = {MIT Press},
	author = {Ghahramani, Zoubin and Roweis, Sam T.},
	year = {1999},
	pages = {599--605},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/72TJ6IPJ/Ghahramani and Roweis - 1999 - Learning Nonlinear Dynamical Systems using an EM A.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/MX5NPPSJ/summary.html:text/html},
}

@article{shumwayAPPROACH1982,
	title = {{AN} {APPROACH} {TO} {TIME} {SERIES} {SMOOTHING} {AND} {FORECASTING} {USING} {THE} {EM} {ALGORITHM}},
	doi = {10.1111/J.1467-9892.1982.TB00349.X},
	abstract = {Abstract. An approach to smoothing and forecasting for time series with missing observations is proposed. For an underlying state-space model, the EM algorithm is used in conjunction with the conventional Kalman smoothed estimators to derive a simple recursive procedure for estimating the parameters by maximum likelihood. An example is given which involves smoothing and forecasting an economic series using the maximum likelihood estimators for the parameters.},
	journal = {Journal of Time Series Analysis},
	author = {Shumway, R. and Stoffer, D.},
	year = {1982},
}

@article{loeligerFactor2007,
	title = {The {Factor} {Graph} {Approach} to {Model}-{Based} {Signal} {Processing}},
	volume = {95},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2007.896497},
	abstract = {The message-passing approach to model-based signal processing is developed with a focus on Gaussian message passing in linear state-space models, which includes recursive least squares, linear minimum-mean-squared-error estimation, and Kalman filtering algorithms. Tabulated message computation rules for the building blocks of linear models allow us to compose a variety of such algorithms without additional derivations or computations. Beyond the Gaussian case, it is emphasized that the message-passing approach encourages us to mix and match different algorithmic techniques, which is exemplified by two different approaches - steepest descent and expectation maximization - to message passing through a multiplier node.},
	number = {6},
	journal = {Proceedings of the IEEE},
	author = {Loeliger, Hans-Andrea and Dauwels, Justin and Hu, Junli and Korl, Sascha and Ping, Li and Kschischang, Frank R.},
	month = jun,
	year = {2007},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {factor graphs, Algorithm design and analysis, Estimation, graphical models, Graphical models, Information technology, Kalman filtering, Kalman filters, Least squares approximation, Machine learning algorithms, message passing, Message passing, Signal design, signal processing, Signal processing, Signal processing algorithms},
	pages = {1295--1322},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/6ARVVJ8G/4282128.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/JBWKUUSB/Loeliger et al. - 2007 - The Factor Graph Approach to Model-Based Signal Pr.pdf:application/pdf},
}

@book{eduardof.Model2007,
	title = {Model {Predictive} {Control}},
	publisher = {Springer},
	author = {Eduardo F., Camacho and Carlos, Bordons},
	year = {2007},
}

@inproceedings{ghahramaniSwitching1996,
	title = {Switching {State}-{Space} {Models}},
	doi = {10.1007/978-0-387-35768-3_13},
	abstract = {We introduce a statistical model for times series data with nonlinear dynamics which iteratively segments the data into regimes with approximately linear dynamics and learns the parameters of each of those regimes. This model combines and generalizes two of the most widely used stochastic time series models{\textbar}the hidden Markov model and the linear dynamical system{\textbar}and is related to models that are widely used in the control and econometrics literatures. It can also be derived by extending the mixture of experts neural network model (Jacobs et al., 1991) to its fully dynamical version, in which both expert and gating networks are recurrent. Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact Expectation Maximization (EM) alogithm cannot be applied. However, we present a variational approximation which maximizes a lower bound on the log likelihood and makes use of both the forward\{\vphantom{\}}backward recursions for hidden Markov models and the Kalman lter recursions for linear dynamical systems.},
	author = {Ghahramani, Zoubin and Hinton, Geoffrey E.},
	year = {1996},
	file = {11-1999.pdf:/Users/aidanscannell/Zotero/storage/QDGJI8XS/11-1999.pdf:application/pdf},
}

@article{ghahramaniVariational1998,
	title = {Variational learning for switching state-space models},
	volume = {12},
	abstract = {We introduce a new statistical model for time series which iteratively segments data into regimes with approximately linear dynamics and learns the parameters of each of these linear regimes. This model combines and generalizes two of the most widely used stochastic time series models -- hidden Markov models and linear dynamical systems -- and is closely related to models that are widely used in the control and econometrics literatures. It can also be derived by extending the mixture of experts neural network (Jacobs et al., 1991) to its fully dynamical version, in which both expert and gating networks are recurrent. Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact Expectation Maximization (EM) algorithm cannot be applied. However, we present a variational approximation that maximizes a lower bound on the log likelihood and makes use of both the forward-backward recursions for hidden Markov models and the Kalman lter recursions for linear dynamical systems. We tested the algorithm both on artificial data sets and on a natural data set of respiration force from a patient with sleep apnea. The results suggest that variational approximations are a viable method for inference and learning in switching state-space models.},
	journal = {Neural Computation},
	author = {Ghahramani, Zoubin and Hinton, Geoffrey E.},
	year = {1998},
	pages = {963--996},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/D9J5HK5G/Ghahramani and Hinton - 1998 - Variational learning for switching state-space mod.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/P9IELXW9/summary.html:text/html},
}

@phdthesis{mcallisterBayesian2017,
	type = {Thesis},
	title = {Bayesian {Learning} for {Data}-{Efficient} {Control}},
	copyright = {All Rights Reserved},
	url = {https://www.repository.cam.ac.uk/handle/1810/269779},
	abstract = {Applications to learn control of unfamiliar dynamical systems with increasing autonomy are ubiquitous. From robotics, to finance, to industrial processing, autonomous learning helps obviate a heavy reliance on experts for system identification and controller design. Often real world systems are nonlinear, stochastic, and expensive to operate (e.g. slow, energy intensive, prone to wear and tear). Ideally therefore, nonlinear systems can be identified with minimal system interaction. This thesis considers data efficient autonomous learning of control of nonlinear, stochastic systems. Data efficient learning critically requires probabilistic modelling of dynamics. Traditional control approaches use deterministic models, which easily overfit data, especially small datasets. We use probabilistic Bayesian modelling to learn systems from scratch, similar to the PILCO algorithm, which achieved unprecedented data efficiency in learning control of several benchmarks. We extend PILCO in three principle ways. First, we learn control under significant observation noise by simulating a filtered control process using a tractably analytic framework of Gaussian distributions. In addition, we develop the ‘latent variable belief Markov decision process’ when filters must predict under real-time constraints. Second, we improve PILCO’s data efficiency by directing exploration with predictive loss uncertainty and Bayesian optimisation, including a novel approximation to the Gittins index. Third, we take a step towards data efficient learning of high-dimensional control using Bayesian neural networks (BNN). Experimentally we show although filtering mitigates adverse effects of observation noise, much greater performance is achieved when optimising controllers with evaluations faithful to reality: by simulating closed-loop filtered control if executing closed-loop filtered control. Thus, controllers are optimised w.r.t. how they are used, outperforming filters applied to systems optimised by unfiltered simulations. We show directed exploration improves data efficiency. Lastly, we show BNN dynamics models are almost as data efficient as Gaussian process models. Results show data efficient learning of high-dimensional control is possible as BNNs scale to high-dimensional state inputs.},
	language = {en},
	urldate = {2021-09-23},
	school = {Department of Engineering, University of Cambridge},
	author = {McAllister, Rowan},
	month = apr,
	year = {2017},
	doi = {10.17863/CAM.16688},
	note = {Accepted: 2017-11-28T16:41:59Z},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/JPLABBYW/McAllister - 2017 - Bayesian Learning for Data-Efficient Control.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/DM29JAFZ/269779.html:text/html},
}

@phdthesis{deisenrothEfficient2010,
	title = {Efficient {Reinforcement} {Learning} using {Gaussian} {Processes}},
	url = {https://deisenroth.cc/publication/deisenroth-2010-b/},
	language = {en-us},
	urldate = {2021-09-23},
	author = {Deisenroth, Marc},
	month = nov,
	year = {2010},
	file = {Deisenroth - 2019 - Efficient Reinforcement Learning using Gaussian Pr.pdf:/Users/aidanscannell/Zotero/storage/8K7J9N2Q/Deisenroth - 2019 - Efficient Reinforcement Learning using Gaussian Pr.pdf:application/pdf},
}

@phdthesis{damianouDeep2015,
	type = {phd},
	title = {Deep {Gaussian} {Processes} and {Variational} {Propagation} of {Uncertainty}},
	copyright = {cc\_by\_nc\_nd},
	url = {https://etheses.whiterose.ac.uk/9968/},
	abstract = {Uncertainty propagation across components of complex probabilistic models is vital for improving regularisation. Unfortunately, for many interesting models based on non-linear Gaussian processes (GPs), straightforward propagation of uncertainty is computationally and mathematically intractable. This thesis is concerned with solving this problem through developing novel variational inference approaches. 

From a modelling perspective, a key contribution of the thesis is the development of deep Gaussian processes (deep GPs). Deep GPs generalise several interesting GP-based models and, hence, motivate the development of uncertainty propagation techniques. In a deep GP, each layer is modelled as the output of a multivariate GP, whose inputs are governed by another GP. The resulting model is no longer a GP but, instead, can learn much more complex interactions between data. In contrast to other deep models, all the uncertainty in parameters and latent variables is marginalised out and both supervised and unsupervised learning is handled.

Two important special cases of a deep GP can equivalently be seen as its building components and, historically, were developed as such. Firstly, the variational GP-LVM is concerned with propagating uncertainty in Gaussian process latent variable models. Any observed inputs (e.g. temporal) can also be used to correlate the latent space posteriors. Secondly, this thesis develops manifold relevance determination (MRD) which considers a common latent space for multiple views. An adapted variational framework allows for strong model regularisation, resulting in rich latent space representations to be learned. The developed models are also equipped with algorithms that maximise the information communicated between their different stages using uncertainty propagation, to achieve improved learning when partially observed values are present. 

The developed methods are demonstrated in experiments with simulated and real data. The results show that the developed variational methodologies improve practical applicability by enabling automatic capacity control in the models, even when data are scarce.},
	language = {en},
	urldate = {2021-09-24},
	school = {University of Sheffield},
	author = {Damianou, Andreas},
	month = jul,
	year = {2015},
	file = {Damianou_Thesis.pdf:/Users/aidanscannell/Zotero/storage/GFC4KFMI/Damianou_Thesis.pdf:application/pdf;Full Text PDF:/Users/aidanscannell/Zotero/storage/6UA38AQH/Damianou - 2015 - Deep Gaussian Processes and Variational Propagatio.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/KMT7ZCPG/9968.html:text/html},
}

@article{julierUnscented2004,
	title = {Unscented filtering and nonlinear estimation},
	volume = {92},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2003.823141},
	abstract = {The extended Kalman filter (EKF) is probably the most widely used estimation algorithm for nonlinear systems. However, more than 35 years of experience in the estimation community has shown that is difficult to implement, difficult to tune, and only reliable for systems that are almost linear on the time scale of the updates. Many of these difficulties arise from its use of linearization. To overcome this limitation, the unscented transformation (UT) was developed as a method to propagate mean and covariance information through nonlinear transformations. It is more accurate, easier to implement, and uses the same order of calculations as linearization. This paper reviews the motivation, development, use, and implications of the UT.},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {Julier, S.J. and Uhlmann, J.K.},
	month = mar,
	year = {2004},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Control systems, Nonlinear systems, Nonlinear control systems, Target tracking, Navigation, Vehicles, Kalman filters, Chemical processes, Filtering, Particle tracking},
	pages = {401--422},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/IGQM2C8D/1271397.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/6TYL885C/Julier and Uhlmann - 2004 - Unscented filtering and nonlinear estimation.pdf:application/pdf},
}

@inproceedings{quinonero-candelaPropagation2003,
	title = {Propagation of uncertainty in {Bayesian} kernel models - application to multiple-step ahead forecasting},
	volume = {2},
	doi = {10.1109/ICASSP.2003.1202463},
	abstract = {The object of Bayesian modelling is predictive distribution, which, in a forecasting scenario, enables evaluation of forecasted values and their uncertainties. We focus on reliably estimating the predictive mean and variance of forecasted values using Bayesian kernel based models such as the Gaussian process and the relevance vector machine. We derive novel analytic expressions for the predictive mean and variance for Gaussian kernel shapes under the assumption of a Gaussian input distribution in the static case, and of a recursive Gaussian predictive density in iterative forecasting. The capability of the method is demonstrated for forecasting of time-series and compared to approximate methods.},
	booktitle = {2003 {IEEE} {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing}.},
	author = {Quinonero-Candela, Joaquin and Girard, A. and Larsen, J. and Rasmussen, C.E.},
	month = apr,
	year = {2003},
	note = {ISSN: 1520-6149},
	keywords = {Kernel, Predictive models, Uncertainty, Bayesian methods, Analysis of variance, Covariance matrix, Equations, Intelligent networks, Taylor series, Testing},
	pages = {II--701},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/8E99C732/1202463.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/MIKCW6A4/Candela et al. - 2003 - Propagation of uncertainty in Bayesian kernel mode.pdf:application/pdf},
}

@phdthesis{kussGaussian2006,
	title = {Gaussian {Process} {Models} for {Robust} {Regression}, {Classification}, and {Reinforcement} {Learning}},
	url = {https://is.mpg.de},
	abstract = {Our goal is to understand the principles of Perception, Action and Learning in autonomous systems that successfully interact with complex environments and to use this understanding to design future systems.},
	language = {en},
	urldate = {2021-09-24},
	school = {Technische Universität Darmstadt, Darmstadt, Germany},
	author = {Kuss, Malte},
	year = {2006},
	file = {Kuss - 2006 - Gaussian Process Models for Robust Regression, Cla.pdf:/Users/aidanscannell/Zotero/storage/PA5ZCPBF/Kuss - 2006 - Gaussian Process Models for Robust Regression, Cla.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/CE36ZCDW/4050.html:text/html},
}

@incollection{girardGaussian2003,
	address = {Vancouver, Canada},
	title = {Gaussian {Process} priors with uncertain inputs? {Application} to multiple-step ahead time series forecasting},
	isbn = {978-0-262-02550-8},
	url = {http://eprints.gla.ac.uk/3117/},
	abstract = {We consider the problem of multi-step ahead prediction in time series analysis using the non-parametric Gaussian process model. k-step ahead forecasting of a discrete-time non-linear dynamic system can be performed by doing repeated one-step ahead predictions. For a state-space model of the form y t = f(Yt-1 ,..., Yt-L ), the prediction of y at time t + k is based on the point estimates of the previous outputs. In this paper, we show how, using an analytical Gaussian approximation, we can formally incorporate the uncertainty about intermediate regressor values, thus updating the uncertainty on the current prediction.},
	language = {en},
	urldate = {2021-09-24},
	booktitle = {Becker, {S}},
	publisher = {MIT Press},
	author = {Girard, Agathe and Rasmussen, Carl Edward and Quinonero-Candela, Joaquin and Murray-Smith, Roderick},
	year = {2003},
	note = {Conference Name: Neural Information Processing Systems
Meeting Name: Neural Information Processing Systems
Publisher: MIT Press},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/2RIMIIAU/Girard et al. - 2003 - Gaussian Process priors with uncertain inputs App.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/36RXX8DX/3117.html:text/html},
}

@article{kingmaAdam2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2021-09-28},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/BA9JP6IL/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/R2QSRLK6/1412.html:text/html},
}

@phdthesis{rawlikProbabilistic2013,
	title = {On {Probabilistic} {Inference} {Approaches} to {Stochastic} {Optimal} {Control}},
	abstract = {While stochastic optimal control, together with associate formulations like Reinforcement Learning, provides a formal approach to, amongst other, motor control, it remains computationally challenging for most practical problems. This thesis is concerned with the study of relations between stochastic optimal control and probabilistic inference. Such dualities – exempliﬁed by the classical Kalman Duality between the Linear-Quadratic-Gaussian control problem and the ﬁltering problem in Linear-Gaussian dynamical systems – make it possible to exploit advances made within the separate ﬁelds. In this context, the emphasis in this work lies with utilisation of approximate inference methods for the control problem.},
	language = {en},
	school = {University of Edinburgh},
	author = {Rawlik, Konrad C},
	year = {2013},
	file = {Rawlik - On Probabilistic Inference Approaches to Stochasti.pdf:/Users/aidanscannell/Zotero/storage/H74IMGYX/Rawlik - On Probabilistic Inference Approaches to Stochasti.pdf:application/pdf},
}

@phdthesis{girardApproximate2004,
	title = {Approximate {Methods} for {Propagation} of {Uncertainty} with {Gaussian} {Process} {Models}},
	abstract = {This thesis presents extensions of the Gaussian Process (GP) model, based on approximate methods allowing the model to deal with input uncertainty. Zero-mean GPs with Gaussian covariance function are of particular interest, as they allow to carry out many derivations exactly, as well as having been shown to have modelling abilities and predictive performance comparable to that of neural networks (Rasmussen, 1996a). With this model, given observed data and a new input, making a prediction corresponds to computing the (Gaussian) predictive distribution of the associated output, whose mean can be used as an estimate. This way, the predictive variance provides error-bars or conﬁdence intervals on this estimate: It quantiﬁes the model’s degree of belief in its ‘best guess’. Using the knowledge of the predictive variance in an informative manner is at the centre of this thesis, as the problems of how to propagate it in the model, how to account for it when derivative observations are available, and how to derive a control law with a cautious behaviour are addressed.},
	language = {en},
	school = {University of Glasgow},
	author = {Girard, Agathe},
	year = {2004},
	file = {Girard - Approximate Methods for Propagation of Uncertainty.pdf:/Users/aidanscannell/Zotero/storage/HQFVDXPM/Girard - Approximate Methods for Propagation of Uncertainty.pdf:application/pdf},
}

@article{mackayBayesian1992,
	title = {Bayesian {Interpolation}},
	volume = {4},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1992.4.3.415},
	doi = {10.1162/neco.1992.4.3.415},
	abstract = {Although Bayesian analysis has been in use since Laplace, the Bayesian method of model-comparison has only recently been developed in depth. In this paper, the Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data. The concepts and methods described are quite general and can be applied to many other data modeling problems. Regularizing constants are set by examining their posterior probability distribution. Alternative regularizers (priors) and alternative basis sets are objectively compared by evaluating the evidence for them. “Occam's razor” is automatically embodied by this process. The way in which Bayes infers the values of regularizing constants and noise levels has an elegant interpretation in terms of the effective number of parameters determined by the data set. This framework is due to Gull and Skilling.},
	number = {3},
	urldate = {2021-10-13},
	journal = {Neural Computation},
	author = {MacKay, David J. C.},
	month = may,
	year = {1992},
	pages = {415--447},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/3GJG8PUA/MacKay - 1992 - Bayesian Interpolation.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/H5INT59A/Bayesian-Interpolation.html:text/html},
}

@article{mackayPractical1992,
	title = {A {Practical} {Bayesian} {Framework} for {Backpropagation} {Networks}},
	volume = {4},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1992.4.3.448},
	doi = {10.1162/neco.1992.4.3.448},
	abstract = {A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks. The framework makes possible (1) objective comparisons between solutions using alternative network architectures, (2) objective stopping rules for network pruning or growing procedures, (3) objective choice of magnitude and type of weight decay terms or additive regularizers (for penalizing large weights, etc.), (4) a measure of the effective number of well-determined parameters in a model, (5) quantified estimates of the error bars on network parameters and on network output, and (6) objective comparisons with alternative learning and interpolation models such as splines and radial basis functions. The Bayesian "evidence" automatically embodies "Occam's razor," penalizing overflexible and overcomplex models. The Bayesian approach helps detect poor underlying assumptions in learning models. For learning models well matched to a problem, a good correlation between generalization ability and the Bayesian evidence is obtained.},
	number = {3},
	urldate = {2021-10-13},
	journal = {Neural Computation},
	author = {MacKay, David J. C.},
	month = may,
	year = {1992},
	pages = {448--472},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/FME5SXC4/MacKay - 1992 - A Practical Bayesian Framework for Backpropagation.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/2BPFDD26/A-Practical-Bayesian-Framework-for-Backpropagation.html:text/html},
}

@article{mackayInformationBased1992,
	title = {Information-{Based} {Objective} {Functions} for {Active} {Data} {Selection}},
	volume = {4},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1992.4.4.590},
	doi = {10.1162/neco.1992.4.4.590},
	abstract = {Learning can be made more efficient if we can actively select particularly salient data points. Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements. Three alternative specifications of what we want to gain information about lead to three different criteria for data selection. All these criteria depend on the assumption that the hypothesis space is correct, which may prove to be their main weakness.},
	number = {4},
	urldate = {2021-10-13},
	journal = {Neural Computation},
	author = {MacKay, David J. C.},
	month = jul,
	year = {1992},
	pages = {590--604},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/NAF2ZXPE/MacKay - 1992 - Information-Based Objective Functions for Active D.pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/GL9H3DEV/Information-Based-Objective-Functions-for-Active.html:text/html},
}

@article{mackayProbable1995,
	title = {Probable networks and plausible predictions — a review of practical {Bayesian} methods for supervised neural networks},
	volume = {6},
	issn = {0954-898X},
	url = {https://doi.org/10.1088/0954-898x_6_3_011},
	doi = {10.1088/0954-898X/6/3/011},
	abstract = {Bayesian probability theory provides a unifying framework for data modelling. In this framework the overall aims are to find models that are well matched to the data, and to use these models to make optimal predictions. Neural network learning is interpreted as an inference of the most probable parameters for the model, given the training data. The search in model space (i.e., the space of architectures, noise models, preprocessings, regularizers and weight decay constants) can then also be treated as an inference problem, in which we infer the relative probability of alternative models, given the data. The article describes practical techniques based on Gaussian approximations for implementation of these powerful methods for controlling, comparing and using adaptive networks.},
	language = {en},
	number = {3},
	urldate = {2021-10-13},
	journal = {Network: Computation in Neural Systems},
	author = {Mackay, David J. C.},
	month = jan,
	year = {1995},
	note = {Publisher: Informa UK Limited},
	pages = {469--505},
}

@techreport{murrayNote2005,
	title = {A note on the evidence and {Bayesian} {Occam}’s razor},
	abstract = {Abstract—In his thesis, MacKay (1991) introduced figure 1, explaining how Bayes rule provides an automatic “Occam’s razor ” effect, penalizing unnecessarily complex models. This figure has been adopted by several authors in the same schematic form. Here, after briefly reviewing necessary material, we compute a realization of the plot for a toy data modeling problem. We discuss interesting aspects of this plot and their implications for understanding model complexity. I.},
	author = {Murray, Iain and Ghahramani, Zoubin},
	year = {2005},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/M5MRVENH/Murray and Ghahramani - 2005 - A note on the evidence and Bayesian Occam’s razor.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/RVURUM52/summary.html:text/html},
}

@inproceedings{rasmussenOccam2001,
	title = {Occam' s {Razor}},
	volume = {13},
	url = {https://proceedings.neurips.cc/paper/2000/hash/0950ca92a4dcf426067cfd2246bb5ff3-Abstract.html},
	urldate = {2021-10-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Rasmussen, Carl and Ghahramani, Zoubin},
	year = {2001},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/SYEYLMMN/Rasmussen and Ghahramani - 2001 - Occam' s Razor.pdf:application/pdf},
}

@inproceedings{trappDeep2020,
	title = {Deep {Structured} {Mixtures} of {Gaussian} {Processes}},
	url = {https://proceedings.mlr.press/v108/trapp20a.html},
	abstract = {Gaussian Processes (GPs) are powerful non-parametric Bayesian regression models that allow exact posterior inference, but exhibit high computational and memory costs. In order to improve scalability of GPs, approximate posterior inference is frequently employed, where a prominent class of approximation techniques is based on local GP experts. However, local-expert techniques proposed so far are either not well-principled, come with limited approximation guarantees, or lead to intractable models. In this paper, we introduce deep structured mixtures of GP experts, a stochastic process model which i) allows exact posterior inference, ii) has attractive computational and memory costs, and iii) when used as GP approximation, captures predictive uncertainties consistently better than previous expert-based approximations. In a variety of experiments, we show that deep structured mixtures have a low approximation error and often perform competitive or outperform prior work.},
	language = {en},
	urldate = {2021-10-14},
	booktitle = {Proceedings of the {Twenty} {Third} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Trapp, Martin and Peharz, Robert and Pernkopf, Franz and Rasmussen, Carl Edward},
	month = jun,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {2251--2261},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/BK6FBB7Z/Trapp et al. - 2020 - Deep Structured Mixtures of Gaussian Processes.pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/EKQQQYDQ/Trapp et al. - 2020 - Deep Structured Mixtures of Gaussian Processes.pdf:application/pdf},
}

@inproceedings{rossiSparse2021,
	title = {Sparse {Gaussian} {Processes} {Revisited}: {Bayesian} {Approaches} to {Inducing}-{Variable} {Approximations}},
	shorttitle = {Sparse {Gaussian} {Processes} {Revisited}},
	url = {https://proceedings.mlr.press/v130/rossi21a.html},
	abstract = {Variational inference techniques based on inducing variables provide an elegant framework for scalable posterior estimation in Gaussian process (GP) models. Besides enabling scalability, one of their main advantages over sparse approximations using direct marginal likelihood maximization is that they provide a robust alternative for point estimation of the inducing inputs, i.e. the location of the inducing variables. In this work we challenge the common wisdom that optimizing the inducing inputs in the variational framework yields optimal performance. We show that, by revisiting old model approximations such as the fully-independent training conditionals endowed with powerful sampling-based inference methods, treating both inducing locations and GP hyper-parameters in a Bayesian way can improve performance significantly. Based on stochastic gradient Hamiltonian Monte Carlo, we develop a fully Bayesian approach to scalable GP and deep GP models, and demonstrate its state-of-the-art performance through an extensive experimental campaign across several regression and classification problems.},
	language = {en},
	urldate = {2021-10-15},
	booktitle = {Proceedings of {The} 24th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Rossi, Simone and Heinonen, Markus and Bonilla, Edwin and Shen, Zheyang and Filippone, Maurizio},
	month = mar,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {1837--1845},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/IZRAMFPA/Rossi et al. - 2021 - Sparse Gaussian Processes Revisited Bayesian Appr.pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/UUBVVQJT/Rossi et al. - 2021 - Sparse Gaussian Processes Revisited Bayesian Appr.pdf:application/pdf},
}

@inproceedings{yuImplicit2019,
	title = {Implicit {Posterior} {Variational} {Inference} for {Deep} {Gaussian} {Processes}},
	volume = {32},
	url = {https://papers.nips.cc/paper/2019/hash/2c463dfdde588f3bfc60d53118c10d6b-Abstract.html},
	urldate = {2021-10-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {YU, Haibin and Chen, Yizhou and Low, Bryan Kian Hsiang and Jaillet, Patrick and Dai, Zhongxiang},
	year = {2019},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/W7EQKCL5/YU et al. - 2019 - Implicit Posterior Variational Inference for Deep .pdf:application/pdf},
}

@article{nakkaChanceConstrained2021,
	title = {Chance-{Constrained} {Trajectory} {Optimization} for {Safe} {Exploration} and {Learning} of {Nonlinear} {Systems}},
	volume = {6},
	issn = {2377-3766},
	doi = {10.1109/LRA.2020.3044033},
	abstract = {Learning-based control algorithms require data collection with abundant supervision for training. Safe exploration algorithms ensure the safety of this data collection process even when only partial knowledge is available. We present a new approach for optimal motion planning with safe exploration that integrates chance-constrained stochastic optimal control with dynamics learning and feedback control. We derive an iterative convex optimization algorithm that solves an Information-cost Stochastic Nonlinear Optimal Control problem (Info-SNOC). The optimization objective encodes control cost for performance and exploration cost for learning, and the safety is incorporated as distributionally robust chance constraints. The dynamics are predicted from a robust regression model that is learned from data. The Info-SNOC algorithm is used to compute a sub-optimal pool of safe motion plans that aid in exploration for learning unknown residual dynamics under safety constraints. A stable feedback controller is used to execute the motion plan and collect data for model learning. We prove the safety of rollout from our exploration method and reduction in uncertainty over epochs, thereby guaranteeing the consistency of our learning method. We validate the effectiveness of Info-SNOC by designing and implementing a pool of safe trajectories for a planar robot. We demonstrate that our approach has higher success rate in ensuring safety when compared to a deterministic trajectory optimization approach.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Nakka, Yashwanth Kumar and Liu, Anqi and Shi, Guanya and Anandkumar, Anima and Yue, Yisong and Chung, Soon-Jo},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Data models, Safety, Computational modeling, Optimal control, Stochastic processes, Planning, Chance constraints, Dynamics, machine learning for robot control, model learning for control, motion and path planning},
	pages = {389--396},
	file = {IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/IDB5STY5/Nakka et al. - 2021 - Chance-Constrained Trajectory Optimization for Saf.pdf:application/pdf},
}

@article{2020SciPy-NMeth,
	title = {{SciPy} 1.0: {Fundamental} algorithms for scientific computing in python},
	volume = {17},
	doi = {10.1038/s41592-019-0686-2},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul and {SciPy 1.0 Contributors}},
	year = {2020},
	note = {tex.adsurl: https://rdcu.be/b08Wh},
	pages = {261--272},
}

@article{2020NumPy-Array,
	title = {Array programming with {NumPy}},
	volume = {585},
	doi = {10.1038/s41586-020-2649-2},
	journal = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and Fernández del Río, Jaime and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	year = {2020},
	pages = {357--362},
}

@inproceedings{NIPS2008_f4b9ec30,
	title = {Variational mixture of gaussian process experts},
	volume = {21},
	url = {https://proceedings.neurips.cc/paper/2008/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf},
	booktitle = {Advances in neural information processing systems},
	publisher = {Curran Associates, Inc.},
	author = {Yuan, Chao and Neubauer, Claus},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	note = {tex.ids= yuanVariational2009},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/TVYKP872/Yuan and Neubauer - 2009 - Variational Mixture of Gaussian Process Experts.pdf:application/pdf},
}

@inproceedings{NIPS2005_f499d34b,
	title = {An alternative infinite mixture of gaussian process experts},
	volume = {18},
	url = {https://proceedings.neurips.cc/paper/2005/file/f499d34bd87b42948b3960b8f6b82e74-Paper.pdf},
	booktitle = {Advances in neural information processing systems},
	publisher = {MIT Press},
	author = {Meeds, Edward and Osindero, Simon},
	editor = {Weiss, Y. and Schölkopf, B. and Platt, J.},
	year = {2006},
	note = {tex.ids= meedsAlternative2006},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/BQWNWLFY/Meeds and Osindero - 2006 - An Alternative Infinite Mixture Of Gaussian Proces.pdf:application/pdf},
}

@inproceedings{cohenHealing2020,
	title = {Healing {Products} of {Gaussian} {Process} {Experts}},
	url = {https://proceedings.mlr.press/v119/cohen20b.html},
	abstract = {Gaussian processes (GPs) are nonparametric Bayesian models that have been applied to regression and classification problems. One of the approaches to alleviate their cubic training cost is the use of local GP experts trained on subsets of the data. In particular, product-of-expert models combine the predictive distributions of local experts through a tractable product operation. While these expert models allow for massively distributed computation, their predictions typically suffer from erratic behaviour of the mean or uncalibrated uncertainty quantification. By calibrating predictions via a tempered softmax weighting, we provide a solution to these problems for multiple product-of-expert models, including the generalised product of experts and the robust Bayesian committee machine. Furthermore, we leverage the optimal transport literature and propose a new product-of-expert model that combines predictions of local experts by computing their Wasserstein barycenter, which can be applied to both regression and classification.},
	language = {en},
	urldate = {2021-10-26},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Cohen, Samuel and Mbuvha, Rendani and Marwala, Tshilidzi and Deisenroth, Marc},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {2068--2077},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/TYJE597B/Cohen et al. - 2020 - Healing Products of Gaussian Process Experts.pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/Z28D4TVC/Cohen et al. - 2020 - Healing Products of Gaussian Process Experts.pdf:application/pdf},
}

@article{trespBayesian2000a,
	title = {A {Bayesian} {Committee} {Machine}},
	volume = {12},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/12/11/2719-2741/6426},
	doi = {10.1162/089976600300014908},
	abstract = {The Bayesian committee machine (BCM) is a novel approach to combining estimators which were trained on diﬀerent data sets. Although the BCM can be applied to the combination of any kind of estimators the main foci are Gaussian process regression and related systems such as regularization networks and smoothing splines for which the degrees of freedom increase with the number of training data. Somewhat surprisingly, we ﬁnd that the performance of the BCM improves if several test points are queried at the same time and is optimal if the number of test points is at least as large as the degrees of freedom of the estimator. The BCM also provides a new solution for online learning with potential applications to data mining. We apply the BCM to systems with ﬁxed basis functions and discuss its relationship to Gaussian process regression. Finally, we also show how the ideas behind the BCM can be applied in a non-Bayesian setting to extend the input dependent combination of estimators.},
	language = {en},
	number = {11},
	urldate = {2021-10-26},
	journal = {Neural Computation},
	author = {Tresp, Volker},
	month = nov,
	year = {2000},
	pages = {2719--2741},
	file = {Tresp - 2000 - A Bayesian Committee Machine.pdf:/Users/aidanscannell/Zotero/storage/6B6B86E3/Tresp - 2000 - A Bayesian Committee Machine.pdf:application/pdf},
}

@article{kimAnalyzing2005,
	title = {Analyzing {Nonstationary} {Spatial} {Data} {Using} {Piecewise} {Gaussian} {Processes}},
	volume = {100},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214504000002014},
	doi = {10.1198/016214504000002014},
	abstract = {In many problems in geostatistics the response variable of interest is strongly related to the underlying geology of the spatial location. In these situations there is often little correlation in the responses found in different rock strata, so the underlying covariance structure shows sharp changes at the boundaries of the rock types. Conventional stationary and nonstationary spatial methods are inappropriate, because they typically assume that the covariance between points is a smooth function of distance. In this article we propose a generic method for the analysis of spatial data with sharp changes in the underlying covariance structure. Our method works by automatically decomposing the spatial domain into disjoint regions within which the process is assumed to be stationary, but the data are assumed independent across regions. Uncertainty in the number of disjoint regions, their shapes, and the model within regions is dealt with in a fully Bayesian fashion. We illustrate our approach on a previously unpublished dataset relating to soil permeability of the Schneider Buda oil field in Wood County, Texas.},
	number = {470},
	urldate = {2021-10-26},
	journal = {Journal of the American Statistical Association},
	author = {Kim, Hyoung-Moon and Mallick, Bani K and Holmes, C. C},
	month = jun,
	year = {2005},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214504000002014},
	keywords = {Bayes factor, Kriging, Model averaging, Reversible-jump Markov chain Monte Carlo, Voronoi tessellation},
	pages = {653--668},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/YPI64BPC/016214504000002014.html:text/html},
}

@article{vasudevanGaussian2009a,
	title = {Gaussian process modeling of large-scale terrain},
	volume = {26},
	issn = {1556-4967},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.20309},
	doi = {10.1002/rob.20309},
	abstract = {Building a model of large-scale terrain that can adequately handle uncertainty and incompleteness in a statistically sound way is a challenging problem. This work proposes the use of Gaussian processes as models of large-scale terrain. The proposed model naturally provides a multiresolution representation of space, incorporates and handles uncertainties aptly, and copes with incompleteness of sensory information. Gaussian process regression techniques are applied to estimate and interpolate (to fill gaps in occluded areas) elevation information across the field. The estimates obtained are the best linear unbiased estimates for the data under consideration. A single nonstationary (neural network) Gaussian process is shown to be powerful enough to model large and complex terrain, effectively handling issues relating to discontinuous data. A local approximation method based on a “moving window” methodology and implemented using k-dimensional (KD)-trees is also proposed. This enables the approach to handle extremely large data sets, thereby completely addressing its scalability issues. Experiments are performed on large-scale data sets taken from real mining applications. These data sets include sparse mine planning data, which are representative of a global positioning system–based survey, as well as dense laser scanner data taken at different mine sites. Further, extensive statistical performance evaluation and benchmarking of the technique has been performed through cross-validation experiments. They conclude that for dense and/or flat data, the proposed approach will perform very competitively with grid-based approaches using standard interpolation techniques and triangulated irregular networks using triangle-based interpolation techniques; for sparse and/or complex data, however, it would significantly outperform them. © 2009 Wiley Periodicals, Inc.},
	language = {en},
	number = {10},
	urldate = {2021-10-26},
	journal = {Journal of Field Robotics},
	author = {Vasudevan, Shrihari and Ramos, Fabio and Nettleton, Eric and Durrant-Whyte, Hugh},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.20309
tex.ids= vasudevanGaussian2009},
	pages = {812--840},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/95WPXWM3/Vasudevan et al. - 2009 - Gaussian Process Modeling of Large-Scale Terrain.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/VXPH4VRG/download.html:text/html;Snapshot:/Users/aidanscannell/Zotero/storage/ZNZ2R2RM/rob.html:text/html},
}

@article{ghahramaniVariational2000,
	title = {Variational {Learning} for {Switching} {State}-{Space} {Models}},
	volume = {12},
	issn = {0899-7667},
	doi = {10.1162/089976600300015619},
	abstract = {We introduce a new statistical model for time series that iteratively segments data into regimes with approximately linear dynamics and learns the parameters of each of these linear regimes. This model combines and generalizes two of the most widely used stochastic time-series models—hidden Markov models and linear dynamical systems—and is closely related to models that are widely used in the control and econometrics literatures. It can also be derived by extending the mixture of experts neural network (Jacobs, Jordan, Nowlan, \& Hinton, 1991) to its fully dynamical version, in which both expert and gating networks are recurrent. Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact expectation maximization (EM) algorithm cannot be applied. However, we present a variational approximation that maximizes a lower bound on the log-likelihood and makes use of both the forward and backward recursions for hidden Markov models and the Kalman filter recursions for linear dynamical systems. We tested the algorithm on artificial data sets and a natural data set of respiration force from a patient with sleep apnea. The results suggest that variational approximations are a viable method for inference and learning in switching state-space models.},
	number = {4},
	journal = {Neural Computation},
	author = {Ghahramani, Zoubin and Hinton, Geoffrey E.},
	month = apr,
	year = {2000},
	note = {Conference Name: Neural Computation},
	pages = {831--864},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/RW4JB25F/6789465.html:text/html},
}

@techreport{ghahramaniSwitching1996a,
	title = {Switching {State}-{Space} {Models}},
	abstract = {We introduce a statistical model for non-linear time series which iteratively segments the data into regimes with approximately linear dynamics and learns the parameters of each of these linear regimes. This model combines and generalizes two of the most widely used stochastic time series models---the hidden Markov model and the linear dynamical system---and is related to models that are widely used in the control and econometrics literatures. It can also be derived by extending the mixture of experts neural network model (Jacobs et al., 1991) to its fully dynamical version, in which both expert and gating networks are recurrent. Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact Expectation Maximization (EM) alogithm cannot be applied. However, we present a variational approximation which maximizes a lower bound on the log likelihood and makes use of both the forward--backward recursions for hidden Markov mo...},
	institution = {King’s College Road, Toronto M5S 3H5},
	author = {Ghahramani, Zoubin and Hinton, Geoffrey E.},
	year = {1996},
	file = {Citeseer - Full Text PDF:/Users/aidanscannell/Zotero/storage/6FJPB3J2/Ghahramani and Hinton - 1996 - Switching State-Space Models.pdf:application/pdf;Citeseer - Snapshot:/Users/aidanscannell/Zotero/storage/8GP9X52Q/download.html:text/html},
}

@inproceedings{nguyenFast2014,
	title = {Fast {Allocation} of {Gaussian} {Process} {Experts}},
	url = {https://proceedings.mlr.press/v32/nguyena14.html},
	abstract = {We propose a scalable nonparametric Bayesian regression model based on a mixture of Gaussian process (GP) experts  and the inducing points formalism underpinning sparse GP approximations. Each expert is augmented with a set of inducing points, and the allocation of data points to experts is defined probabilistically based on their proximity to the experts. This allocation mechanism enables a fast variational inference procedure for learning of the inducing inputs and hyperparameters of the experts. When using K experts, our method can  run K{\textasciicircum}2 times faster and use K{\textasciicircum}2 times less memory than popular sparse methods such as the FITC approximation. Furthermore, it is easy to parallelize and handles non-stationarity  straightforwardly. Our experiments show that on medium-sized datasets (of around 10{\textasciicircum}4 training points) it  trains up to 5 times faster than FITC while achieving comparable accuracy. On a large dataset  of 10{\textasciicircum}5 training points, our method significantly outperforms six  competitive baselines while requiring only a few hours of training.},
	language = {en},
	urldate = {2021-10-26},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Nguyen, Trung and Bonilla, Edwin},
	month = jan,
	year = {2014},
	note = {ISSN: 1938-7228},
	pages = {145--153},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/3M2SHR5F/Nguyen and Bonilla - 2014 - Fast Allocation of Gaussian Process Experts.pdf:application/pdf},
}

@inproceedings{gaddEnriched2020,
	title = {Enriched mixtures of generalised {Gaussian} process experts},
	url = {https://proceedings.mlr.press/v108/gadd20a.html},
	abstract = {Mixtures of experts probabilistically divide the input space into regions, where the assumptions of each expert, or conditional model, need only hold locally. Combined with Gaussian process (GP) experts, this results in a powerful and highly flexible model. We focus on alternative mixtures of GP experts, which  model the joint distribution of the inputs and targets explicitly. We highlight issues of this approach in multi-dimensional input spaces, namely,  poor scalability and the need for an unnecessarily large number of experts, degrading the predictive performance and increasing uncertainty. We construct a novel model to address these issues through a nested partitioning scheme that automatically infers the number of components at both levels. Multiple response types are accommodated through a generalised GP framework, while multiple input types are included through a factorised exponential family structure. We show the effectiveness of our approach in estimating a parsimonious probabilistic description of both  synthetic data of increasing dimension and an Alzheimer’s challenge dataset.},
	language = {en},
	urldate = {2021-10-26},
	booktitle = {Proceedings of the {Twenty} {Third} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Gadd, Charles and Wade, Sara and Boukouvalas, Alexis},
	month = jun,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {3144--3154},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/GXCW2FXW/Gadd et al. - 2020 - Enriched mixtures of generalised Gaussian process .pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/77MNIVHX/Gadd et al. - 2020 - Enriched mixtures of generalised Gaussian process .pdf:application/pdf},
}

@inproceedings{naish-guzmanGeneralized2008,
	title = {The {Generalized} {FITC} {Approximation}},
	volume = {20},
	url = {https://proceedings.neurips.cc/paper/2007/hash/94c7bb58efc3b337800875b5d382a072-Abstract.html},
	urldate = {2021-10-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Naish-guzman, Andrew and Holden, Sean},
	year = {2008},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/F98CE2B4/Naish-guzman and Holden - 2008 - The Generalized FITC Approximation.pdf:application/pdf},
}

@inproceedings{boneyRegularizing2019,
	title = {Regularizing {Trajectory} {Optimization} with {Denoising} {Autoencoders}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/21fe5b8ba755eeaece7a450849876228-Abstract.html},
	urldate = {2021-12-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Boney, Rinu and Di Palo, Norman and Berglund, Mathias and Ilin, Alexander and Kannala, Juho and Rasmus, Antti and Valpola, Harri},
	year = {2019},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/AS2KZHRW/Boney et al. - 2019 - Regularizing Trajectory Optimization with Denoisin.pdf:application/pdf},
}

@article{liuConstrained2021,
	title = {Constrained {Model}-based {Reinforcement} {Learning} with {Robust} {Cross}-{Entropy} {Method}},
	url = {http://arxiv.org/abs/2010.07968},
	abstract = {This paper studies the constrained/safe reinforcement learning (RL) problem with sparse indicator signals for constraint violations. We propose a model-based approach to enable RL agents to effectively explore the environment with unknown system dynamics and environment constraints given a significantly small number of violation budgets. We employ the neural network ensemble model to estimate the prediction uncertainty and use model predictive control as the basic control framework. We propose the robust cross-entropy method to optimize the control sequence considering the model uncertainty and constraints. We evaluate our methods in the Safety Gym environment. The results show that our approach learns to complete the tasks with a much smaller number of constraint violations than state-of-the-art baselines. Additionally, we are able to achieve several orders of magnitude better sample efficiency when compared with constrained model-free RL approaches. The code is available at {\textbackslash}url\{https://github.com/liuzuxin/safe-mbrl\}.},
	urldate = {2022-01-11},
	journal = {arXiv:2010.07968 [cs]},
	author = {Liu, Zuxin and Zhou, Hongyi and Chen, Baiming and Zhong, Sicheng and Hebert, Martial and Zhao, Ding},
	month = mar,
	year = {2021},
	note = {arXiv: 2010.07968},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: 8 pages, 5 figures},
	file = {arXiv Fulltext PDF:/Users/aidanscannell/Zotero/storage/DSGIGWHF/Liu et al. - 2021 - Constrained Model-based Reinforcement Learning wit.pdf:application/pdf;arXiv.org Snapshot:/Users/aidanscannell/Zotero/storage/MKP3BWF3/2010.html:text/html},
}

@article{cowen-riversSAMBA2022,
	title = {{SAMBA}: safe model-based \& active reinforcement learning},
	issn = {1573-0565},
	shorttitle = {{SAMBA}},
	url = {https://doi.org/10.1007/s10994-021-06103-6},
	doi = {10.1007/s10994-021-06103-6},
	abstract = {In this paper, we propose SAMBA, a novel framework for safe reinforcement learning that combines aspects from probabilistic modelling, information theory, and statistics. Our method builds upon PILCO to enable active exploration using novel acquisition functions for out-of-sample Gaussian process evaluation optimised through a multi-objective problem that supports conditional-value-at-risk constraints. We evaluate our algorithm on a variety of safe dynamical system benchmarks involving both low and high-dimensional state representations. Our results show orders of magnitude reductions in samples and violations compared to state-of-the-art methods. Lastly, we provide intuition as to the effectiveness of the framework by a detailed analysis of our acquisition functions and safety constraints.},
	language = {en},
	urldate = {2022-01-11},
	journal = {Machine Learning},
	author = {Cowen-Rivers, Alexander I. and Palenicek, Daniel and Moens, Vincent and Abdullah, Mohammed Amin and Sootla, Aivar and Wang, Jun and Bou-Ammar, Haitham},
	month = jan,
	year = {2022},
	file = {Springer Full Text PDF:/Users/aidanscannell/Zotero/storage/4K3U6I8V/Cowen-Rivers et al. - 2022 - SAMBA safe model-based & active reinforcement lea.pdf:application/pdf},
}

@article{lowreyPlan2019,
	title = {Plan {Online}, {Learn} {Offline}: {Efficient} {Learning} and {Exploration} via {Model}-{Based} {Control}},
	shorttitle = {Plan {Online}, {Learn} {Offline}},
	abstract = {A plan online and learn offline (POLO) framework for the setting where an agent, with an internal model, needs to continually act and learn in the world and how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. We propose a plan online and learn offline (POLO) framework for the setting where an agent, with an internal model, needs to continually act and learn in the world. Our work builds on the synergistic relationship between local model-based control, global value function learning, and exploration. We study how local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value function. Combining these components enable solutions to complex simulated control tasks, like humanoid locomotion and dexterous in-hand manipulation, in the equivalent of a few minutes of experience in the real world.},
	journal = {ICLR},
	author = {Lowrey, Kendall and Rajeswaran, A. and Kakade, S. and Todorov, E. and Mordatch, Igor},
	year = {2019},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/AW7BCGGU/Lowrey et al. - 2019 - Plan Online, Learn Offline Efficient Learning and.pdf:application/pdf},
}

@inproceedings{titsiasBayesian2010,
	title = {Bayesian {Gaussian} {Process} {Latent} {Variable} {Model}},
	url = {https://proceedings.mlr.press/v9/titsias10a.html},
	abstract = {We introduce a variational inference framework for training the Gaussian process latent variable model and thus performing Bayesian nonlinear dimensionality reduction. This method allows us to variationally integrate out the input variables of the Gaussian process and compute a lower bound on the exact marginal likelihood of the nonlinear latent variable model. The maximization of the variational lower bound provides a Bayesian training procedure that is robust to overfitting and can automatically select the dimensionality of the nonlinear latent space. We demonstrate our method on real world datasets. The focus in this paper is on dimensionality reduction problems, but the methodology is more general. For example, our algorithm is immediately applicable for training Gaussian process models in the presence of missing or uncertain inputs.},
	language = {en},
	urldate = {2022-03-07},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Titsias, Michalis and Lawrence, Neil D.},
	month = mar,
	year = {2010},
	note = {ISSN: 1938-7228},
	pages = {844--851},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/VU5NQZLV/Titsias and Lawrence - 2010 - Bayesian Gaussian Process Latent Variable Model.pdf:application/pdf},
}

@inproceedings{galImproving2016,
	title = {Improving {PILCO} with {Bayesian} {Neural} {Network} {Dynamics} {Models}},
	url = {https://www.semanticscholar.org/paper/Improving-PILCO-with-Bayesian-Neural-Network-Models-McAllister-Rasmussen/127d856c8b74d3e54a2f7da7b11b784014832ed9},
	abstract = {PILCO’s framework is extended to use Bayesian deep dynamics models with approximate variational inference, allowing PILCO to scale linearly with number of trials and observation space dimensionality, and it is shown that moment matching is a crucial simplifying assumption made by the model. Model-based reinforcement learning (RL) allows an agent to discover good policies with a small number of trials by generalising observed transitions. Data efficiency can be further improved with a probabilistic model of the agent’s ignorance about the world, allowing it to choose actions under uncertainty. Bayesian modelling offers tools for this task, with PILCO [1] being a prominent example, achieving state-of-theart data efficiency on low dimensional RL benchmarks. But PILCO relies on Gaussian processes (GPs), which prohibits its applicability to problems that require a larger number of trials to be solved. Further, PILCO does not consider temporal correlation in model uncertainty between successive state transitions, which results in PILCO underestimating state uncertainty at future time steps [2]. In this paper we extend PILCO’s framework to use Bayesian deep dynamics models with approximate variational inference, allowing PILCO to scale linearly with number of trials and observation space dimensionality. Using particle methods we sample dynamics function realisations, and obtain lower cumulative cost than PILCO. We give insights into the modelling assumptions made in PILCO, and show that moment matching is a crucial simplifying assumption made by the model. Our implementation can leverage GPU architectures, offering faster running time than PILCO, and will allow structured observation spaces to be modelled (images or higher dimensional inputs) in the future.},
	language = {en},
	urldate = {2022-03-09},
	author = {Gal, Yarin and McAllister, Rowan and Rasmussen, Carl},
	year = {2016},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/7CC35VP4/127d856c8b74d3e54a2f7da7b11b784014832ed9.html:text/html},
}

@book{kirkOptimal2004,
	title = {Optimal control theory: an introduction},
	publisher = {Courier Corporation},
	author = {Kirk, Donald},
	year = {2004},
}

@article{jakschNearoptimal2010,
	title = {Near-optimal {Regret} {Bounds} for {Reinforcement} {Learning}},
	volume = {11},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v11/jaksch10a.html},
	abstract = {For undiscounted reinforcement learning in Markov decision processes (MDPs) we consider the total regret of a learning algorithm with respect to an optimal policy. In order to describe the transition structure of an MDP we propose a new parameter: An MDP has diameter D if for any pair of states s,s' there is a policy which moves from s to s' in at most D steps (on average). We present a reinforcement learning algorithm with total regret Õ(DS√AT) after T steps for any unknown MDP with S states, A actions per state, and diameter D. A corresponding lower bound of Ω(√DSAT) on the total regret of any learning algorithm is given as well.
These results are complemented by a sample complexity bound on the number of suboptimal steps taken by our algorithm. This bound can be used to achieve a (gap-dependent) regret bound that is logarithmic in T.
Finally, we also consider a setting where the MDP is allowed to change a fixed number of l times. We present a modification of our algorithm that is able to deal with this setting and show a regret bound of Õ(l1/3T2/3DS√A).},
	number = {51},
	urldate = {2022-04-06},
	journal = {Journal of Machine Learning Research},
	author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
	year = {2010},
	pages = {1563--1600},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/4Z9LMIWU/Jaksch et al. - 2010 - Near-optimal Regret Bounds for Reinforcement Learn.pdf:application/pdf},
}

@article{kingmaAutoEncoding2014,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	abstract = {A stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case is introduced. Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	journal = {ICLR},
	author = {Kingma, Diederik P. and Welling, M.},
	year = {2014},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/STWNYJNX/Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf:application/pdf},
}

@inproceedings{burtRates2019,
	title = {Rates of {Convergence} for {Sparse} {Variational} {Gaussian} {Process} {Regression}},
	url = {https://proceedings.mlr.press/v97/burt19a.html},
	abstract = {Excellent variational approximations to Gaussian process posteriors have been developed which avoid the (𝑁3)O(N3){\textbackslash}mathcal\{O\}{\textbackslash}left(N{\textasciicircum}3{\textbackslash}right) scaling with dataset size 𝑁NN. They reduce the computational cost to (𝑁𝑀2)O(NM2){\textbackslash}mathcal\{O\}{\textbackslash}left(NM{\textasciicircum}2{\textbackslash}right), with 𝑀≪𝑁M≪NM{\textbackslash}ll N the number of inducing variables, which summarise the process. While the computational cost seems to be linear in 𝑁NN, the true complexity of the algorithm depends on how 𝑀MM must increase to ensure a certain quality of approximation. We show that with high probability the KL divergence can be made arbitrarily small by growing 𝑀MM more slowly than 𝑁NN. A particular case is that for regression with normally distributed inputs in D-dimensions with the Squared Exponential kernel, 𝑀=(log𝐷𝑁)M=O(logD⁡N)M={\textbackslash}mathcal\{O\}({\textbackslash}log{\textasciicircum}D N) suffices. Our results show that as datasets grow, Gaussian process posteriors can be approximated cheaply, and provide a concrete rule for how to increase 𝑀MM in continual learning scenarios.},
	language = {en},
	urldate = {2022-04-08},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Burt, David and Rasmussen, Carl Edward and Wilk, Mark Van Der},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {862--871},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/IVLK3YJI/Burt et al. - 2019 - Rates of Convergence for Sparse Variational Gaussi.pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/VLQ6WE7S/Burt et al. - 2019 - Rates of Convergence for Sparse Variational Gaussi.pdf:application/pdf},
}

@article{bellmanDynamic1956,
	title = {Dynamic {Programming}},
	url = {https://www.science.org/doi/abs/10.1126/science.153.3731.34},
	doi = {10.1126/science.153.3731.34},
	urldate = {2022-04-28},
	journal = {Princeton University Press},
	author = {Bellman, Richard},
	year = {1956},
}

@inproceedings{atkesonComparison1997,
	title = {A comparison of direct and model-based reinforcement learning},
	volume = {4},
	doi = {10.1109/ROBOT.1997.606886},
	abstract = {This paper compares direct reinforcement learning (no explicit model) and model-based reinforcement learning on a simple task: pendulum swing up. We find that in this task model-based approaches support reinforcement learning from smaller amounts of training data and efficient handling of changing goals.},
	booktitle = {Proceedings of {International} {Conference} on {Robotics} and {Automation}},
	author = {Atkeson, C.G. and Santamaria, J.C.},
	month = apr,
	year = {1997},
	keywords = {Computational modeling, Robots, Control systems, State-space methods, Control system synthesis, Educational institutions, Force control, Jacobian matrices, Learning, Training data},
	pages = {3557--3564 vol.4},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/P4GM3WQN/606886.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/ANHXHIXS/Atkeson and Santamaria - 1997 - A comparison of direct and model-based reinforceme.pdf:application/pdf},
}

@article{kurutachModelEnsemble2018,
	title = {Model-{Ensemble} {Trust}-{Region} {Policy} {Optimization}},
	abstract = {This paper analyzes the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and shows that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.},
	journal = {ICLR},
	author = {Kurutach, Thanard and Clavera, I. and Duan, Yan and Tamar, Aviv and Abbeel, P.},
	year = {2018},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/BGUTUYR2/Kurutach et al. - 2018 - Model-Ensemble Trust-Region Policy Optimization.pdf:application/pdf},
}

@inproceedings{depewegLearning2017,
	title = {Learning and policy search in stochastic dynamical systems with {Bayesian} neural networks},
	url = {http://publications.eng.cam.ac.uk/1195629/},
	urldate = {2022-04-29},
	booktitle = {5th {International} {Conference} on {Learning} {Representations}, {ICLR} 2017 - {Conference} {Track} {Proceedings}},
	author = {Depeweg, S. and Hernández-Lobato, J. M. and Doshi-Velez, F. and Udluft, S.},
	year = {2017},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/XDBN68FW/1195629.html:text/html},
}

@inproceedings{nagabandiDeep2020,
	title = {Deep {Dynamics} {Models} for {Learning} {Dexterous} {Manipulation}},
	url = {https://proceedings.mlr.press/v100/nagabandi20a.html},
	abstract = {Dexterous multi-fingered hands can provide robots with the ability to flexibly perform a wide range of manipulation skills. However, many of the more complex behaviors are also notoriously difficult to control: Performing in-hand object manipulation, executing finger gaits to move objects, and exhibiting precise fine motor skills such as writing, all require finely balancing contact forces, breaking and reestablishing contacts repeatedly, and maintaining control of unactuated objects. Learning-based techniques provide the appealing possibility of acquiring these skills directly from data, but current learning approaches either require large amounts of data and produce task-specific policies, or they have not yet been shown to scale up to more complex and realistic tasks requiring fine motor skills. In this work, we demonstrate that our method of online planning with deep dynamics models (PDDM) addresses both of these limitations; we show that improvements in learned dynamics models, together with improvements in on-line model-predictive control, can indeed enable efficient and effective learning of flexible contact-rich dexterous manipulation skills – and that too, on a 24-DoF anthropomorphic hand in the real world, using just 4 hours of purely real-world data to learn to simultaneously coordinate multiple free-floating objects. Videos can be found at https://sites.google.com/view/pddm/.},
	language = {en},
	urldate = {2022-04-29},
	booktitle = {Proceedings of the {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
	month = may,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {1101--1112},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/NU3ZJ22M/Nagabandi et al. - 2020 - Deep Dynamics Models for Learning Dexterous Manipu.pdf:application/pdf},
}

@article{lambertLowLevel2019,
	title = {Low-{Level} {Control} of a {Quadrotor} {With} {Deep} {Model}-{Based} {Reinforcement} {Learning}},
	volume = {4},
	issn = {2377-3766},
	doi = {10.1109/LRA.2019.2930489},
	abstract = {Designing effective low-level robot controllers often entail platform-specific implementations that require manual heuristic parameter tuning, significant system knowledge, or long design times. With the rising number of robotic and mechatronic systems deployed across areas ranging from industrial automation to intelligent toys, the need for a general approach to generating low-level controllers is increasing. To address the challenge of rapidly generating low-level controllers, we argue for using model-based reinforcement learning (MBRL) trained on relatively small amounts of automatically generated (i.e., without system simulation) data. In this letter, we explore the capabilities of MBRL on a Crazyflie centimeter-scale quadrotor with rapid dynamics to predict and control at ≤50 Hz. To our knowledge, this is the first use of MBRL for controlled hover of a quadrotor using only on-board sensors, direct motor input signals, and no initial dynamics knowledge. Our controller leverages rapid simulation of a neural network forward dynamics model on a graphic processing unit enabled base station, which then transmits the best current action to the quadrotor firmware via radio. In our experiments, the quadrotor achieved hovering capability of up to 6 s with 3 min of experimental training data.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Lambert, Nathan O. and Drew, Daniel S. and Yaconelli, Joseph and Levine, Sergey and Calandra, Roberto and Pister, Kristofer S. J.},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Data models, Predictive models, Trajectory, Vehicle dynamics, Robots, aerial systems: mechanics and control, Attitude control, Deep learning in robotics and automation, Pulse width modulation},
	pages = {4224--4230},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/DMLF4SDJ/8769882.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/NU9R9BNE/Lambert et al. - 2019 - Low-Level Control of a Quadrotor With Deep Model-B.pdf:application/pdf},
}

@book{pontryagin1987mathematical,
	title = {Mathematical theory of optimal processes},
	publisher = {CRC press},
	author = {Pontryagin, Lev Semenovich},
	year = {1987},
}

@article{yongStochastic1999,
	title = {Stochastic {Controls}: {Hamiltonian} {Systems} and {HJB} {Equations}},
	shorttitle = {Stochastic {Controls}},
	url = {https://www.semanticscholar.org/paper/Stochastic-Controls%3A-Hamiltonian-Systems-and-HJB-Yong-Zhou/f60223dee8815324a4b9df9d1825e7c33fc099f3},
	abstract = {1. Basic Stochastic Calculus.- 1. Probability.- 1.1. Probability spaces.- 1.2. Random variables.- 1.3. Conditional expectation.- 1.4. Convergence of probabilities.- 2. Stochastic Processes.- 2.1. General considerations.- 2.2. Brownian motions.- 3. Stopping Times.- 4. Martingales.- 5. Ito\&\#39;s Integral.- 5.1. Nondifferentiability of Brownian motion.- 5.2. Definition of Ito\&\#39;s integral and basic properties.- 5.3. Ito\&\#39;s formula.- 5.4. Martingale representation theorems.- 6. Stochastic Differential Equations.- 6.1. Strong solutions.- 6.2. Weak solutions.- 6.3. Linear SDEs.- 6.4. Other types of SDEs.- 2. Stochastic Optimal Control Problems.- 1. Introduction.- 2. Deterministic Cases Revisited.- 3. Examples of Stochastic Control Problems.- 3.1. Production planning.- 3.2. Investment vs. consumption.- 3.3. Reinsurance and dividend management.- 3.4. Technology diffusion.- 3.5. Queueing systems in heavy traffic.- 4. Formulations of Stochastic Optimal Control Problems.- 4.1. Strong formulation.- 4.2. Weak formulation.- 5. Existence of Optimal Controls.- 5.1. A deterministic result.- 5.2. Existence under strong formulation.- 5.3. Existence under weak formulation.- 6. Reachable Sets of Stochastic Control Systems.- 6.1. Nonconvexity of the reachable sets.- 6.2. Noncloseness of the reachable sets.- 7. Other Stochastic Control Models.- 7.1. Random duration.- 7.2. Optimal stopping.- 7.3. Singular and impulse controls.- 7.4. Risk-sensitive controls.- 7.5. Ergodic controls.- 7.6. Partially observable systems.- 8. Historical Remarks.- 3. Maximum Principle and Stochastic Hamiltonian Systems.- 1. Introduction.- 2. The Deterministic Case Revisited.- 3. Statement of the Stochastic Maximum Principle.- 3.1. Adjoint equations.- 3.2. The maximum principle and stochastic Hamiltonian systems.- 3.3. A worked-out example.- 4. A Proof of the Maximum Principle.- 4.1. A moment estimate.- 4.2. Taylor expansions.- 4.3. Duality analysis and completion of the proof.- 5. Sufficient Conditions of Optimality.- 6. Problems with State Constraints.- 6.1. Formulation of the problem and the maximum principle.- 6.2. Some preliminary lemmas.- 6.3. A proof of Theorem 6.1.- 7. Historical Remarks.- 4. Dynamic Programming and HJB Equations.- 1. Introduction.- 2. The Deterministic Case Revisited.- 3. The Stochastic Principle of Optimality and the HJB Equation.- 3.1. A stochastic framework for dynamic programming.- 3.2. Principle of optimality.- 3.3. The HJB equation.- 4. Other Properties of the Value Function.- 4.1. Continuous dependence on parameters.- 4.2. Semiconcavity.- 5. Viscosity Solutions.- 5.1. Definitions.- 5.2. Some properties.- 6. Uniqueness of Viscosity Solutions.- 6.1. A uniqueness theorem.- 6.2. Proofs of Lemmas 6.6 and 6.7.- 7. Historical Remarks.- 5. The Relationship Between the Maximum Principle and Dynamic Programming.- 1. Introduction.- 2. Classical Hamilton-Jacobi Theory.- 3. Relationship for Deterministic Systems.- 3.1. Adjoint variable and value function: Smooth case.- 3.2. Economic interpretation.- 3.3. Methods of characteristics and the Feynman-Kac formula.- 3.4. Adjoint variable and value function: Nonsmooth case.- 3.5. Verification theorems.- 4. Relationship for Stochastic Systems.- 4.1. Smooth case.- 4.2. Nonsmooth case: Differentials in the spatial variable.- 4.3. Nonsmooth case: Differentials in the time variable.- 5. Stochastic Verification Theorems.- 5.1. Smooth case.- 5.2. Nonsmooth case.- 6. Optimal Feedback Controls.- 7. Historical Remarks.- 6. Linear Quadratic Optimal Control Problems.- 1. Introduction.- 2. The Deterministic LQ Problems Revisited.- 2.1. Formulation.- 2.2. A minimization problem of a quadratic functional.- 2.3. A linear Hamiltonian system.- 2.4. The Riccati equation and feedback optimal control.- 3. Formulation of Stochastic LQ Problems.- 3.1. Statement of the problems.- 3.2. Examples.- 4. Finiteness and Solvability.- 5. A Necessary Condition and a Hamiltonian System.- 6. Stochastic Riccati Equations.- 7. Global Solvability of Stochastic Riccati Equations.- 7.1. Existence: The standard case.- 7.2. Existence: The case C = 0, S = 0, and Q, G ?0.- 7.3. Existence: The one-dimensional case.- 8. A Mean-variance Portfolio Selection Problem.- 9. Historical Remarks.- 7. Backward Stochastic Differential Equations.- 1. Introduction.- 2. Linear Backward Stochastic Differential Equations.- 3. Nonlinear Backward Stochastic Differential Equations.- 3.1. BSDEs in finite deterministic durations: Method of contraction mapping.- 3.2. BSDEs in random durations: Method of continuation.- 4. Feynman-Kac-Type Formulae.- 4.1. Representation via SDEs.- 4.2. Representation via BSDEs.- 5. Forward-Backward Stochastic Differential Equations.- 5.1. General formulation and nonsolvability.- 5.2. The four-step scheme, a heuristic derivation.- 5.3. Several solvable classes of FBSDEs.- 6. Option Pricing Problems.- 6.1. European call options and the Black--Scholes formula.- 6.2. Other options.- 7. Historical Remarks.- References.},
	language = {en},
	urldate = {2022-04-29},
	journal = {undefined},
	author = {Yong, J. and Zhou, X.},
	year = {1999},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/JC3ZG78J/f60223dee8815324a4b9df9d1825e7c33fc099f3.html:text/html},
}

@inproceedings{Yong1999StochasticCH,
	title = {Stochastic controls: {Hamiltonian} systems and {HJB} equations},
	author = {Yong, Jiongmin and Zhou, Xun Yu},
	year = {1999},
}

@article{vinogradskaNumerical2020,
	title = {Numerical {Quadrature} for {Probabilistic} {Policy} {Search}},
	volume = {42},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2018.2879335},
	abstract = {Learning control policies has become an appealing alternative to the derivation of control laws based on classic control theory. Model-based approaches have proven an outstanding data efficiency, especially when combined with probabilistic models to eliminate model bias. However, a major difficulty for these methods is that multi-step-ahead predictions typically become intractable for larger planning horizons and can only poorly be approximated. In this paper, we propose the use of numerical quadrature to overcome this drawback and provide significantly more accurate multi-step-ahead predictions. As a result, our approach increases data efficiency and enhances the quality of learned policies. Furthermore, policy learning is not restricted to optimizing locally around one trajectory, as numerical quadrature provides a principled approach to extend optimization to all trajectories starting in a specified starting state region. Thus, manual effort, such as choosing informative starting points for simultaneous policy optimization, is significantly decreased. Furthermore, learning is highly robust to the choice of initial policy and, thus, interaction time with the system is minimized. Empirical evaluations on simulated benchmark problems show the efficiency of the proposed approach and support our theoretical results.},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Vinogradska, Julia and Bischoff, Bastian and Achterhold, Jan and Koller, Torsten and Peters, Jan},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data models, Gaussian processes, Predictive models, Uncertainty, Computational modeling, control, Policy search, reinforcement learning, System dynamics, Numerical models},
	pages = {164--175},
	file = {IEEE Xplore Abstract Record:/Users/aidanscannell/Zotero/storage/K82ZSX66/8520758.html:text/html;IEEE Xplore Full Text PDF:/Users/aidanscannell/Zotero/storage/32JH2IZA/Vinogradska et al. - 2020 - Numerical Quadrature for Probabilistic Policy Sear.pdf:application/pdf},
}

@article{nguyen-tuongModel2009,
	title = {Model learning with local gaussian process regression},
	volume = {23},
	url = {https://doi.org/10.1163/016918609X12529286896877},
	doi = {10.1163/016918609X12529286896877},
	number = {15},
	journal = {Advanced Robotics},
	author = {Nguyen-Tuong, Duy and Seeger, Matthias and Peters, Jan},
	year = {2009},
	note = {Publisher: Taylor \& Francis
tex.eprint: https://doi.org/10.1163/016918609X12529286896877},
	pages = {2015--2034},
}

@inproceedings{sekarPlanning2020,
	title = {Planning to {Explore} via {Self}-{Supervised} {World} {Models}},
	url = {https://proceedings.mlr.press/v119/sekar20a.html},
	abstract = {Reinforcement learning allows solving complex tasks, however, the learning tends to be task-specific and the sample efficiency remains a challenge. We present Plan2Explore, a self-supervised reinforcement learning agent that tackles both these challenges through a new approach to self-supervised exploration and fast adaptation to new tasks, which need not be known during exploration. During exploration, unlike prior methods which retrospectively compute the novelty of observations after the agent has already reached them, our agent acts efficiently by leveraging planning to seek out expected future novelty. After exploration, the agent quickly adapts to multiple downstream tasks in a zero or a few-shot manner. We evaluate on challenging control tasks from high-dimensional image inputs. Without any training supervision or task-specific interaction, Plan2Explore outperforms prior self-supervised exploration methods, and in fact, almost matches the performances oracle which has access to rewards. Videos and code: https://ramanans1.github.io/plan2explore/},
	language = {en},
	urldate = {2022-05-02},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Sekar, Ramanan and Rybkin, Oleh and Daniilidis, Kostas and Abbeel, Pieter and Hafner, Danijar and Pathak, Deepak},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {8583--8592},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/4RJFWDE7/Sekar et al. - 2020 - Planning to Explore via Self-Supervised World Mode.pdf:application/pdf;Supplementary PDF:/Users/aidanscannell/Zotero/storage/79JZ8WW6/Sekar et al. - 2020 - Planning to Explore via Self-Supervised World Mode.pdf:application/pdf},
}

@inproceedings{moerlandEfficient2017,
	title = {Efficient exploration with {Double} {Uncertain} {Value} {Networks}},
	abstract = {This paper studies directed exploration for reinforcement learning agents by tracking uncertainty about the value of each available action. We identify two sources of uncertainty that are relevant for exploration. The first originates from limited data (parametric uncertainty), while the second originates from the distribution of the returns (return uncertainty). We identify methods to learn these distributions with deep neural networks, where we estimate parametric uncertainty with Bayesian drop-out, while return uncertainty is propagated through the Bellman equation as a Gaussian distribution. Then, we identify that both can be jointly estimated in one network, which we call the Double Uncertain Value Network. The policy is directly derived from the learned distributions based on Thompson sampling. Experimental results show that both types of uncertainty may vastly improve learning in domains with a strong exploration challenge.},
	booktitle = {Neural {Information} {Processing} {Systems}},
	author = {Moerland, Thomas and Broekens, Joost and Jonker, Catholijn},
	year = {2017},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/Q94JFI6T/Moerland et al. - 2017 - Efficient exploration with Double Uncertain Value .pdf:application/pdf},
}

@article{auerUsing2002,
	title = {Using {Confidence} {Bounds} for {Exploitation}-{Exploration} {Trade}-offs},
	volume = {3},
	issn = {ISSN 1533-7928},
	url = {https://www.jmlr.org/papers/v3/auer02a.html},
	abstract = {We show how a standard tool from statistics --- namely confidence bounds --- can be used to elegantly deal with situations which exhibit an exploitation-exploration trade-off. Our technique for designing and analyzing algorithms for such situations is general and can be applied when an algorithm has to make exploitation-versus-exploration decisions based on uncertain information provided by a random process.

We apply our technique to two models with such an exploitation-exploration trade-off. For the adversarial bandit problem with shifting our new algorithm suffers only O((ST)1/2) regret with high probability over T trials with S shifts. Such a regret bound was previously known only in expectation. The second model we consider is associative reinforcement learning with linear value functions. For this model our technique improves the regret from O(T3/4) to O(T1/2).},
	number = {Nov},
	urldate = {2022-05-02},
	journal = {Journal of Machine Learning Research},
	author = {Auer, Peter},
	year = {2002},
	pages = {397--422},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/T7P7KJVN/Auer - 2002 - Using Confidence Bounds for Exploitation-Explorati.pdf:application/pdf},
}

@article{ariafarADMMBO2019,
	title = {{ADMMBO}: {Bayesian} {Optimization} with {Unknown} {Constraints} using {ADMM}},
	volume = {20},
	shorttitle = {{ADMMBO}},
	abstract = {There exist many problems in science and engineering that involve optimization of an unknown or partially unknown objective function. Recently, Bayesian Optimization (BO) has emerged as a powerful tool for solving optimization problems whose objective functions are only available as a black box and are expensive to evaluate. Many practical problems, however, involve optimization of an unknown objective function subject to unknown constraints. This is an important yet challenging problem for which, unlike optimizing an unknown function, existing methods face several limitations. In this paper, we present a novel constrained Bayesian optimization framework to optimize an unknown objective function subject to unknown constraints. We introduce an equivalent optimization by augmenting the objective function with constraints, introducing auxiliary variables for each constraint, and forcing the new variables to be equal to the main variable. Building on the Alternating Direction Method of Multipliers (ADMM) algorithm, we propose ADMM-Bayesian Optimization (ADMMBO) to solve the problem in an iterative fashion. Our framework leads to multiple unconstrained subproblems with unknown objective functions, which we then solve via BO. Our method resolves several challenges of state-of-the-art techniques: it can start from infeasible points, is insensitive to initialization, can efficiently handle 'decoupled problems' and has a concrete stopping criterion. Extensive experiments on a number of challenging BO benchmark problems show that our proposed approach outperforms the state-of-the-art methods in terms of the speed of obtaining a feasible solution and convergence to the global optimum as well as minimizing the number of total evaluations of unknown objective and constraints functions.},
	journal = {Journal of machine learning research : JMLR},
	author = {Ariafar, Setareh and Coll-Font, Jaume and Brooks, Dana and Dy, Jennifer},
	month = jan,
	year = {2019},
}

@inproceedings{gelbartBayesian2014,
	title = {Bayesian optimization with unknown constraints},
	url = {https://collaborate.princeton.edu/en/publications/bayesian-optimization-with-unknown-constraints},
	language = {English (US)},
	urldate = {2022-05-02},
	booktitle = {Uncertainty in {Artificial} {Intelligence} - {Proceedings} of the 30th {Conference}, {UAI} 2014},
	publisher = {AUAI Press},
	author = {Gelbart, Michael A. and Snoek, Jasper and Adams, Ryan P.},
	year = {2014},
	pages = {250--259},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/VG2LGR3L/bayesian-optimization-with-unknown-constraints.html:text/html},
}

@article{schwarmChanceconstrained1999,
	title = {Chance-constrained model predictive control},
	volume = {45},
	issn = {1547-5905},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.690450811},
	doi = {10.1002/aic.690450811},
	abstract = {This work focuses on robustness of model-predictive control with respect to satisfaction of process output constraints. A method of improving such robustness is presented. The method relies on formulating output constraints as chance constraints using the uncertainty description of the process model. The resulting on-line optimization problem is convex. The proposed approach is illustrated through a simulation case study on a high-purity distillation column. Suggestions for further improvements are made.},
	language = {en},
	number = {8},
	urldate = {2022-05-02},
	journal = {AIChE Journal},
	author = {Schwarm, Alexander T. and Nikolaou, Michael},
	year = {1999},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aic.690450811},
	pages = {1743--1752},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/G8ZC8FQA/aic.html:text/html},
}

@inproceedings{turchettaSafe2016,
	title = {Safe {Exploration} in {Finite} {Markov} {Decision} {Processes} with {Gaussian} {Processes}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/9a49a25d845a483fae4be7e341368e36-Abstract.html},
	abstract = {In classical reinforcement learning agents accept arbitrary short term loss for long term gain when exploring their environment. This is infeasible for safety critical applications such as robotics, where even a single unsafe action may cause system failure or harm the environment. In this paper, we address the problem of safely exploring finite Markov decision processes (MDP). We define safety in terms of an a priori unknown safety constraint that depends on states and actions and satisfies certain regularity conditions expressed via a Gaussian process prior. We develop a novel algorithm, SAFEMDP, for this task and prove that it completely explores the safely reachable part of the MDP without violating the safety constraint. To achieve this, it cautiously explores safe states and actions in order to gain statistical confidence about the safety of unvisited state-action pairs from noisy observations collected while navigating the environment. Moreover, the algorithm explicitly considers reachability when exploring the MDP, ensuring that it does not get stuck in any state with no safe way out. We demonstrate our method on digital terrain models for the task of exploring an unknown map with a rover.},
	urldate = {2022-05-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
	year = {2016},
	file = {Full Text PDF:/Users/aidanscannell/Zotero/storage/WUKK7N6W/Turchetta et al. - 2016 - Safe Exploration in Finite Markov Decision Process.pdf:application/pdf},
}

@inproceedings{sadighSafe2016,
	title = {Safe {Control} {Under} {Uncertainty} with {Probabilistic} {Signal} {Temporal} {Logic}},
	url = {https://www.microsoft.com/en-us/research/publication/safe-control-uncertainty-probabilistic-signal-temporal-logic/},
	abstract = {Controller synthesis for hybrid systems that satisfy temporal specifications expressing various system properties is a challenging problem that has drawn the attention of many researchers. However, making the assumption that such temporal properties are deterministic is far from the reality. For example, many of the properties the controller has to satisfy are learned through machine […]},
	language = {en-US},
	urldate = {2022-05-02},
	author = {Sadigh, Dorsa and Kapoor, Ashish},
	month = jun,
	year = {2016},
	note = {tex.ids= sadighSafe2016a},
	file = {Sadigh and Kapoor - 2016 - Safe Control under Uncertainty with Probabilistic .pdf:/Users/aidanscannell/Zotero/storage/33KXXXBE/Sadigh and Kapoor - 2016 - Safe Control under Uncertainty with Probabilistic .pdf:application/pdf;Snapshot:/Users/aidanscannell/Zotero/storage/JT2L6HUF/safe-control-uncertainty-probabilistic-signal-temporal-logic.html:text/html},
}

@article{lyapunovGeneral1992a,
	title = {The general problem of the stability of motion},
	volume = {55},
	issn = {0020-7179},
	url = {https://doi.org/10.1080/00207179208934253},
	doi = {10.1080/00207179208934253},
	number = {3},
	urldate = {2022-05-02},
	journal = {International Journal of Control},
	author = {Lyapunov, A. M.},
	month = mar,
	year = {1992},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207179208934253},
	pages = {531--534},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/L73PVNMP/00207179208934253.html:text/html},
}

@book{ferberGames1958,
	title = {Games and {Decisions}: {Introduction} and {Critical} {Survey}},
	shorttitle = {Games and {Decisions}},
	abstract = {Semantic Scholar extracted view of "Games and Decisions: Introduction and Critical Survey" by R. Ferber et al.},
	publisher = {Wiley New York},
	author = {Ferber, R. and Luce, R. and Raiffa, H.},
	year = {1958},
}

@article{duffieOverview1997a,
	title = {An {Overview} of {Value} at {Risk}},
	volume = {4},
	copyright = {© 1997 Pageant Media Ltd},
	issn = {1074-1240, 2168-8524},
	url = {https://jod.pm-research.com/content/4/3/7},
	doi = {10.3905/jod.1997.407971},
	language = {en},
	number = {3},
	urldate = {2022-05-02},
	journal = {The Journal of Derivatives},
	author = {Duffie, Darrell and Pan, Jun},
	month = feb,
	year = {1997},
	note = {Publisher: Institutional Investor Journals Umbrella
Section: Primary Article},
	pages = {7--49},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/PUPCSZR8/7.html:text/html},
}

@article{rockafellarConditional2001,
	title = {Conditional {Value}-at-{Risk} for {General} {Loss} {Distributions}},
	url = {https://www.semanticscholar.org/paper/Conditional-Value-at-Risk-for-General-Loss-Rockafellar-Uryasev/d243a33c209f41453927fe969949288abb4c3382},
	abstract = {Fundamental properties of conditional value-at-risk, as a measure of risk with significant advantages over value-at-risk, are derived for loss distributions in finance that can involve discreetness. Such distributions are of particular importance in applications because of the prevalence of models based on scenarios and finite sampling. Conditional value-at-risk is able to quantify dangers beyond value-at-risk, and moreover it is coherent. It provides optimization shortcuts which, through linear programming techniques, make practical many large-scale calculations that could otherwise be out of reach. The numerical efficiency and stability of such calculations, shown in several case studies, are illustrated further with an example of index tracking.},
	language = {en},
	urldate = {2022-05-02},
	journal = {Journal of Banking \& Finance},
	author = {Rockafellar, R. and Uryasev, S.},
	year = {2001},
	pages = {1443--1471},
	file = {Snapshot:/Users/aidanscannell/Zotero/storage/2837SYH3/d243a33c209f41453927fe969949288abb4c3382.html:text/html},
}

@article{Woodcock2009FormalMP,
	title = {Formal methods: {Practice} and experience},
	volume = {41},
	journal = {Acm Computing Surveys},
	author = {Woodcock, Jim and Larsen, Peter Gorm and Bicarregui, Juan and Fitzgerald, John S.},
	year = {2009},
	pages = {19:1--19:36},
}

@book{altmanConstrained1999,
	title = {Constrained {Markov} {Decision} {Processes}: {Stochastic} {Modeling}},
	shorttitle = {Constrained {Markov} {Decision} {Processes}},
	abstract = {This book provides a unified approach for the study of constrained Markov decision processes with a finite state space and unbounded costs. Unlike the single controller case considered in many other books, the author considers a single controller with several objectives, such as minimizing delays and loss, probabilities, and maximization of throughputs. It is desirable to design a controller that minimizes one cost objective, subject to inequality constraints on other cost objectives. This framework describes dynamic decision problems arising frequently in many engineering fields. A thorough overview of these applications is presented in the introduction. The book is then divided into three sections that build upon each other.},
	publisher = {Routledge},
	author = {Altman, Eitan},
	year = {1999},
	doi = {10.1201/9781315140223},
}
